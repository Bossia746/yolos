#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ç®€åŒ–ç‰ˆå¤šæ¨¡æ€è¯†åˆ«GUIæµ‹è¯• - ä¸“æ³¨äºåŸºæœ¬åŠŸèƒ½éªŒè¯"""

import sys
import os
import cv2
import numpy as np
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / 'src'))

# è®¾ç½®ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('simple_multimodal_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class SimpleMultimodalTester:
    """ç®€åŒ–ç‰ˆå¤šæ¨¡æ€è¯†åˆ«æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.face_recognizer = None
        self.gesture_recognizer = None
        self.pose_recognizer = None
        self.cap = None
        self.running = False
        self.frame_count = 0
        self.detection_stats = {
            'faces': 0,
            'gestures': 0,
            'poses': 0
        }
        
    def initialize_recognizers(self):
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–è¯†åˆ«å™¨...")
        
        # åˆå§‹åŒ–é¢éƒ¨è¯†åˆ«å™¨
        try:
            from recognition.face_recognizer import FaceRecognizer
            self.face_recognizer = FaceRecognizer()
            logger.info("âœ… é¢éƒ¨è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ é¢éƒ¨è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–æ‰‹åŠ¿è¯†åˆ«å™¨
        try:
            from recognition.gesture_recognizer import GestureRecognizer
            self.gesture_recognizer = GestureRecognizer()
            logger.info("âœ… æ‰‹åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ æ‰‹åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–å§¿åŠ¿è¯†åˆ«å™¨
        try:
            from recognition.pose_recognizer import PoseRecognizer
            self.pose_recognizer = PoseRecognizer()
            logger.info("âœ… å§¿åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ å§¿åŠ¿è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        return True
    
    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        logger.info("ğŸ“· åˆå§‹åŒ–æ‘„åƒå¤´...")
        
        try:
            self.cap = cv2.VideoCapture(0)
            
            if not self.cap.isOpened():
                logger.error("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            # æµ‹è¯•è¯»å–
            ret, frame = self.cap.read()
            if ret and frame is not None:
                logger.info(f"âœ… æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ: {frame.shape}")
                return True
            else:
                logger.error("âŒ æ‘„åƒå¤´æµ‹è¯•è¯»å–å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def detect_multimodal(self, frame: np.ndarray) -> Tuple[np.ndarray, Dict[str, Any]]:
        """æ‰§è¡Œå¤šæ¨¡æ€æ£€æµ‹"""
        annotated_frame = frame.copy()
        results = {
            'faces': [],
            'gestures': [],
            'poses': []
        }
        
        # é¢éƒ¨æ£€æµ‹
        if self.face_recognizer:
            try:
                face_frame, face_results = self.face_recognizer.detect_faces(frame)
                if face_results:
                    results['faces'] = face_results
                    self.detection_stats['faces'] += len(face_results)
                    annotated_frame = face_frame
            except Exception as e:
                logger.debug(f"é¢éƒ¨æ£€æµ‹é”™è¯¯: {e}")
        
        # æ‰‹åŠ¿æ£€æµ‹
        if self.gesture_recognizer:
            try:
                gesture_frame, gesture_results = self.gesture_recognizer.detect_hands(annotated_frame)
                if gesture_results:
                    results['gestures'] = gesture_results
                    self.detection_stats['gestures'] += len(gesture_results)
                    annotated_frame = gesture_frame
            except Exception as e:
                logger.debug(f"æ‰‹åŠ¿æ£€æµ‹é”™è¯¯: {e}")
        
        # å§¿åŠ¿æ£€æµ‹
        if self.pose_recognizer:
            try:
                pose_frame, pose_result = self.pose_recognizer.detect_pose(annotated_frame)
                if pose_result and pose_result.get('pose_detected', False):
                    results['poses'] = [pose_result]
                    self.detection_stats['poses'] += 1
                    annotated_frame = pose_frame
            except Exception as e:
                logger.debug(f"å§¿åŠ¿æ£€æµ‹é”™è¯¯: {e}")
        
        return annotated_frame, results
    
    def draw_info_overlay(self, frame: np.ndarray, fps: float):
        """ç»˜åˆ¶ä¿¡æ¯è¦†ç›–å±‚"""
        try:
            # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
            overlay = frame.copy()
            cv2.rectangle(overlay, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            
            # ç»˜åˆ¶æ–‡æœ¬ä¿¡æ¯
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            color = (255, 255, 255)
            thickness = 1
            
            # å½“å‰æ—¶é—´
            current_time = datetime.now().strftime("%H:%M:%S")
            cv2.putText(frame, f"Time: {current_time}", (10, 25), font, font_scale, color, thickness)
            
            # FPSä¿¡æ¯
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, 50), font, font_scale, color, thickness)
            
            # å¸§è®¡æ•°
            cv2.putText(frame, f"Frame: {self.frame_count}", (10, 75), font, font_scale, color, thickness)
            
            # æ£€æµ‹ç»Ÿè®¡
            stats_text = f"Faces: {self.detection_stats['faces']} | "
            stats_text += f"Gestures: {self.detection_stats['gestures']} | "
            stats_text += f"Poses: {self.detection_stats['poses']}"
            cv2.putText(frame, stats_text, (10, 100), font, 0.5, color, thickness)
            
            # æ§åˆ¶è¯´æ˜
            control_text = "Controls: [Q]uit | [S]ave | [R]eset | [SPACE]Pause"
            cv2.putText(frame, control_text, (10, frame.shape[0] - 10), font, 0.4, (0, 255, 0), 1)
            
        except Exception as e:
            logger.warning(f"ç»˜åˆ¶ä¿¡æ¯è¦†ç›–å±‚å¤±è´¥: {e}")
    
    def save_screenshot(self, frame: np.ndarray):
        """ä¿å­˜æˆªå›¾"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"multimodal_screenshot_{timestamp}.jpg"
            cv2.imwrite(filename, frame)
            logger.info(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜æˆªå›¾å¤±è´¥: {e}")
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.detection_stats = {'faces': 0, 'gestures': 0, 'poses': 0}
        self.frame_count = 0
        logger.info("ğŸ“Š ç»Ÿè®¡å·²é‡ç½®")
    
    def run_test(self):
        """è¿è¡Œæµ‹è¯•"""
        logger.info("ğŸ–¥ï¸ å¼€å§‹ç®€åŒ–ç‰ˆå¤šæ¨¡æ€è¯†åˆ«GUIæµ‹è¯•")
        
        # åˆå§‹åŒ–è¯†åˆ«å™¨
        if not self.initialize_recognizers():
            logger.error("âŒ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        if not self.initialize_camera():
            logger.error("âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
            return False
        
        # åˆ›å»ºçª—å£
        window_name = "Simple Multimodal Recognition Test"
        cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
        
        logger.info("ğŸ¬ å¼€å§‹å®æ—¶æ£€æµ‹ï¼ŒæŒ‰ 'q' é€€å‡º...")
        
        self.running = True
        paused = False
        fps_counter = 0
        fps_start_time = time.time()
        current_fps = 0
        
        try:
            while self.running:
                if not paused:
                    # è¯»å–æ‘„åƒå¤´å¸§
                    ret, frame = self.cap.read()
                    
                    if not ret or frame is None:
                        logger.warning("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                        continue
                    
                    self.frame_count += 1
                    fps_counter += 1
                    
                    # æ‰§è¡Œå¤šæ¨¡æ€æ£€æµ‹
                    start_time = time.time()
                    try:
                        annotated_frame, results = self.detect_multimodal(frame)
                        processing_time = time.time() - start_time
                    except Exception as e:
                        logger.warning(f"æ£€æµ‹å¤„ç†å¤±è´¥: {e}")
                        annotated_frame = frame
                        processing_time = 0
                    
                    # è®¡ç®—FPS
                    current_time = time.time()
                    if current_time - fps_start_time >= 1.0:
                        current_fps = fps_counter / (current_time - fps_start_time)
                        fps_counter = 0
                        fps_start_time = current_time
                    
                    # ç»˜åˆ¶ä¿¡æ¯è¦†ç›–å±‚
                    self.draw_info_overlay(annotated_frame, current_fps)
                    
                    # æ˜¾ç¤ºå¸§
                    cv2.imshow(window_name, annotated_frame)
                
                # å¤„ç†é”®ç›˜è¾“å…¥
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # 'q' æˆ– ESC é€€å‡º
                    logger.info("ç”¨æˆ·è¯·æ±‚é€€å‡º")
                    break
                elif key == ord('s'):  # 's' ä¿å­˜æˆªå›¾
                    if 'annotated_frame' in locals():
                        self.save_screenshot(annotated_frame)
                elif key == ord('r'):  # 'r' é‡ç½®ç»Ÿè®¡
                    self.reset_stats()
                elif key == ord(' '):  # ç©ºæ ¼é”®æš‚åœ/ç»§ç»­
                    paused = not paused
                    status = "æš‚åœ" if paused else "ç»§ç»­"
                    logger.info(f"ğŸ“¹ è§†é¢‘ {status}")
                
                # æ£€æŸ¥çª—å£æ˜¯å¦è¢«å…³é—­
                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:
                    logger.info("çª—å£è¢«å…³é—­")
                    break
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            self.generate_report(current_fps)
            
            logger.info("âœ… æµ‹è¯•å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
        
        finally:
            self.cleanup()
    
    def generate_report(self, fps: float):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š å¤šæ¨¡æ€è¯†åˆ«æµ‹è¯•æŠ¥å‘Š")
        logger.info("="*60)
        logger.info(f"æ€»å¸§æ•°: {self.frame_count}")
        logger.info(f"å¹³å‡FPS: {fps:.1f}")
        logger.info(f"é¢éƒ¨æ£€æµ‹æ¬¡æ•°: {self.detection_stats['faces']}")
        logger.info(f"æ‰‹åŠ¿æ£€æµ‹æ¬¡æ•°: {self.detection_stats['gestures']}")
        logger.info(f"å§¿åŠ¿æ£€æµ‹æ¬¡æ•°: {self.detection_stats['poses']}")
        
        # è®¡ç®—æ£€æµ‹ç‡
        if self.frame_count > 0:
            face_rate = (self.detection_stats['faces'] / self.frame_count) * 100
            gesture_rate = (self.detection_stats['gestures'] / self.frame_count) * 100
            pose_rate = (self.detection_stats['poses'] / self.frame_count) * 100
            
            logger.info(f"é¢éƒ¨æ£€æµ‹ç‡: {face_rate:.1f}%")
            logger.info(f"æ‰‹åŠ¿æ£€æµ‹ç‡: {gesture_rate:.1f}%")
            logger.info(f"å§¿åŠ¿æ£€æµ‹ç‡: {pose_rate:.1f}%")
        
        logger.info("="*60)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        
        self.running = False
        
        # é‡Šæ”¾æ‘„åƒå¤´
        if self.cap:
            self.cap.release()
        
        # å…³é—­æ‰€æœ‰OpenCVçª—å£
        cv2.destroyAllWindows()
        
        # æ¸…ç†è¯†åˆ«å™¨
        if self.face_recognizer and hasattr(self.face_recognizer, 'close'):
            self.face_recognizer.close()
        if self.gesture_recognizer and hasattr(self.gesture_recognizer, 'close'):
            self.gesture_recognizer.close()
        if self.pose_recognizer and hasattr(self.pose_recognizer, 'close'):
            self.pose_recognizer.close()
        
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ–¥ï¸ ç®€åŒ–ç‰ˆå¤šæ¨¡æ€è¯†åˆ«GUIæµ‹è¯•")
    print("=" * 50)
    print("åŠŸèƒ½è¯´æ˜:")
    print("- å®æ—¶æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢")
    print("- åŒæ—¶è¿›è¡Œé¢éƒ¨ã€æ‰‹åŠ¿ã€èº«ä½“å§¿åŠ¿è¯†åˆ«")
    print("- æ˜¾ç¤ºFPSå’Œæ£€æµ‹ç»Ÿè®¡")
    print("- æŒ‰ 'q' æˆ– ESC é€€å‡º")
    print("- æŒ‰ 's' ä¿å­˜æˆªå›¾")
    print("- æŒ‰ 'r' é‡ç½®ç»Ÿè®¡")
    print("- æŒ‰ç©ºæ ¼é”®æš‚åœ/ç»§ç»­")
    print("=" * 50)
    
    try:
        tester = SimpleMultimodalTester()
        success = tester.run_test()
        
        if success:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
            sys.exit(0)
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()