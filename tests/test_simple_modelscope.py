#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„ModelScopeæœåŠ¡æµ‹è¯•
"""

import os
import sys
import time
import cv2
import numpy as np
from pathlib import Path
from openai import OpenAI

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    try:
        print("=== æµ‹è¯•ModelScope APIè¿æ¥ ===")
        
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='*****'
        )
        
        # æµ‹è¯•æ–‡æœ¬è¯·æ±‚
        response = client.chat.completions.create(
            model='Qwen/Qwen2.5-VL-72B-Instruct',
            messages=[{
                'role': 'user',
                'content': [{'type': 'text', 'text': 'ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ çš„è§†è§‰åˆ†æèƒ½åŠ›ã€‚'}]
            }],
            max_tokens=200,
            timeout=30
        )
        
        if response.choices:
            print("âœ“ APIè¿æ¥æˆåŠŸ")
            print(f"å“åº”: {response.choices[0].message.content}")
            return True
        else:
            print("âœ— APIå“åº”ä¸ºç©º")
            return False
            
    except Exception as e:
        print(f"âœ— APIè¿æ¥å¤±è´¥: {e}")
        return False

def create_test_image():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    try:
        # åˆ›å»ºç›®å½•
        test_dir = Path("test_images")
        test_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        image = np.zeros((400, 600, 3), dtype=np.uint8)
        
        # èƒŒæ™¯è‰²
        image[:] = (240, 248, 255)  # æ·¡è“è‰²
        
        # æ·»åŠ ä¸€äº›å‡ ä½•å›¾å½¢
        cv2.rectangle(image, (50, 50), (200, 150), (0, 255, 0), -1)  # ç»¿è‰²çŸ©å½¢
        cv2.circle(image, (400, 100), 50, (255, 0, 0), -1)  # è“è‰²åœ†å½¢
        cv2.ellipse(image, (300, 250), (80, 40), 0, 0, 360, (0, 0, 255), -1)  # çº¢è‰²æ¤­åœ†
        
        # æ·»åŠ æ–‡å­—
        cv2.putText(image, "YOLOS Test Image", (150, 300), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.putText(image, "Medical AI System", (150, 350), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 100, 100), 2)
        
        # ä¿å­˜å›¾åƒ
        test_image_path = test_dir / "test_image.jpg"
        cv2.imwrite(str(test_image_path), image)
        
        print(f"âœ“ åˆ›å»ºæµ‹è¯•å›¾åƒ: {test_image_path}")
        return str(test_image_path)
        
    except Exception as e:
        print(f"âœ— åˆ›å»ºæµ‹è¯•å›¾åƒå¤±è´¥: {e}")
        return None

def test_image_analysis(image_path):
    """æµ‹è¯•å›¾åƒåˆ†æ"""
    try:
        print(f"\n=== æµ‹è¯•å›¾åƒåˆ†æ ===")
        print(f"åˆ†æå›¾åƒ: {image_path}")
        
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='*****'
        )
        
        # è¯»å–å¹¶ç¼–ç å›¾åƒ
        import base64
        with open(image_path, 'rb') as f:
            image_data = f.read()
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        
        # æ„å»ºåˆ†ææç¤º
        prompt = """
        è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾åƒï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
        
        {
          "scene_description": "è¯¦ç»†çš„åœºæ™¯æè¿°",
          "detected_objects": [
            {
              "name": "å¯¹è±¡åç§°",
              "confidence": 0.95,
              "category": "å¯¹è±¡ç±»åˆ«",
              "location": "ä½ç½®æè¿°"
            }
          ],
          "scene_category": "åœºæ™¯ç±»åˆ«",
          "overall_confidence": 0.85,
          "technical_details": {
            "image_quality": "excellent/good/fair/poor",
            "lighting_conditions": "æè¿°",
            "clarity": "æ¸…æ™°åº¦è¯„ä¼°"
          }
        }
        """
        
        start_time = time.time()
        
        # å‘é€è¯·æ±‚
        response = client.chat.completions.create(
            model='Qwen/Qwen2.5-VL-72B-Instruct',
            messages=[{
                'role': 'user',
                'content': [
                    {'type': 'text', 'text': prompt},
                    {
                        'type': 'image_url',
                        'image_url': {
                            'url': f'data:image/jpeg;base64,{image_base64}'
                        }
                    }
                ]
            }],
            max_tokens=2048,
            temperature=0.1,
            timeout=60
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        if response.choices:
            result = response.choices[0].message.content
            
            print("âœ“ å›¾åƒåˆ†ææˆåŠŸ")
            print(f"å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
            print(f"åˆ†æç»“æœ:")
            print("-" * 50)
            print(result)
            print("-" * 50)
            
            # å°è¯•è§£æJSON
            try:
                import json
                if result.strip().startswith('{'):
                    parsed_result = json.loads(result)
                    print("\nâœ“ JSONæ ¼å¼è§£ææˆåŠŸ")
                    print(f"åœºæ™¯æè¿°: {parsed_result.get('scene_description', 'N/A')}")
                    print(f"åœºæ™¯ç±»åˆ«: {parsed_result.get('scene_category', 'N/A')}")
                    print(f"æ•´ä½“ç½®ä¿¡åº¦: {parsed_result.get('overall_confidence', 'N/A')}")
                    
                    detected_objects = parsed_result.get('detected_objects', [])
                    if detected_objects:
                        print(f"æ£€æµ‹åˆ° {len(detected_objects)} ä¸ªå¯¹è±¡:")
                        for i, obj in enumerate(detected_objects):
                            print(f"  {i+1}. {obj.get('name', 'Unknown')} - {obj.get('category', 'Unknown')}")
                else:
                    print("âš  ç»“æœä¸æ˜¯JSONæ ¼å¼ï¼Œä½†åˆ†ææˆåŠŸ")
            except json.JSONDecodeError:
                print("âš  JSONè§£æå¤±è´¥ï¼Œä½†åˆ†ææˆåŠŸ")
            
            return True
        else:
            print("âœ— å›¾åƒåˆ†æå¤±è´¥ï¼šAPIè¿”å›ç©ºç»“æœ")
            return False
            
    except Exception as e:
        print(f"âœ— å›¾åƒåˆ†æå¤±è´¥: {e}")
        return False

def test_medical_analysis():
    """æµ‹è¯•åŒ»ç–—åœºæ™¯åˆ†æ"""
    try:
        print(f"\n=== æµ‹è¯•åŒ»ç–—åœºæ™¯åˆ†æ ===")
        
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key='*****'
        )
        
        # åŒ»ç–—åˆ†ææç¤º
        medical_prompt = """
        ä½œä¸ºYOLOSåŒ»ç–—AIç³»ç»Ÿçš„è§†è§‰åˆ†æä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹åŒ»ç–—åœºæ™¯éœ€æ±‚ï¼š
        
        1. å¦‚æœå›¾åƒä¸­åŒ…å«è¯ç‰©ï¼Œè¯·è¯†åˆ«è¯å“ç±»å‹ã€åŒ…è£…ä¿¡æ¯
        2. å¦‚æœå›¾åƒä¸­åŒ…å«äººå‘˜ï¼Œè¯·è¯„ä¼°å¥åº·çŠ¶æ€ã€æ˜¯å¦æœ‰è·Œå€’é£é™©
        3. å¦‚æœå›¾åƒä¸­åŒ…å«åŒ»ç–—å™¨æ¢°ï¼Œè¯·è¯†åˆ«ç±»å‹å’Œç”¨é€”
        4. è¯„ä¼°æ•´ä½“å®‰å…¨çŠ¶å†µå’Œç´§æ€¥ç¨‹åº¦
        
        è¯·æä¾›ä¸“ä¸šçš„åŒ»ç–—åˆ†æå»ºè®®ã€‚
        """
        
        response = client.chat.completions.create(
            model='Qwen/Qwen2.5-VL-72B-Instruct',
            messages=[{
                'role': 'user',
                'content': [{'type': 'text', 'text': medical_prompt}]
            }],
            max_tokens=1000,
            temperature=0.05,  # åŒ»ç–—åœºæ™¯éœ€è¦æ›´ä¿å®ˆ
            timeout=30
        )
        
        if response.choices:
            result = response.choices[0].message.content
            print("âœ“ åŒ»ç–—åˆ†æèƒ½åŠ›æµ‹è¯•æˆåŠŸ")
            print("åŒ»ç–—AIåˆ†æèƒ½åŠ›:")
            print("-" * 50)
            print(result)
            print("-" * 50)
            return True
        else:
            print("âœ— åŒ»ç–—åˆ†ææµ‹è¯•å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âœ— åŒ»ç–—åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("YOLOS ModelScopeæœåŠ¡ç®€åŒ–æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ç»“æœç»Ÿè®¡
    test_results = []
    
    # 1. æµ‹è¯•APIè¿æ¥
    api_success = test_api_connection()
    test_results.append(("APIè¿æ¥", api_success))
    
    if not api_success:
        print("\nâŒ APIè¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return
    
    # 2. åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image_path = create_test_image()
    if test_image_path:
        test_results.append(("æµ‹è¯•å›¾åƒåˆ›å»º", True))
        
        # 3. æµ‹è¯•å›¾åƒåˆ†æ
        analysis_success = test_image_analysis(test_image_path)
        test_results.append(("å›¾åƒåˆ†æ", analysis_success))
    else:
        test_results.append(("æµ‹è¯•å›¾åƒåˆ›å»º", False))
        test_results.append(("å›¾åƒåˆ†æ", False))
    
    # 4. æµ‹è¯•åŒ»ç–—åˆ†æ
    medical_success = test_medical_analysis()
    test_results.append(("åŒ»ç–—åˆ†æ", medical_success))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 60)
    
    success_count = 0
    for test_name, success in test_results:
        status = "âœ“ æˆåŠŸ" if success else "âœ— å¤±è´¥"
        print(f"{test_name:<15}: {status}")
        if success:
            success_count += 1
    
    print(f"\næ€»ä½“ç»“æœ: {success_count}/{len(test_results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if success_count == len(test_results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ModelScopeé›†æˆæˆåŠŸï¼")
    elif success_count > 0:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥")
    
    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    if api_success:
        print("1. âœ… ModelScope APIé›†æˆæˆåŠŸ")
        print("2. ğŸ“ å¯ä»¥å¼€å§‹é›†æˆåˆ°YOLOSä¸»ç³»ç»Ÿ")
        print("3. ğŸ”§ æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´é…ç½®å‚æ•°")
        print("4. ğŸ“Š è¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("5. ğŸš€ éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
    else:
        print("1. ğŸ” æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("2. ğŸŒ æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("3. ğŸ“‹ æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—")

if __name__ == "__main__":
    main()