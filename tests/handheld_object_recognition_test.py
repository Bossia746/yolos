#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«ä¸“ä¸šæµ‹è¯•
å±•ç¤ºé¡¹ç›®çš„å®Œæ•´æ£€æµ‹èƒ½åŠ›å’Œæ€§èƒ½ä¼˜åŒ–ç‰¹æ€§

åŠŸèƒ½ç‰¹æ€§:
- å¤šæ¨¡å‹å¯¹æ¯”æµ‹è¯• (YOLOv8, YOLOv11)
- å®æ—¶æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡
- æ™ºèƒ½æ£€æµ‹ç»“æœåˆ†æ
- å¤šç§å¯è§†åŒ–æ¨¡å¼
- è‡ªåŠ¨æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
- è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–å±•ç¤º
"""

import cv2
import numpy as np
import time
import json
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import matplotlib.pyplot as plt
import seaborn as sns

# é¡¹ç›®æ¨¡å—å¯¼å…¥
import sys
sys.path.append('src')

try:
    from models.yolov8_model import YOLOv8Model
    from models.yolov11_detector import YOLOv11Detector
    from utils.logging_manager import LoggingManager
    from .test_config import YOLOSTestConfig
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    # ä¸è¦ç›´æ¥é€€å‡ºï¼Œè€Œæ˜¯è·³è¿‡æµ‹è¯•
    import pytest
    pytest.skip(f"è·³è¿‡æµ‹è¯•ï¼Œæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")


# TestConfig is now imported from .test_config as YOLOSTestConfig
    
    # è¾“å‡ºé…ç½®
    save_images: bool = True
    save_video: bool = True
    generate_report: bool = True
    output_dir: str = "test_results"
    
    def __post_init__(self):
        if self.models_to_test is None:
            self.models_to_test = ['yolov8n', 'yolov8s', 'yolov11n', 'yolov11s']


@dataclass
class DetectionStats:
    """æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    model_name: str
    total_detections: int = 0
    unique_objects: int = 0
    avg_confidence: float = 0.0
    avg_inference_time: float = 0.0
    fps: float = 0.0
    object_categories: Dict[str, int] = None
    confidence_distribution: List[float] = None
    
    def __post_init__(self):
        if self.object_categories is None:
            self.object_categories = {}
        if self.confidence_distribution is None:
            self.confidence_distribution = []


class HandheldObjectRecognitionTest:
    """æ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æµ‹è¯•ç³»ç»Ÿ"""
    
    def __init__(self, config: YOLOSTestConfig):
        self.config = config
        self.logger = LoggingManager().get_logger("HandheldObjectTest")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.detectors = {}
        self.detection_stats = {}
        
        # æµ‹è¯•æ•°æ®
        self.test_images = []
        self.test_results = {}
        self.performance_data = {}
        
        # æ‘„åƒå¤´
        self.camera = None
        self.is_testing = False
        
        self.logger.info("æ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def initialize_detectors(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ£€æµ‹å™¨"""
        self.logger.info("æ­£åœ¨åˆå§‹åŒ–æ£€æµ‹å™¨...")
        
        for model_name in self.config.models_to_test:
            try:
                if model_name.startswith('yolov8'):
                    # YOLOv8æ¨¡å‹
                    model_size = model_name.replace('yolov8', '')
                    model_path = f"models/yolov8{model_size}.pt"
                    
                    if Path(model_path).exists():
                        detector = YOLOv8Model(model_path=model_path)
                        detector.conf_threshold = self.config.confidence_threshold
                        detector.iou_threshold = self.config.iou_threshold
                        self.detectors[model_name] = detector
                        self.logger.info(f"âœ… {model_name} åŠ è½½æˆåŠŸ")
                    else:
                        self.logger.warning(f"âš ï¸ {model_name} æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                
                elif model_name.startswith('yolov11'):
                    # YOLOv11æ¨¡å‹
                    model_size = model_name.replace('yolov11', '')
                    
                    detector = YOLOv11Detector(
                        model_size=model_size,
                        device='auto',
                        half_precision=self.config.enable_half_precision,
                        tensorrt_optimize=self.config.enable_tensorrt,
                        confidence_threshold=self.config.confidence_threshold,
                        iou_threshold=self.config.iou_threshold
                    )
                    self.detectors[model_name] = detector
                    self.logger.info(f"âœ… {model_name} åŠ è½½æˆåŠŸ")
                
                # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
                self.detection_stats[model_name] = DetectionStats(model_name=model_name)
                
            except Exception as e:
                self.logger.error(f"âŒ {model_name} åŠ è½½å¤±è´¥: {e}")
        
        if not self.detectors:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ£€æµ‹å™¨")
        
        self.logger.info(f"æˆåŠŸåŠ è½½ {len(self.detectors)} ä¸ªæ£€æµ‹å™¨")
    
    def setup_camera(self):
        """è®¾ç½®æ‘„åƒå¤´"""
        self.logger.info("æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
        
        self.camera = cv2.VideoCapture(self.config.camera_id)
        
        if not self.camera.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.config.camera_id}")
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        self.camera.set(cv2.CAP_PROP_FPS, 30)
        self.camera.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # è·å–å®é™…å‚æ•°
        width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(self.camera.get(cv2.CAP_PROP_FPS))
        
        self.logger.info(f"æ‘„åƒå¤´é…ç½®: {width}x{height} @ {fps}FPS")
        
        # é¢„çƒ­æ‘„åƒå¤´
        for _ in range(10):
            ret, _ = self.camera.read()
            if not ret:
                raise RuntimeError("æ‘„åƒå¤´é¢„çƒ­å¤±è´¥")
        
        self.logger.info("æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆ")
    
    def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹æ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«ç»¼åˆæµ‹è¯•")
        self.logger.info(f"æµ‹è¯•æ—¶é•¿: {self.config.test_duration}ç§’")
        self.logger.info(f"æµ‹è¯•æ¨¡å‹: {', '.join(self.config.models_to_test)}")
        
        try:
            # åˆå§‹åŒ–ç³»ç»Ÿ
            self.initialize_detectors()
            self.setup_camera()
            
            # åˆ›å»ºè§†é¢‘å½•åˆ¶å™¨
            video_writer = None
            if self.config.save_video:
                video_writer = self._create_video_writer()
            
            # å¼€å§‹æµ‹è¯•
            self.is_testing = True
            start_time = time.time()
            last_capture_time = 0
            frame_count = 0
            
            print("\n" + "="*60)
            print("ğŸ¯ YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æµ‹è¯•")
            print("="*60)
            print("æ“ä½œè¯´æ˜:")
            print("  - æ‰‹æŒä¸åŒç‰©ä½“åœ¨æ‘„åƒå¤´å‰å±•ç¤º")
            print("  - æŒ‰ 'c' é”®æ‰‹åŠ¨æ•è·å½“å‰å¸§è¿›è¡Œåˆ†æ")
            print("  - æŒ‰ 's' é”®ä¿å­˜å½“å‰æ£€æµ‹ç»“æœ")
            print("  - æŒ‰ 'p' é”®æ˜¾ç¤ºå®æ—¶æ€§èƒ½ç»Ÿè®¡")
            print("  - æŒ‰ 'q' é”®é€€å‡ºæµ‹è¯•")
            print("="*60)
            
            while self.is_testing:
                current_time = time.time()
                elapsed_time = current_time - start_time
                
                # æ£€æŸ¥æµ‹è¯•æ—¶é—´
                if elapsed_time >= self.config.test_duration:
                    self.logger.info("æµ‹è¯•æ—¶é—´åˆ°è¾¾ï¼Œè‡ªåŠ¨ç»“æŸ")
                    break
                
                # è¯»å–æ‘„åƒå¤´å¸§
                ret, frame = self.camera.read()
                if not ret:
                    self.logger.error("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                    break
                
                frame_count += 1
                
                # åˆ›å»ºæ˜¾ç¤ºå¸§
                display_frame = frame.copy()
                
                # è‡ªåŠ¨æ•è·é€»è¾‘
                if (current_time - last_capture_time) >= self.config.capture_interval:
                    self._capture_and_analyze_frame(frame, f"auto_{len(self.test_images)}")
                    last_capture_time = current_time
                
                # ç»˜åˆ¶å®æ—¶ä¿¡æ¯
                self._draw_test_info(display_frame, elapsed_time, len(self.test_images))
                
                # æ˜¾ç¤ºæœ€æ–°æ£€æµ‹ç»“æœ
                if self.test_results:
                    latest_result = list(self.test_results.values())[-1]
                    self._draw_latest_detection_results(display_frame, latest_result)
                
                # å½•åˆ¶è§†é¢‘
                if video_writer:
                    video_writer.write(display_frame)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow('YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•', display_frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.logger.info("ç”¨æˆ·é€€å‡ºæµ‹è¯•")
                    break
                elif key == ord('c'):
                    self._capture_and_analyze_frame(frame, f"manual_{len(self.test_images)}")
                elif key == ord('s'):
                    self._save_current_results(frame)
                elif key == ord('p'):
                    self._print_realtime_stats()
            
            # æ¸…ç†èµ„æº
            if video_writer:
                video_writer.release()
            
            self.camera.release()
            cv2.destroyAllWindows()
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            if self.config.generate_report:
                self._generate_comprehensive_report()
            
            self.logger.info("âœ… æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
        finally:
            self.is_testing = False
            if self.camera:
                self.camera.release()
            cv2.destroyAllWindows()
    
    def _capture_and_analyze_frame(self, frame: np.ndarray, frame_id: str):
        """æ•è·å¹¶åˆ†æå¸§"""
        self.logger.info(f"ğŸ“¸ æ•è·å¸§è¿›è¡Œåˆ†æ: {frame_id}")
        
        # ä¿å­˜åŸå§‹å›¾åƒ
        if self.config.save_images:
            image_path = self.output_dir / f"captured_{frame_id}.jpg"
            cv2.imwrite(str(image_path), frame)
        
        # å­˜å‚¨æµ‹è¯•å›¾åƒ
        self.test_images.append((frame_id, frame.copy()))
        
        # å¯¹æ‰€æœ‰æ¨¡å‹è¿›è¡Œæ£€æµ‹
        frame_results = {}
        
        for model_name, detector in self.detectors.items():
            try:
                start_time = time.time()
                
                # æ‰§è¡Œæ£€æµ‹
                if hasattr(detector, 'detect'):
                    # YOLOv11æ£€æµ‹å™¨
                    results = detector.detect(frame)
                    # è½¬æ¢ç»“æœæ ¼å¼
                    detections = []
                    for result in results:
                        detections.append({
                            'bbox': [result.bbox.x, result.bbox.y, result.bbox.x2, result.bbox.y2],
                            'confidence': result.confidence,
                            'class_id': result.class_id,
                            'class_name': result.class_name
                        })
                else:
                    # YOLOv8æ£€æµ‹å™¨
                    detections = detector.predict(frame)
                
                inference_time = time.time() - start_time
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._update_detection_stats(model_name, detections, inference_time)
                
                # å­˜å‚¨ç»“æœ
                frame_results[model_name] = {
                    'detections': detections,
                    'inference_time': inference_time,
                    'timestamp': time.time()
                }
                
                self.logger.debug(f"{model_name}: {len(detections)}ä¸ªæ£€æµ‹, {inference_time:.3f}s")
                
            except Exception as e:
                self.logger.error(f"{model_name} æ£€æµ‹å¤±è´¥: {e}")
                frame_results[model_name] = {
                    'detections': [],
                    'inference_time': 0,
                    'error': str(e)
                }
        
        # å­˜å‚¨å¸§ç»“æœ
        self.test_results[frame_id] = frame_results
        
        # åˆ›å»ºå¯¹æ¯”å¯è§†åŒ–
        if len(frame_results) > 1:
            self._create_detection_comparison(frame, frame_results, frame_id)
    
    def _update_detection_stats(self, model_name: str, detections: List[Dict], inference_time: float):
        """æ›´æ–°æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.detection_stats[model_name]
        
        # åŸºç¡€ç»Ÿè®¡
        stats.total_detections += len(detections)
        
        # æ¨ç†æ—¶é—´ç»Ÿè®¡
        if hasattr(stats, 'inference_times'):
            stats.inference_times.append(inference_time)
        else:
            stats.inference_times = [inference_time]
        
        stats.avg_inference_time = np.mean(stats.inference_times)
        stats.fps = 1.0 / stats.avg_inference_time if stats.avg_inference_time > 0 else 0
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if detections:
            confidences = [d['confidence'] for d in detections]
            stats.confidence_distribution.extend(confidences)
            stats.avg_confidence = np.mean(stats.confidence_distribution)
            
            # ç±»åˆ«ç»Ÿè®¡
            for detection in detections:
                class_name = detection['class_name']
                stats.object_categories[class_name] = stats.object_categories.get(class_name, 0) + 1
            
            stats.unique_objects = len(stats.object_categories)
    
    def _create_detection_comparison(self, frame: np.ndarray, results: Dict, frame_id: str):
        """åˆ›å»ºæ£€æµ‹ç»“æœå¯¹æ¯”å›¾"""
        num_models = len(results)
        fig, axes = plt.subplots(2, (num_models + 1) // 2, figsize=(15, 10))
        if num_models == 1:
            axes = [axes]
        elif num_models <= 2:
            axes = axes.flatten()
        else:
            axes = axes.flatten()
        
        for idx, (model_name, result) in enumerate(results.items()):
            if idx >= len(axes):
                break
                
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            annotated_frame = self._draw_detections_on_frame(
                frame.copy(), result['detections'], model_name
            )
            
            # è½¬æ¢BGRåˆ°RGB
            annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            
            axes[idx].imshow(annotated_frame_rgb)
            axes[idx].set_title(f"{model_name}\næ£€æµ‹æ•°: {len(result['detections'])}, "
                              f"æ—¶é—´: {result['inference_time']:.3f}s")
            axes[idx].axis('off')
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(len(results), len(axes)):
            axes[idx].axis('off')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / f"comparison_{frame_id}.png", dpi=150, bbox_inches='tight')
        plt.close()
    
    def _draw_detections_on_frame(self, frame: np.ndarray, detections: List[Dict], model_name: str) -> np.ndarray:
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
        ]
        
        for i, detection in enumerate(detections):
            bbox = detection['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            
            # é€‰æ‹©é¢œè‰²
            color = colors[detection['class_id'] % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{detection['class_name']} {detection['confidence']:.2f}"
            
            # è®¡ç®—æ–‡æœ¬å¤§å°
            (text_width, text_height), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1
            )
            
            # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
            cv2.rectangle(frame, (x1, y1 - text_height - 5), 
                         (x1 + text_width, y1), color, -1)
            
            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(frame, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        return frame
    
    def _draw_test_info(self, frame: np.ndarray, elapsed_time: float, captured_frames: int):
        """ç»˜åˆ¶æµ‹è¯•ä¿¡æ¯"""
        info_lines = [
            f"æµ‹è¯•æ—¶é—´: {elapsed_time:.1f}s / {self.config.test_duration}s",
            f"å·²æ•è·å¸§æ•°: {captured_frames}",
            f"æ´»è·ƒæ¨¡å‹: {len(self.detectors)}",
            f"æŒ‰ 'c' æ‰‹åŠ¨æ•è·, 'q' é€€å‡º"
        ]
        
        # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (400, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ç»˜åˆ¶æ–‡æœ¬
        for i, line in enumerate(info_lines):
            cv2.putText(frame, line, (20, 35 + i * 25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
    
    def _draw_latest_detection_results(self, frame: np.ndarray, latest_result: Dict):
        """ç»˜åˆ¶æœ€æ–°æ£€æµ‹ç»“æœæ‘˜è¦"""
        y_offset = 150
        
        # ç»˜åˆ¶èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, y_offset), (500, y_offset + 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # æ ‡é¢˜
        cv2.putText(frame, "æœ€æ–°æ£€æµ‹ç»“æœ:", (20, y_offset + 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # å„æ¨¡å‹ç»“æœ
        line_y = y_offset + 50
        for model_name, result in latest_result.items():
            if 'error' in result:
                text = f"{model_name}: é”™è¯¯"
                color = (0, 0, 255)
            else:
                detections = result['detections']
                inference_time = result['inference_time']
                text = f"{model_name}: {len(detections)}ä¸ªç›®æ ‡, {inference_time:.3f}s"
                color = (0, 255, 0)
            
            cv2.putText(frame, text, (30, line_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            line_y += 25
    
    def _create_video_writer(self):
        """åˆ›å»ºè§†é¢‘å½•åˆ¶å™¨"""
        if not self.config.save_video:
            return None
        
        # è·å–æ‘„åƒå¤´å‚æ•°
        width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = 20  # å½•åˆ¶FPS
        
        # åˆ›å»ºè§†é¢‘æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_path = self.output_dir / f"test_video_{timestamp}.mp4"
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
        
        self.logger.info(f"å¼€å§‹å½•åˆ¶è§†é¢‘: {video_path}")
        return video_writer
    
    def _save_current_results(self, frame: np.ndarray):
        """ä¿å­˜å½“å‰ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å½“å‰å¸§
        frame_path = self.output_dir / f"manual_save_{timestamp}.jpg"
        cv2.imwrite(str(frame_path), frame)
        
        # ä¿å­˜æ£€æµ‹ç»“æœ
        if self.test_results:
            latest_result = list(self.test_results.values())[-1]
            result_path = self.output_dir / f"detection_result_{timestamp}.json"
            
            with open(result_path, 'w', encoding='utf-8') as f:
                json.dump(latest_result, f, ensure_ascii=False, indent=2, default=str)
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜: {frame_path}")
    
    def _print_realtime_stats(self):
        """æ‰“å°å®æ—¶ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š å®æ—¶æ€§èƒ½ç»Ÿè®¡")
        print("="*60)
        
        for model_name, stats in self.detection_stats.items():
            print(f"\nğŸ” {model_name}:")
            print(f"  æ€»æ£€æµ‹æ•°: {stats.total_detections}")
            print(f"  å¹³å‡æ¨ç†æ—¶é—´: {stats.avg_inference_time:.3f}s")
            print(f"  FPS: {stats.fps:.1f}")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats.avg_confidence:.3f}")
            print(f"  æ£€æµ‹ç±»åˆ«æ•°: {stats.unique_objects}")
            
            if stats.object_categories:
                print("  æ£€æµ‹åˆ°çš„ç‰©ä½“:")
                for obj_name, count in sorted(stats.object_categories.items(), 
                                            key=lambda x: x[1], reverse=True)[:5]:
                    print(f"    {obj_name}: {count}æ¬¡")
        
        print("="*60)
    
    def _generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        self.logger.info("æ­£åœ¨ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_dir = self.output_dir / f"report_{timestamp}"
        report_dir.mkdir(exist_ok=True)
        
        # 1. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨
        self._create_performance_charts(report_dir)
        
        # 2. ç”Ÿæˆæ£€æµ‹ç»“æœç»Ÿè®¡
        self._create_detection_statistics(report_dir)
        
        # 3. ç”ŸæˆHTMLæŠ¥å‘Š
        self._create_html_report(report_dir, timestamp)
        
        # 4. ä¿å­˜åŸå§‹æ•°æ®
        self._save_raw_data(report_dir)
        
        self.logger.info(f"ğŸ“‹ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_dir}")
    
    def _create_performance_charts(self, report_dir: Path):
        """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. æ¨ç†æ—¶é—´å¯¹æ¯”
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        model_names = list(self.detection_stats.keys())
        inference_times = [stats.avg_inference_time for stats in self.detection_stats.values()]
        fps_values = [stats.fps for stats in self.detection_stats.values()]
        total_detections = [stats.total_detections for stats in self.detection_stats.values()]
        avg_confidences = [stats.avg_confidence for stats in self.detection_stats.values()]
        
        # æ¨ç†æ—¶é—´å¯¹æ¯”
        bars1 = ax1.bar(model_names, inference_times, color='skyblue')
        ax1.set_title('å¹³å‡æ¨ç†æ—¶é—´å¯¹æ¯”')
        ax1.set_ylabel('æ—¶é—´ (ç§’)')
        ax1.tick_params(axis='x', rotation=45)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, time_val in zip(bars1, inference_times):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{time_val:.3f}s', ha='center', va='bottom')
        
        # FPSå¯¹æ¯”
        bars2 = ax2.bar(model_names, fps_values, color='lightgreen')
        ax2.set_title('FPSæ€§èƒ½å¯¹æ¯”')
        ax2.set_ylabel('FPS')
        ax2.tick_params(axis='x', rotation=45)
        
        for bar, fps_val in zip(bars2, fps_values):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{fps_val:.1f}', ha='center', va='bottom')
        
        # æ£€æµ‹æ•°é‡å¯¹æ¯”
        bars3 = ax3.bar(model_names, total_detections, color='orange')
        ax3.set_title('æ€»æ£€æµ‹æ•°é‡å¯¹æ¯”')
        ax3.set_ylabel('æ£€æµ‹æ•°é‡')
        ax3.tick_params(axis='x', rotation=45)
        
        for bar, det_count in zip(bars3, total_detections):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{det_count}', ha='center', va='bottom')
        
        # å¹³å‡ç½®ä¿¡åº¦å¯¹æ¯”
        bars4 = ax4.bar(model_names, avg_confidences, color='pink')
        ax4.set_title('å¹³å‡ç½®ä¿¡åº¦å¯¹æ¯”')
        ax4.set_ylabel('ç½®ä¿¡åº¦')
        ax4.tick_params(axis='x', rotation=45)
        
        for bar, conf_val in zip(bars4, avg_confidences):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{conf_val:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(report_dir / 'performance_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ç½®ä¿¡åº¦åˆ†å¸ƒå›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for idx, (model_name, stats) in enumerate(self.detection_stats.items()):
            if idx >= len(axes):
                break
            
            if stats.confidence_distribution:
                axes[idx].hist(stats.confidence_distribution, bins=20, alpha=0.7, color='blue')
                axes[idx].set_title(f'{model_name} ç½®ä¿¡åº¦åˆ†å¸ƒ')
                axes[idx].set_xlabel('ç½®ä¿¡åº¦')
                axes[idx].set_ylabel('é¢‘æ¬¡')
                axes[idx].axvline(stats.avg_confidence, color='red', linestyle='--', 
                                label=f'å¹³å‡å€¼: {stats.avg_confidence:.3f}')
                axes[idx].legend()
        
        # éšè—å¤šä½™çš„å­å›¾
        for idx in range(len(self.detection_stats), len(axes)):
            axes[idx].axis('off')
        
        plt.tight_layout()
        plt.savefig(report_dir / 'confidence_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_detection_statistics(self, report_dir: Path):
        """åˆ›å»ºæ£€æµ‹ç»“æœç»Ÿè®¡"""
        # æ±‡æ€»æ‰€æœ‰æ£€æµ‹åˆ°çš„ç‰©ä½“ç±»åˆ«
        all_categories = {}
        
        for stats in self.detection_stats.values():
            for category, count in stats.object_categories.items():
                all_categories[category] = all_categories.get(category, 0) + count
        
        # åˆ›å»ºç±»åˆ«æ£€æµ‹ç»Ÿè®¡å›¾
        if all_categories:
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # é¥¼å›¾
            categories = list(all_categories.keys())
            counts = list(all_categories.values())
            
            ax1.pie(counts, labels=categories, autopct='%1.1f%%', startangle=90)
            ax1.set_title('æ£€æµ‹ç‰©ä½“ç±»åˆ«åˆ†å¸ƒ')
            
            # æŸ±çŠ¶å›¾
            ax2.bar(categories, counts, color='lightcoral')
            ax2.set_title('å„ç±»åˆ«æ£€æµ‹æ¬¡æ•°')
            ax2.set_ylabel('æ£€æµ‹æ¬¡æ•°')
            ax2.tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plt.savefig(report_dir / 'category_statistics.png', dpi=300, bbox_inches='tight')
            plt.close()
    
    def _create_html_report(self, report_dir: Path, timestamp: str):
        """åˆ›å»ºHTMLæµ‹è¯•æŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 20px; }}
        .section {{ margin: 30px 0; }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .stat-card {{ background: #f9f9f9; padding: 15px; border-radius: 8px; border-left: 4px solid #4CAF50; }}
        .chart-container {{ text-align: center; margin: 20px 0; }}
        .chart-container img {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #4CAF50; color: white; }}
        .highlight {{ color: #4CAF50; font-weight: bold; }}
        .config-section {{ background: #e8f5e8; padding: 15px; border-radius: 8px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¯ YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•æŠ¥å‘Š</h1>
            <p>æµ‹è¯•æ—¶é—´: {timestamp}</p>
            <p>æµ‹è¯•æ—¶é•¿: {self.config.test_duration}ç§’ | æ•è·å¸§æ•°: {len(self.test_images)}</p>
        </div>
        
        <div class="section">
            <h2>ğŸ“‹ æµ‹è¯•é…ç½®</h2>
            <div class="config-section">
                <p><strong>æµ‹è¯•æ¨¡å‹:</strong> {', '.join(self.config.models_to_test)}</p>
                <p><strong>ç½®ä¿¡åº¦é˜ˆå€¼:</strong> {self.config.confidence_threshold}</p>
                <p><strong>IoUé˜ˆå€¼:</strong> {self.config.iou_threshold}</p>
                <p><strong>TensorRTä¼˜åŒ–:</strong> {'å¯ç”¨' if self.config.enable_tensorrt else 'ç¦ç”¨'}</p>
                <p><strong>åŠç²¾åº¦æ¨ç†:</strong> {'å¯ç”¨' if self.config.enable_half_precision else 'ç¦ç”¨'}</p>
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ“Š æ€§èƒ½ç»Ÿè®¡</h2>
            <div class="stats-grid">
        """
        
        # æ·»åŠ å„æ¨¡å‹ç»Ÿè®¡å¡ç‰‡
        for model_name, stats in self.detection_stats.items():
            html_content += f"""
                <div class="stat-card">
                    <h3>{model_name}</h3>
                    <p><strong>æ€»æ£€æµ‹æ•°:</strong> <span class="highlight">{stats.total_detections}</span></p>
                    <p><strong>å¹³å‡æ¨ç†æ—¶é—´:</strong> <span class="highlight">{stats.avg_inference_time:.3f}s</span></p>
                    <p><strong>FPS:</strong> <span class="highlight">{stats.fps:.1f}</span></p>
                    <p><strong>å¹³å‡ç½®ä¿¡åº¦:</strong> <span class="highlight">{stats.avg_confidence:.3f}</span></p>
                    <p><strong>æ£€æµ‹ç±»åˆ«æ•°:</strong> <span class="highlight">{stats.unique_objects}</span></p>
                </div>
            """
        
        html_content += """
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ“ˆ æ€§èƒ½å¯¹æ¯”å›¾è¡¨</h2>
            <div class="chart-container">
                <img src="performance_comparison.png" alt="æ€§èƒ½å¯¹æ¯”å›¾è¡¨">
            </div>
            <div class="chart-container">
                <img src="confidence_distribution.png" alt="ç½®ä¿¡åº¦åˆ†å¸ƒå›¾">
            </div>
        """
        
        # å¦‚æœæœ‰ç±»åˆ«ç»Ÿè®¡å›¾ï¼Œæ·»åŠ å®ƒ
        if (report_dir / 'category_statistics.png').exists():
            html_content += """
            <div class="chart-container">
                <img src="category_statistics.png" alt="ç±»åˆ«ç»Ÿè®¡å›¾">
            </div>
            """
        
        html_content += """
        </div>
        
        <div class="section">
            <h2>ğŸ” è¯¦ç»†æ£€æµ‹ç»“æœ</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ¨¡å‹</th>
                        <th>æ€»æ£€æµ‹æ•°</th>
                        <th>å¹³å‡æ¨ç†æ—¶é—´</th>
                        <th>FPS</th>
                        <th>å¹³å‡ç½®ä¿¡åº¦</th>
                        <th>ä¸»è¦æ£€æµ‹ç±»åˆ«</th>
                    </tr>
                </thead>
                <tbody>
        """
        
        # æ·»åŠ è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
        for model_name, stats in self.detection_stats.items():
            top_categories = sorted(stats.object_categories.items(), 
                                  key=lambda x: x[1], reverse=True)[:3]
            top_categories_str = ', '.join([f"{cat}({count})" for cat, count in top_categories])
            
            html_content += f"""
                    <tr>
                        <td>{model_name}</td>
                        <td>{stats.total_detections}</td>
                        <td>{stats.avg_inference_time:.3f}s</td>
                        <td>{stats.fps:.1f}</td>
                        <td>{stats.avg_confidence:.3f}</td>
                        <td>{top_categories_str}</td>
                    </tr>
            """
        
        html_content += """
                </tbody>
            </table>
        </div>
        
        <div class="section">
            <h2>ğŸ’¡ æµ‹è¯•æ€»ç»“</h2>
            <div class="config-section">
        """
        
        # ç”Ÿæˆæµ‹è¯•æ€»ç»“
        best_fps_model = max(self.detection_stats.items(), key=lambda x: x[1].fps)
        best_accuracy_model = max(self.detection_stats.items(), key=lambda x: x[1].avg_confidence)
        most_detections_model = max(self.detection_stats.items(), key=lambda x: x[1].total_detections)
        
        html_content += f"""
                <p><strong>ğŸš€ æœ€å¿«æ¨¡å‹:</strong> {best_fps_model[0]} (FPS: {best_fps_model[1].fps:.1f})</p>
                <p><strong>ğŸ¯ æœ€é«˜ç½®ä¿¡åº¦:</strong> {best_accuracy_model[0]} (ç½®ä¿¡åº¦: {best_accuracy_model[1].avg_confidence:.3f})</p>
                <p><strong>ğŸ” æ£€æµ‹æ•°æœ€å¤š:</strong> {most_detections_model[0]} (æ£€æµ‹æ•°: {most_detections_model[1].total_detections})</p>
                <p><strong>ğŸ“Š æµ‹è¯•å®Œæˆåº¦:</strong> æˆåŠŸæµ‹è¯•äº† {len(self.detectors)} ä¸ªæ¨¡å‹ï¼Œæ•è·äº† {len(self.test_images)} å¸§å›¾åƒ</p>
            </div>
        </div>
        
        <div class="section">
            <p style="text-align: center; color: #666; margin-top: 40px;">
                æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | 
                YOLOSæ™ºèƒ½è§†é¢‘è¯†åˆ«ç³»ç»Ÿ
            </p>
        </div>
    </div>
</body>
</html>
        """
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        with open(report_dir / 'test_report.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _save_raw_data(self, report_dir: Path):
        """ä¿å­˜åŸå§‹æµ‹è¯•æ•°æ®"""
        # ä¿å­˜ç»Ÿè®¡æ•°æ®
        stats_data = {}
        for model_name, stats in self.detection_stats.items():
            stats_data[model_name] = asdict(stats)
        
        with open(report_dir / 'detection_stats.json', 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        with open(report_dir / 'test_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜æµ‹è¯•é…ç½®
        with open(report_dir / 'test_config.json', 'w', encoding='utf-8') as f:
            json.dump(asdict(self.config), f, ensure_ascii=False, indent=2)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«ä¸“ä¸šæµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = TestConfig(
        test_duration=120,  # 2åˆ†é’Ÿæµ‹è¯•
        capture_interval=3.0,  # æ¯3ç§’è‡ªåŠ¨æ•è·
        models_to_test=['yolov8n', 'yolov8s', 'yolov11n', 'yolov11s'],
        confidence_threshold=0.25,
        enable_tensorrt=True,
        enable_half_precision=True,
        save_images=True,
        save_video=True,
        generate_report=True
    )
    
    # åˆ›å»ºæµ‹è¯•ç³»ç»Ÿ
    test_system = HandheldObjectRecognitionTest(config)
    
    try:
        # è¿è¡Œæµ‹è¯•
        test_system.run_comprehensive_test()
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {test_system.output_dir}")
        print("ğŸ“‹ è¯·æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Šè·å–è¯¦ç»†åˆ†æç»“æœ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()