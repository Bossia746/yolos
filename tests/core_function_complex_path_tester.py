#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒåŠŸèƒ½å¤æ‚è·¯å¾„æµ‹è¯•æ‰§è¡Œå™¨

å®æ–½YOLOSç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½çš„å¤æ‚è·¯å¾„æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
1. YOLOæ¨¡å‹å¤æ‚åœºæ™¯æµ‹è¯•ï¼ˆå¤šæ¨¡å‹ã€åŠ¨æ€åˆ‡æ¢ã€å¼‚å¸¸å¤„ç†ï¼‰
2. å®æ—¶æ£€æµ‹å¤æ‚è·¯å¾„æµ‹è¯•ï¼ˆé«˜å¹¶å‘ã€èµ„æºç«äº‰ã€ç½‘ç»œä¸­æ–­ï¼‰
3. å¤šç›®æ ‡è¯†åˆ«å¤æ‚åœºæ™¯æµ‹è¯•ï¼ˆé®æŒ¡ã€é‡å ã€è¾¹ç•Œæ¡ä»¶ï¼‰
4. ç³»ç»Ÿé›†æˆå¤æ‚è·¯å¾„æµ‹è¯•ï¼ˆæ¨¡å—é—´äº¤äº’ã€é”™è¯¯ä¼ æ’­ã€æ¢å¤æœºåˆ¶ï¼‰
5. æ•°æ®æµå¤æ‚è·¯å¾„æµ‹è¯•ï¼ˆå¤§æ•°æ®é‡ã€å¼‚å¸¸æ•°æ®ã€å†…å­˜æ³„æ¼ï¼‰
"""

import asyncio
import time
import threading
import multiprocessing
import psutil
import gc
import numpy as np
import cv2
from typing import Dict, List, Any, Optional, Callable, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, Future
import logging
import traceback
import sys
import os
from contextlib import contextmanager
import tempfile
import shutil
import random

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TestPathType(Enum):
    """æµ‹è¯•è·¯å¾„ç±»å‹"""
    NORMAL = "normal"              # æ­£å¸¸è·¯å¾„
    EDGE_CASE = "edge_case"        # è¾¹ç•Œæ¡ä»¶
    ERROR_PATH = "error_path"      # é”™è¯¯è·¯å¾„
    STRESS_PATH = "stress_path"    # å‹åŠ›è·¯å¾„
    RACE_CONDITION = "race_condition"  # ç«æ€æ¡ä»¶
    RESOURCE_EXHAUSTION = "resource_exhaustion"  # èµ„æºè€—å°½
    NETWORK_FAILURE = "network_failure"  # ç½‘ç»œæ•…éšœ
    CONCURRENT_ACCESS = "concurrent_access"  # å¹¶å‘è®¿é—®

class TestSeverity(Enum):
    """æµ‹è¯•ä¸¥é‡ç¨‹åº¦"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class ComplexTestCase:
    """å¤æ‚æµ‹è¯•ç”¨ä¾‹"""
    name: str
    path_type: TestPathType
    severity: TestSeverity
    description: str
    test_function: Callable
    setup_function: Optional[Callable] = None
    teardown_function: Optional[Callable] = None
    timeout: float = 60.0
    retry_count: int = 0
    prerequisites: List[str] = field(default_factory=list)
    expected_exceptions: List[type] = field(default_factory=list)
    performance_thresholds: Dict[str, float] = field(default_factory=dict)

@dataclass
class TestExecutionResult:
    """æµ‹è¯•æ‰§è¡Œç»“æœ"""
    test_name: str
    success: bool
    execution_time: float
    memory_usage: float
    cpu_usage: float
    error_message: Optional[str] = None
    exception_type: Optional[str] = None
    stack_trace: Optional[str] = None
    performance_metrics: Dict[str, Any] = field(default_factory=dict)
    resource_usage: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.now)

class MockDataGenerator:
    """æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_test_image(width: int = 640, height: int = 480, channels: int = 3) -> np.ndarray:
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        return np.random.randint(0, 255, (height, width, channels), dtype=np.uint8)
    
    @staticmethod
    def generate_corrupted_image(width: int = 640, height: int = 480) -> np.ndarray:
        """ç”ŸæˆæŸåçš„å›¾åƒæ•°æ®"""
        # ç”Ÿæˆéƒ¨åˆ†æŸåçš„å›¾åƒ
        image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
        # éšæœºæ·»åŠ å™ªå£°å’ŒæŸååŒºåŸŸ
        mask = np.random.random((height, width)) < 0.1
        image[mask] = 0
        return image
    
    @staticmethod
    def generate_large_image(scale_factor: int = 4) -> np.ndarray:
        """ç”Ÿæˆå¤§å°ºå¯¸å›¾åƒ"""
        width, height = 640 * scale_factor, 480 * scale_factor
        return np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
    
    @staticmethod
    def generate_video_frames(frame_count: int = 100, width: int = 640, height: int = 480) -> List[np.ndarray]:
        """ç”Ÿæˆè§†é¢‘å¸§åºåˆ—"""
        frames = []
        for i in range(frame_count):
            frame = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
            # æ·»åŠ ä¸€äº›è¿åŠ¨æ¨¡æ‹Ÿ
            cv2.circle(frame, (int(width/2 + 50*np.sin(i*0.1)), int(height/2)), 20, (255, 255, 255), -1)
            frames.append(frame)
        return frames

class ResourceMonitor:
    """èµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.start_memory = None
        self.start_cpu_time = None
        self.peak_memory = 0
        self.monitoring = False
        self._monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        self.start_cpu_time = self.process.cpu_times().user
        self.peak_memory = self.start_memory
        self.monitoring = True
        self._monitor_thread = threading.Thread(target=self._monitor_loop)
        self._monitor_thread.daemon = True
        self._monitor_thread.start()
    
    def stop_monitoring(self) -> Dict[str, float]:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»“æœ"""
        self.monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join(timeout=1.0)
        
        current_memory = self.process.memory_info().rss / 1024 / 1024  # MB
        current_cpu_time = self.process.cpu_times().user
        
        return {
            'memory_usage_mb': current_memory,
            'memory_delta_mb': current_memory - self.start_memory,
            'peak_memory_mb': self.peak_memory,
            'cpu_time_delta': current_cpu_time - self.start_cpu_time,
            'cpu_percent': self.process.cpu_percent()
        }
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                current_memory = self.process.memory_info().rss / 1024 / 1024
                self.peak_memory = max(self.peak_memory, current_memory)
                time.sleep(0.1)
            except:
                break

class CoreFunctionComplexPathTester:
    """æ ¸å¿ƒåŠŸèƒ½å¤æ‚è·¯å¾„æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_cases: List[ComplexTestCase] = []
        self.results: List[TestExecutionResult] = []
        self.logger = logging.getLogger(__name__)
        self.temp_dir = None
        self._initialize_test_cases()
    
    def _initialize_test_cases(self):
        """åˆå§‹åŒ–æµ‹è¯•ç”¨ä¾‹"""
        # ç®€åŒ–çš„æµ‹è¯•ç”¨ä¾‹ï¼Œé¿å…å¤æ‚çš„ä¾èµ–
        self._add_basic_tests()
    
    def _add_basic_tests(self):
        """æ·»åŠ åŸºç¡€æµ‹è¯•ç”¨ä¾‹"""
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        self.test_cases.append(ComplexTestCase(
            name="basic_image_processing",
            path_type=TestPathType.NORMAL,
            severity=TestSeverity.MEDIUM,
            description="åŸºç¡€å›¾åƒå¤„ç†æµ‹è¯•",
            test_function=self._test_basic_image_processing,
            timeout=30.0
        ))
        
        # å†…å­˜å‹åŠ›æµ‹è¯•
        self.test_cases.append(ComplexTestCase(
            name="memory_stress_test",
            path_type=TestPathType.STRESS_PATH,
            severity=TestSeverity.HIGH,
            description="å†…å­˜å‹åŠ›æµ‹è¯•",
            test_function=self._test_memory_stress,
            timeout=60.0
        ))
        
        # å¹¶å‘æµ‹è¯•
        self.test_cases.append(ComplexTestCase(
            name="concurrent_processing",
            path_type=TestPathType.CONCURRENT_ACCESS,
            severity=TestSeverity.HIGH,
            description="å¹¶å‘å¤„ç†æµ‹è¯•",
            test_function=self._test_concurrent_processing,
            timeout=45.0
        ))
        
        # é”™è¯¯å¤„ç†æµ‹è¯•
        self.test_cases.append(ComplexTestCase(
            name="error_handling_test",
            path_type=TestPathType.ERROR_PATH,
            severity=TestSeverity.CRITICAL,
            description="é”™è¯¯å¤„ç†æµ‹è¯•",
            test_function=self._test_error_handling,
            expected_exceptions=[Exception],
            timeout=30.0
        ))
    
    def _test_basic_image_processing(self) -> Dict[str, Any]:
        """åŸºç¡€å›¾åƒå¤„ç†æµ‹è¯•"""
        results = {'images_processed': 0, 'processing_times': []}
        
        try:
            for i in range(10):
                start_time = time.time()
                
                # ç”Ÿæˆæµ‹è¯•å›¾åƒ
                image = MockDataGenerator.generate_test_image()
                
                # åŸºç¡€å¤„ç†
                resized = cv2.resize(image, (640, 640))
                blurred = cv2.GaussianBlur(resized, (5, 5), 0)
                
                end_time = time.time()
                processing_time = (end_time - start_time) * 1000  # ms
                
                results['images_processed'] += 1
                results['processing_times'].append(processing_time)
                
                # æ¸…ç†
                del image, resized, blurred
        
        except Exception as e:
            results['error'] = str(e)
            raise
        
        return results
    
    def _test_memory_stress(self) -> Dict[str, Any]:
        """å†…å­˜å‹åŠ›æµ‹è¯•"""
        results = {'peak_memory': 0, 'operations': 0, 'memory_cleaned': False}
        
        try:
            memory_hogs = []
            
            # é€æ­¥å¢åŠ å†…å­˜ä½¿ç”¨
            for i in range(15):
                # åˆ›å»ºå¤§å‹æ•°ç»„
                large_array = np.random.random((1000, 1000)).astype(np.float32)
                memory_hogs.append(large_array)
                
                # è®°å½•å†…å­˜ä½¿ç”¨
                current_memory = psutil.Process().memory_info().rss / 1024 / 1024
                results['peak_memory'] = max(results['peak_memory'], current_memory)
                results['operations'] += 1
                
                # æ£€æŸ¥å†…å­˜é™åˆ¶
                if current_memory > 800:  # 800MBé™åˆ¶
                    break
            
            # æ¸…ç†å†…å­˜
            del memory_hogs
            gc.collect()
            results['memory_cleaned'] = True
        
        except Exception as e:
            results['error'] = str(e)
            raise
        
        return results
    
    def _test_concurrent_processing(self) -> Dict[str, Any]:
        """å¹¶å‘å¤„ç†æµ‹è¯•"""
        results = {'threads_completed': 0, 'total_operations': 0, 'errors': 0}
        
        def worker_function(thread_id):
            try:
                for i in range(20):
                    # æ¨¡æ‹Ÿå¤„ç†
                    image = MockDataGenerator.generate_test_image(320, 240)
                    processed = cv2.resize(image, (160, 120))
                    results['total_operations'] += 1
                    time.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                return True
            except Exception:
                results['errors'] += 1
                return False
        
        try:
            # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
            threads = []
            thread_count = 4
            
            for i in range(thread_count):
                thread = threading.Thread(target=lambda tid=i: worker_function(tid))
                threads.append(thread)
                thread.start()
            
            # ç­‰å¾…å®Œæˆ
            for thread in threads:
                thread.join()
                results['threads_completed'] += 1
        
        except Exception as e:
            results['error'] = str(e)
            raise
        
        return results
    
    def _test_error_handling(self) -> Dict[str, Any]:
        """é”™è¯¯å¤„ç†æµ‹è¯•"""
        results = {'exceptions_handled': 0, 'recovery_successful': 0}
        
        try:
            for i in range(5):
                try:
                    # æ•…æ„å¼•å‘é”™è¯¯
                    if i % 2 == 0:
                        raise ValueError(f"æµ‹è¯•é”™è¯¯ {i}")
                    
                    # æ­£å¸¸å¤„ç†
                    image = MockDataGenerator.generate_test_image()
                    processed = cv2.resize(image, (640, 640))
                    
                except Exception as e:
                    results['exceptions_handled'] += 1
                    
                    # æ¨¡æ‹Ÿæ¢å¤
                    try:
                        default_image = np.zeros((640, 640, 3), dtype=np.uint8)
                        results['recovery_successful'] += 1
                    except:
                        pass
        
        except Exception as e:
            results['error'] = str(e)
            # å¯¹äºè¿™ä¸ªæµ‹è¯•ï¼Œå¼‚å¸¸æ˜¯é¢„æœŸçš„
            pass
        
        return results
    
    @contextmanager
    def _setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp(prefix="yolos_test_")
        
        try:
            yield self.temp_dir
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if self.temp_dir and os.path.exists(self.temp_dir):
                shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def execute_test_case(self, test_case: ComplexTestCase) -> TestExecutionResult:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        self.logger.info(f"å¼€å§‹æ‰§è¡Œæµ‹è¯•: {test_case.name}")
        
        monitor = ResourceMonitor()
        start_time = time.time()
        
        try:
            with self._setup_test_environment():
                # è®¾ç½®æµ‹è¯•
                if test_case.setup_function:
                    test_case.setup_function()
                
                # å¼€å§‹ç›‘æ§
                monitor.start_monitoring()
                
                # æ‰§è¡Œæµ‹è¯•
                test_result = test_case.test_function()
                
                # åœæ­¢ç›‘æ§
                resource_metrics = monitor.stop_monitoring()
                
                execution_time = time.time() - start_time
                
                # åˆ›å»ºæˆåŠŸç»“æœ
                result = TestExecutionResult(
                    test_name=test_case.name,
                    success=True,
                    execution_time=execution_time,
                    memory_usage=resource_metrics['memory_usage_mb'],
                    cpu_usage=resource_metrics['cpu_percent'],
                    performance_metrics=test_result,
                    resource_usage=resource_metrics
                )
        
        except Exception as e:
            execution_time = time.time() - start_time
            resource_metrics = monitor.stop_monitoring()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„æœŸå¼‚å¸¸
            expected = any(isinstance(e, exc_type) for exc_type in test_case.expected_exceptions)
            
            result = TestExecutionResult(
                test_name=test_case.name,
                success=expected,
                execution_time=execution_time,
                memory_usage=resource_metrics['memory_usage_mb'],
                cpu_usage=resource_metrics['cpu_percent'],
                error_message=str(e),
                exception_type=type(e).__name__,
                stack_trace=traceback.format_exc(),
                resource_usage=resource_metrics
            )
        
        finally:
            # æ¸…ç†æµ‹è¯•
            if test_case.teardown_function:
                try:
                    test_case.teardown_function()
                except Exception as cleanup_error:
                    self.logger.warning(f"æµ‹è¯•æ¸…ç†å¤±è´¥: {cleanup_error}")
        
        self.logger.info(f"æµ‹è¯•å®Œæˆ: {test_case.name}, æˆåŠŸ: {result.success}")
        return result
    
    def run_all_tests(self) -> List[TestExecutionResult]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.logger.info(f"å¼€å§‹è¿è¡Œ {len(self.test_cases)} ä¸ªå¤æ‚è·¯å¾„æµ‹è¯•")
        
        results = []
        
        for test_case in self.test_cases:
            try:
                result = self.execute_test_case(test_case)
                results.append(result)
                self.results.append(result)
            except Exception as e:
                self.logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {test_case.name}, é”™è¯¯: {e}")
                # åˆ›å»ºå¤±è´¥ç»“æœ
                failed_result = TestExecutionResult(
                    test_name=test_case.name,
                    success=False,
                    execution_time=0.0,
                    memory_usage=0.0,
                    cpu_usage=0.0,
                    error_message=f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}",
                    exception_type=type(e).__name__
                )
                results.append(failed_result)
                self.results.append(failed_result)
        
        return results
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        if not self.results:
            return {'error': 'æ²¡æœ‰æµ‹è¯•ç»“æœ'}
        
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results if r.success)
        failed_tests = total_tests - successful_tests
        
        # æŒ‰è·¯å¾„ç±»å‹ç»Ÿè®¡
        path_type_stats = {}
        for test_case in self.test_cases:
            path_type = test_case.path_type.value
            if path_type not in path_type_stats:
                path_type_stats[path_type] = {'total': 0, 'passed': 0, 'failed': 0}
            path_type_stats[path_type]['total'] += 1
        
        for result in self.results:
            test_case = next((tc for tc in self.test_cases if tc.name == result.test_name), None)
            if test_case:
                path_type = test_case.path_type.value
                if result.success:
                    path_type_stats[path_type]['passed'] += 1
                else:
                    path_type_stats[path_type]['failed'] += 1
        
        # æ€§èƒ½ç»Ÿè®¡
        execution_times = [r.execution_time for r in self.results]
        memory_usages = [r.memory_usage for r in self.results]
        cpu_usages = [r.cpu_usage for r in self.results]
        
        report = {
            'summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': failed_tests,
                'success_rate': successful_tests / total_tests if total_tests > 0 else 0,
                'total_execution_time': sum(execution_times)
            },
            'path_type_analysis': path_type_stats,
            'performance_metrics': {
                'avg_execution_time': np.mean(execution_times) if execution_times else 0,
                'max_execution_time': max(execution_times) if execution_times else 0,
                'avg_memory_usage': np.mean(memory_usages) if memory_usages else 0,
                'peak_memory_usage': max(memory_usages) if memory_usages else 0,
                'avg_cpu_usage': np.mean(cpu_usages) if cpu_usages else 0
            }
        }
        
        return report
    
    def save_report(self, filename: str = None) -> str:
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'core_function_complex_test_report_{timestamp}.json'
        
        report = self.generate_comprehensive_report()
        
        # æ·»åŠ è¯¦ç»†ç»“æœ
        detailed_results = []
        for result in self.results:
            detailed_results.append({
                'test_name': result.test_name,
                'success': result.success,
                'execution_time': result.execution_time,
                'memory_usage': result.memory_usage,
                'cpu_usage': result.cpu_usage,
                'error_message': result.error_message,
                'performance_metrics': result.performance_metrics,
                'timestamp': result.timestamp.isoformat()
            })
        
        report['detailed_results'] = detailed_results
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        return filename
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        if not self.results:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        report = self.generate_comprehensive_report()
        
        print("\n" + "="*80)
        print("YOLOSæ ¸å¿ƒåŠŸèƒ½å¤æ‚è·¯å¾„æµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        summary = report['summary']
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"   æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        print(f"   å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"   æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.2f}ç§’")
        
        # è·¯å¾„ç±»å‹åˆ†æ
        print(f"\nğŸ›¤ï¸  è·¯å¾„ç±»å‹åˆ†æ:")
        for path_type, stats in report['path_type_analysis'].items():
            success_rate = stats['passed'] / stats['total'] if stats['total'] > 0 else 0
            print(f"   {path_type}: {stats['passed']}/{stats['total']} ({success_rate:.1%})")
        
        # æ€§èƒ½æŒ‡æ ‡
        perf = report['performance_metrics']
        print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {perf['avg_execution_time']:.2f}ç§’")
        print(f"   æœ€å¤§æ‰§è¡Œæ—¶é—´: {perf['max_execution_time']:.2f}ç§’")
        print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {perf['avg_memory_usage']:.1f}MB")
        print(f"   å³°å€¼å†…å­˜ä½¿ç”¨: {perf['peak_memory_usage']:.1f}MB")
        
        print("\n" + "="*80)

def main():
    """ä¸»å‡½æ•°"""
    print("YOLOSæ ¸å¿ƒåŠŸèƒ½å¤æ‚è·¯å¾„æµ‹è¯•å™¨")
    print("ä½œä¸ºèµ„æ·±AIoTæµ‹è¯•ä¸“å®¶ï¼Œæ‰§è¡Œå…¨é¢çš„å¤æ‚è·¯å¾„æµ‹è¯•")
    
    tester = CoreFunctionComplexPathTester()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        print(f"\nå¼€å§‹æ‰§è¡Œ {len(tester.test_cases)} ä¸ªå¤æ‚è·¯å¾„æµ‹è¯•...")
        results = tester.run_all_tests()
        
        # æ‰“å°æ‘˜è¦
        tester.print_summary()
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = tester.save_report()
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return 0 if all(r.success for r in results) else 1
        
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\næµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)