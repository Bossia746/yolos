#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æµ‹è¯• - æœ¬åœ°ç‰ˆæœ¬
ä½¿ç”¨OpenCVå†…ç½®åŠŸèƒ½å’Œæœ¬åœ°æ¨¡å‹è¿›è¡Œæµ‹è¯•
"""

import cv2
import numpy as np
import time
import json
import os
from datetime import datetime
from pathlib import Path
import matplotlib.pyplot as plt

class LocalHandheldObjectTest:
    """æœ¬åœ°æ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•ç³»ç»Ÿ"""
    
    def __init__(self):
        self.output_dir = Path("test_results")
        self.output_dir.mkdir(exist_ok=True)
        
        # æµ‹è¯•é…ç½®
        self.test_config = {
            "test_name": "YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æµ‹è¯•",
            "test_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "test_images": 5,
            "detection_methods": ["Haarçº§è”", "è½®å»“æ£€æµ‹", "è¾¹ç¼˜æ£€æµ‹", "ç‰¹å¾ç‚¹æ£€æµ‹"]
        }
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.detectors = {}
        self.results = {}
        
        print("ğŸ¯ YOLOSæœ¬åœ°æ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æµ‹è¯•")
        print("=" * 80)
        print("ğŸ“ ä½¿ç”¨OpenCVå†…ç½®åŠŸèƒ½è¿›è¡Œå¤šç§æ£€æµ‹æ–¹æ³•æ¼”ç¤º")
        print("ğŸ¨ å±•ç¤ºé¡¹ç›®çš„å›¾åƒå¤„ç†å’Œåˆ†æèƒ½åŠ›")
        print("=" * 80)
    
    def initialize_detectors(self):
        """åˆå§‹åŒ–å„ç§æ£€æµ‹å™¨"""
        print("ğŸ¤– åˆå§‹åŒ–æ£€æµ‹å™¨...")
        
        # 1. Haarçº§è”æ£€æµ‹å™¨ (äººè„¸æ£€æµ‹ä½œä¸ºç¤ºä¾‹)
        try:
            face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            self.detectors['face'] = cv2.CascadeClassifier(face_cascade_path)
            print("âœ… Haarçº§è”äººè„¸æ£€æµ‹å™¨å·²åŠ è½½")
        except Exception as e:
            print(f"âš ï¸ Haarçº§è”æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
        
        # 2. ORBç‰¹å¾æ£€æµ‹å™¨
        try:
            self.detectors['orb'] = cv2.ORB_create()
            print("âœ… ORBç‰¹å¾æ£€æµ‹å™¨å·²åŠ è½½")
        except Exception as e:
            print(f"âš ï¸ ORBæ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
        
        # 3. SIFTç‰¹å¾æ£€æµ‹å™¨ (å¦‚æœå¯ç”¨)
        try:
            self.detectors['sift'] = cv2.SIFT_create()
            print("âœ… SIFTç‰¹å¾æ£€æµ‹å™¨å·²åŠ è½½")
        except Exception as e:
            print(f"âš ï¸ SIFTæ£€æµ‹å™¨ä¸å¯ç”¨: {e}")
        
        # 4. è¾¹ç¼˜æ£€æµ‹å™¨ (Canny)
        self.detectors['canny'] = True
        print("âœ… Cannyè¾¹ç¼˜æ£€æµ‹å™¨å·²å‡†å¤‡")
        
        # 5. è½®å»“æ£€æµ‹å™¨
        self.detectors['contour'] = True
        print("âœ… è½®å»“æ£€æµ‹å™¨å·²å‡†å¤‡")
    
    def generate_test_images(self):
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        print("\nğŸ–¼ï¸ ç”Ÿæˆæµ‹è¯•å›¾åƒ...")
        
        test_images = []
        
        for i in range(self.test_config["test_images"]):
            # åˆ›å»ºä¸åŒç±»å‹çš„æµ‹è¯•å›¾åƒ
            if i == 0:
                # å‡ ä½•å›¾å½¢
                img = self.create_geometric_shapes()
                name = "geometric_shapes"
            elif i == 1:
                # æ–‡å­—å›¾åƒ
                img = self.create_text_image()
                name = "text_image"
            elif i == 2:
                # å™ªå£°å›¾åƒ
                img = self.create_noise_image()
                name = "noise_image"
            elif i == 3:
                # æ¸å˜å›¾åƒ
                img = self.create_gradient_image()
                name = "gradient_image"
            else:
                # å¤åˆå›¾åƒ
                img = self.create_complex_image()
                name = "complex_image"
            
            # ä¿å­˜å›¾åƒ
            img_path = self.output_dir / f"test_{name}_{i+1}.jpg"
            cv2.imwrite(str(img_path), img)
            
            test_images.append({
                'image': img,
                'path': img_path,
                'name': name,
                'index': i+1
            })
            
            print(f"âœ… ç”Ÿæˆæµ‹è¯•å›¾åƒ {i+1}: {name}")
        
        return test_images
    
    def create_geometric_shapes(self):
        """åˆ›å»ºå‡ ä½•å›¾å½¢æµ‹è¯•å›¾åƒ"""
        img = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # ç»˜åˆ¶å„ç§å‡ ä½•å›¾å½¢
        cv2.rectangle(img, (50, 50), (150, 150), (0, 255, 0), 2)
        cv2.circle(img, (300, 100), 50, (255, 0, 0), 2)
        cv2.ellipse(img, (500, 100), (60, 40), 0, 0, 360, (0, 0, 255), 2)
        
        # ç»˜åˆ¶å¤šè¾¹å½¢
        pts = np.array([[100, 200], [150, 300], [50, 300]], np.int32)
        cv2.polylines(img, [pts], True, (255, 255, 0), 2)
        
        # ç»˜åˆ¶çº¿æ¡
        cv2.line(img, (200, 200), (400, 300), (255, 0, 255), 2)
        
        return img
    
    def create_text_image(self):
        """åˆ›å»ºæ–‡å­—æµ‹è¯•å›¾åƒ"""
        img = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ ä¸åŒå¤§å°å’Œå­—ä½“çš„æ–‡å­—
        cv2.putText(img, 'YOLOS TEST', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)
        cv2.putText(img, 'Object Detection', (50, 200), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 255), 2)
        cv2.putText(img, 'Computer Vision', (50, 300), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (255, 0, 255), 2)
        cv2.putText(img, '2024', (50, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 0), 2)
        
        return img
    
    def create_noise_image(self):
        """åˆ›å»ºå™ªå£°æµ‹è¯•å›¾åƒ"""
        # ç”Ÿæˆéšæœºå™ªå£°
        noise = np.random.randint(0, 256, (480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ ä¸€äº›ç»“æ„åŒ–å…ƒç´ 
        cv2.rectangle(noise, (200, 150), (400, 350), (255, 255, 255), -1)
        cv2.circle(noise, (300, 250), 50, (0, 0, 0), -1)
        
        return noise
    
    def create_gradient_image(self):
        """åˆ›å»ºæ¸å˜æµ‹è¯•å›¾åƒ"""
        img = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # åˆ›å»ºæ°´å¹³æ¸å˜
        for x in range(640):
            intensity = int(255 * x / 640)
            img[:, x] = [intensity, intensity, intensity]
        
        # æ·»åŠ ä¸€äº›å¯¹è±¡
        cv2.circle(img, (160, 120), 60, (255, 0, 0), -1)
        cv2.circle(img, (320, 240), 80, (0, 255, 0), -1)
        cv2.circle(img, (480, 360), 70, (0, 0, 255), -1)
        
        return img
    
    def create_complex_image(self):
        """åˆ›å»ºå¤åˆæµ‹è¯•å›¾åƒ"""
        img = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # èƒŒæ™¯æ¸å˜
        for y in range(480):
            for x in range(640):
                img[y, x] = [int(255 * x / 640), int(255 * y / 480), 128]
        
        # æ·»åŠ å¤šç§å…ƒç´ 
        cv2.rectangle(img, (100, 100), (200, 200), (255, 255, 255), 3)
        cv2.circle(img, (400, 150), 50, (0, 0, 0), 3)
        cv2.ellipse(img, (300, 350), (80, 50), 45, 0, 360, (255, 255, 0), 3)
        
        # æ·»åŠ æ–‡å­—
        cv2.putText(img, 'COMPLEX', (450, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        return img
    
    def detect_objects(self, test_images):
        """å¯¹æµ‹è¯•å›¾åƒè¿›è¡Œç‰©ä½“æ£€æµ‹"""
        print("\nğŸ” å¼€å§‹ç‰©ä½“æ£€æµ‹åˆ†æ...")
        
        all_results = []
        
        for img_data in test_images:
            img = img_data['image']
            img_name = img_data['name']
            
            print(f"\nğŸ“¸ åˆ†æå›¾åƒ: {img_name}")
            
            result = {
                'image_name': img_name,
                'image_path': str(img_data['path']),
                'detections': {},
                'performance': {},
                'statistics': {}
            }
            
            # 1. Haarçº§è”æ£€æµ‹
            if 'face' in self.detectors:
                start_time = time.time()
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                faces = self.detectors['face'].detectMultiScale(gray, 1.1, 4)
                detection_time = time.time() - start_time
                
                result['detections']['haar_faces'] = len(faces)
                result['performance']['haar_time'] = detection_time
                print(f"  ğŸ‘¤ Haarçº§è”æ£€æµ‹: {len(faces)} ä¸ªäººè„¸, è€—æ—¶: {detection_time:.3f}s")
            
            # 2. ORBç‰¹å¾ç‚¹æ£€æµ‹
            if 'orb' in self.detectors:
                start_time = time.time()
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                keypoints = self.detectors['orb'].detect(gray, None)
                detection_time = time.time() - start_time
                
                result['detections']['orb_keypoints'] = len(keypoints)
                result['performance']['orb_time'] = detection_time
                print(f"  ğŸ¯ ORBç‰¹å¾ç‚¹: {len(keypoints)} ä¸ª, è€—æ—¶: {detection_time:.3f}s")
            
            # 3. SIFTç‰¹å¾ç‚¹æ£€æµ‹
            if 'sift' in self.detectors:
                start_time = time.time()
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                keypoints = self.detectors['sift'].detect(gray, None)
                detection_time = time.time() - start_time
                
                result['detections']['sift_keypoints'] = len(keypoints)
                result['performance']['sift_time'] = detection_time
                print(f"  ğŸ” SIFTç‰¹å¾ç‚¹: {len(keypoints)} ä¸ª, è€—æ—¶: {detection_time:.3f}s")
            
            # 4. Cannyè¾¹ç¼˜æ£€æµ‹
            start_time = time.time()
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            edge_pixels = np.sum(edges > 0)
            detection_time = time.time() - start_time
            
            result['detections']['edge_pixels'] = int(edge_pixels)
            result['performance']['canny_time'] = detection_time
            print(f"  ğŸ“ è¾¹ç¼˜åƒç´ : {edge_pixels} ä¸ª, è€—æ—¶: {detection_time:.3f}s")
            
            # 5. è½®å»“æ£€æµ‹
            start_time = time.time()
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            detection_time = time.time() - start_time
            
            result['detections']['contours'] = len(contours)
            result['performance']['contour_time'] = detection_time
            print(f"  ğŸ”„ è½®å»“æ•°é‡: {len(contours)} ä¸ª, è€—æ—¶: {detection_time:.3f}s")
            
            # 6. å›¾åƒç»Ÿè®¡ä¿¡æ¯
            result['statistics'] = {
                'mean_brightness': float(np.mean(gray)),
                'std_brightness': float(np.std(gray)),
                'min_brightness': int(np.min(gray)),
                'max_brightness': int(np.max(gray)),
                'image_size': f"{img.shape[1]}x{img.shape[0]}",
                'total_pixels': int(img.shape[0] * img.shape[1])
            }
            
            all_results.append(result)
        
        return all_results
    
    def create_visualization(self, test_images, results):
        """åˆ›å»ºå¯è§†åŒ–ç»“æœ"""
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        
        # åˆ›å»ºæ£€æµ‹ç»“æœå¯è§†åŒ–å›¾åƒ
        for i, (img_data, result) in enumerate(zip(test_images, results)):
            img = img_data['image'].copy()
            
            # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
            if 'orb' in self.detectors:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                keypoints = self.detectors['orb'].detect(gray, None)
                img = cv2.drawKeypoints(img, keypoints, None, color=(0, 255, 0), flags=0)
            
            # ç»˜åˆ¶è¾¹ç¼˜
            gray = cv2.cvtColor(img_data['image'], cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            img[edges > 0] = [0, 0, 255]  # çº¢è‰²è¾¹ç¼˜
            
            # ä¿å­˜å¯è§†åŒ–ç»“æœ
            vis_path = self.output_dir / f"visualization_{i+1}_{img_data['name']}.jpg"
            cv2.imwrite(str(vis_path), img)
            print(f"âœ… ä¿å­˜å¯è§†åŒ–ç»“æœ: {vis_path.name}")
        
        # åˆ›å»ºæ€§èƒ½åˆ†æå›¾è¡¨
        self.create_performance_charts(results)
    
    def create_performance_charts(self, results):
        """åˆ›å»ºæ€§èƒ½åˆ†æå›¾è¡¨"""
        print("ğŸ“ˆ ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨...")
        
        # æå–æ€§èƒ½æ•°æ®
        methods = []
        times = []
        
        for result in results:
            for method, time_val in result['performance'].items():
                methods.append(f"{result['image_name']}_{method}")
                times.append(time_val)
        
        if times:
            # åˆ›å»ºæ€§èƒ½å›¾è¡¨
            plt.figure(figsize=(12, 8))
            
            # å­å›¾1: æ£€æµ‹æ—¶é—´
            plt.subplot(2, 2, 1)
            plt.bar(range(len(times)), times)
            plt.title('æ£€æµ‹æ–¹æ³•æ€§èƒ½å¯¹æ¯”')
            plt.ylabel('æ—¶é—´ (ç§’)')
            plt.xticks(range(len(times)), methods, rotation=45, ha='right')
            
            # å­å›¾2: ç‰¹å¾ç‚¹æ•°é‡å¯¹æ¯”
            plt.subplot(2, 2, 2)
            orb_counts = [r['detections'].get('orb_keypoints', 0) for r in results]
            sift_counts = [r['detections'].get('sift_keypoints', 0) for r in results]
            image_names = [r['image_name'] for r in results]
            
            x = np.arange(len(image_names))
            width = 0.35
            
            plt.bar(x - width/2, orb_counts, width, label='ORBç‰¹å¾ç‚¹')
            plt.bar(x + width/2, sift_counts, width, label='SIFTç‰¹å¾ç‚¹')
            plt.title('ç‰¹å¾ç‚¹æ£€æµ‹å¯¹æ¯”')
            plt.ylabel('ç‰¹å¾ç‚¹æ•°é‡')
            plt.xticks(x, image_names, rotation=45, ha='right')
            plt.legend()
            
            # å­å›¾3: è¾¹ç¼˜åƒç´ ç»Ÿè®¡
            plt.subplot(2, 2, 3)
            edge_pixels = [r['detections'].get('edge_pixels', 0) for r in results]
            plt.bar(image_names, edge_pixels, color='red', alpha=0.7)
            plt.title('è¾¹ç¼˜åƒç´ ç»Ÿè®¡')
            plt.ylabel('è¾¹ç¼˜åƒç´ æ•°é‡')
            plt.xticks(rotation=45, ha='right')
            
            # å­å›¾4: è½®å»“æ•°é‡
            plt.subplot(2, 2, 4)
            contour_counts = [r['detections'].get('contours', 0) for r in results]
            plt.bar(image_names, contour_counts, color='green', alpha=0.7)
            plt.title('è½®å»“æ£€æµ‹ç»Ÿè®¡')
            plt.ylabel('è½®å»“æ•°é‡')
            plt.xticks(rotation=45, ha='right')
            
            plt.tight_layout()
            chart_path = self.output_dir / "performance_analysis.png"
            plt.savefig(chart_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… æ€§èƒ½åˆ†æå›¾è¡¨å·²ä¿å­˜: {chart_path.name}")
    
    def generate_report(self, results):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        report = {
            "test_info": self.test_config,
            "system_info": {
                "opencv_version": cv2.__version__,
                "test_time": datetime.now().isoformat(),
                "total_images": len(results),
                "detection_methods": len(self.detectors)
            },
            "results": results,
            "summary": {
                "total_detections": sum(sum(r['detections'].values()) for r in results),
                "average_processing_time": np.mean([sum(r['performance'].values()) for r in results]),
                "fastest_method": min(results, key=lambda x: min(x['performance'].values()))['image_name'],
                "most_features": max(results, key=lambda x: x['detections'].get('orb_keypoints', 0))['image_name']
            }
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_path = self.output_dir / "test_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        md_report = self.create_markdown_report(report)
        md_path = self.output_dir / "test_report.md"
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_report)
        
        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   ğŸ“„ JSONæŠ¥å‘Š: {report_path.name}")
        print(f"   ğŸ“ MarkdownæŠ¥å‘Š: {md_path.name}")
        
        return report
    
    def create_markdown_report(self, report):
        """åˆ›å»ºMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        md = f"""# {report['test_info']['test_name']}

## æµ‹è¯•æ¦‚è§ˆ
- **æµ‹è¯•æ—¶é—´**: {report['test_info']['test_date']}
- **OpenCVç‰ˆæœ¬**: {report['system_info']['opencv_version']}
- **æµ‹è¯•å›¾åƒæ•°é‡**: {report['system_info']['total_images']}
- **æ£€æµ‹æ–¹æ³•æ•°é‡**: {report['system_info']['detection_methods']}

## æµ‹è¯•ç»“æœæ‘˜è¦
- **æ€»æ£€æµ‹æ•°é‡**: {report['summary']['total_detections']}
- **å¹³å‡å¤„ç†æ—¶é—´**: {report['summary']['average_processing_time']:.3f}ç§’
- **æœ€å¿«å¤„ç†å›¾åƒ**: {report['summary']['fastest_method']}
- **æœ€å¤šç‰¹å¾ç‚¹å›¾åƒ**: {report['summary']['most_features']}

## è¯¦ç»†ç»“æœ

"""
        
        for i, result in enumerate(report['results'], 1):
            md += f"""### å›¾åƒ {i}: {result['image_name']}

**æ£€æµ‹ç»“æœ**:
"""
            for method, count in result['detections'].items():
                md += f"- {method}: {count}\n"
            
            md += f"""
**æ€§èƒ½æ•°æ®**:
"""
            for method, time_val in result['performance'].items():
                md += f"- {method}: {time_val:.3f}ç§’\n"
            
            md += f"""
**å›¾åƒç»Ÿè®¡**:
- å¹³å‡äº®åº¦: {result['statistics']['mean_brightness']:.2f}
- äº®åº¦æ ‡å‡†å·®: {result['statistics']['std_brightness']:.2f}
- å›¾åƒå°ºå¯¸: {result['statistics']['image_size']}
- æ€»åƒç´ æ•°: {result['statistics']['total_pixels']}

"""
        
        md += """## æµ‹è¯•è¯´æ˜

æœ¬æµ‹è¯•å±•ç¤ºäº†YOLOSé¡¹ç›®çš„å›¾åƒå¤„ç†å’Œåˆ†æèƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š

1. **Haarçº§è”æ£€æµ‹**: ç”¨äºäººè„¸ç­‰ç‰¹å®šå¯¹è±¡æ£€æµ‹
2. **ORBç‰¹å¾æ£€æµ‹**: å¿«é€Ÿç‰¹å¾ç‚¹æ£€æµ‹å’Œæè¿°
3. **SIFTç‰¹å¾æ£€æµ‹**: é«˜è´¨é‡ç‰¹å¾ç‚¹æ£€æµ‹
4. **Cannyè¾¹ç¼˜æ£€æµ‹**: è¾¹ç¼˜æå–å’Œåˆ†æ
5. **è½®å»“æ£€æµ‹**: å½¢çŠ¶å’Œç»“æ„åˆ†æ

æµ‹è¯•ä½¿ç”¨äº†å¤šç§ç±»å‹çš„å›¾åƒæ¥è¯„ä¼°ä¸åŒæ£€æµ‹æ–¹æ³•çš„æ€§èƒ½å’Œå‡†ç¡®æ€§ã€‚
"""
        
        return md
    
    def run_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æœ¬åœ°æµ‹è¯•")
        
        # 1. åˆå§‹åŒ–æ£€æµ‹å™¨
        self.initialize_detectors()
        
        # 2. ç”Ÿæˆæµ‹è¯•å›¾åƒ
        test_images = self.generate_test_images()
        
        # 3. æ‰§è¡Œæ£€æµ‹
        results = self.detect_objects(test_images)
        
        # 4. åˆ›å»ºå¯è§†åŒ–
        self.create_visualization(test_images, results)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(results)
        
        # 6. æ˜¾ç¤ºæ€»ç»“
        self.display_summary(report)
        
        return report
    
    def display_summary(self, report):
        """æ˜¾ç¤ºæµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 80)
        print("ğŸ‰ YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æµ‹è¯•å®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
        print(f"   â€¢ å¤„ç†å›¾åƒ: {report['system_info']['total_images']} å¼ ")
        print(f"   â€¢ æ£€æµ‹æ–¹æ³•: {report['system_info']['detection_methods']} ç§")
        print(f"   â€¢ æ€»æ£€æµ‹æ•°: {report['summary']['total_detections']}")
        print(f"   â€¢ å¹³å‡è€—æ—¶: {report['summary']['average_processing_time']:.3f}ç§’")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   â€¢ æµ‹è¯•å›¾åƒ: {self.output_dir}/test_*.jpg")
        print(f"   â€¢ å¯è§†åŒ–ç»“æœ: {self.output_dir}/visualization_*.jpg")
        print(f"   â€¢ æ€§èƒ½å›¾è¡¨: {self.output_dir}/performance_analysis.png")
        print(f"   â€¢ æµ‹è¯•æŠ¥å‘Š: {self.output_dir}/test_report.md")
        print("=" * 80)

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test_system = LocalHandheldObjectTest()
        
        # è¿è¡Œæµ‹è¯•
        report = test_system.run_test()
        
        print("\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()