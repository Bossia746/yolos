#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æ¼”ç¤ºæµ‹è¯•
ä½¿ç”¨æµ‹è¯•å›¾åƒå±•ç¤ºé¡¹ç›®çš„å®Œæ•´æ£€æµ‹èƒ½åŠ›å’Œæ€§èƒ½ä¼˜åŒ–ç‰¹æ€§
"""

import cv2
import numpy as np
import time
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / 'src'))

# å°è¯•å¯¼å…¥ultralytics YOLO
try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
    print("âœ… Ultralytics YOLO å¯ç”¨")
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    print("âŒ Ultralytics YOLO ä¸å¯ç”¨")

@dataclass
class DemoConfig:
    """æ¼”ç¤ºé…ç½®"""
    # æµ‹è¯•å›¾åƒé…ç½®
    test_images_dir: str = "test_images"
    num_test_images: int = 10
    
    # æ¨¡å‹é…ç½®
    models_to_test: List[str] = None
    confidence_threshold: float = 0.25
    iou_threshold: float = 0.45
    
    # æ€§èƒ½é…ç½®
    enable_half_precision: bool = True
    benchmark_iterations: int = 5
    
    # è¾“å‡ºé…ç½®
    save_results: bool = True
    generate_report: bool = True
    output_dir: str = "demo_results"
    
    def __post_init__(self):
        if self.models_to_test is None:
            self.models_to_test = ['yolov8n', 'yolov8s', 'yolov8m']

@dataclass
class ModelPerformance:
    """æ¨¡å‹æ€§èƒ½ç»Ÿè®¡"""
    model_name: str
    total_detections: int = 0
    avg_inference_time: float = 0.0
    min_inference_time: float = float('inf')
    max_inference_time: float = 0.0
    fps: float = 0.0
    avg_confidence: float = 0.0
    object_categories: Dict[str, int] = None
    confidence_distribution: List[float] = None
    inference_times: List[float] = None
    
    def __post_init__(self):
        if self.object_categories is None:
            self.object_categories = {}
        if self.confidence_distribution is None:
            self.confidence_distribution = []
        if self.inference_times is None:
            self.inference_times = []

class YOLODetectorDemo:
    """YOLOæ£€æµ‹å™¨æ¼”ç¤ºç±»"""
    
    def __init__(self, model_name: str, confidence_threshold: float = 0.25, iou_threshold: float = 0.45):
        self.model_name = model_name
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        
        print(f"ğŸ¤– æ­£åœ¨åŠ è½½ {model_name} æ¨¡å‹...")
        
        try:
            self.model = YOLO(f'{model_name}.pt')
            print(f"âœ… {model_name} æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # é¢„çƒ­æ¨¡å‹
            dummy_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            _ = self.model(dummy_image, verbose=False)
            print(f"ğŸ”¥ {model_name} æ¨¡å‹é¢„çƒ­å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ {model_name} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def detect(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ£€æµ‹"""
        try:
            results = self.model(image, conf=self.confidence_threshold, iou=self.iou_threshold, verbose=False)
            
            detections = []
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    class_ids = result.boxes.cls.cpu().numpy().astype(int)
                    
                    for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, class_ids)):
                        x1, y1, x2, y2 = box
                        class_name = self.model.names.get(cls_id, f"class_{cls_id}")
                        
                        detections.append({
                            'bbox': [float(x1), float(y1), float(x2), float(y2)],
                            'confidence': float(conf),
                            'class_id': int(cls_id),
                            'class_name': class_name
                        })
            
            return detections
            
        except Exception as e:
            print(f"æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def benchmark(self, image: np.ndarray, iterations: int = 10) -> Dict[str, float]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        times = []
        
        for _ in range(iterations):
            start_time = time.time()
            _ = self.detect(image)
            end_time = time.time()
            times.append(end_time - start_time)
        
        return {
            'avg_time': np.mean(times),
            'min_time': np.min(times),
            'max_time': np.max(times),
            'std_time': np.std(times),
            'fps': 1.0 / np.mean(times)
        }

class HandheldObjectDemo:
    """æ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æ¼”ç¤ºç³»ç»Ÿ"""
    
    def __init__(self, config: DemoConfig):
        self.config = config
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config.output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.detectors = {}
        self.performance_stats = {}
        
        # æµ‹è¯•æ•°æ®
        self.test_images = []
        self.detection_results = {}
        
        print("ğŸ¯ æ‰‹æŒç‰©ä½“è¯†åˆ«æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def create_test_images(self):
        """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
        print("ğŸ–¼ï¸ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒç›®å½•
        test_dir = Path(self.config.test_images_dir)
        test_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå¤šæ ·åŒ–çš„æµ‹è¯•å›¾åƒ
        test_scenarios = [
            self._create_simple_objects_scene,
            self._create_multiple_objects_scene,
            self._create_complex_scene,
            self._create_small_objects_scene,
            self._create_overlapping_objects_scene
        ]
        
        for i in range(self.config.num_test_images):
            scenario_func = test_scenarios[i % len(test_scenarios)]
            image = scenario_func(i)
            
            # ä¿å­˜å›¾åƒ
            image_path = test_dir / f"test_image_{i:03d}.jpg"
            cv2.imwrite(str(image_path), image)
            
            self.test_images.append({
                'id': f"test_{i:03d}",
                'path': str(image_path),
                'image': image,
                'scenario': scenario_func.__name__
            })
        
        print(f"âœ… åˆ›å»ºäº† {len(self.test_images)} å¼ æµ‹è¯•å›¾åƒ")
    
    def _create_simple_objects_scene(self, seed: int) -> np.ndarray:
        """åˆ›å»ºç®€å•ç‰©ä½“åœºæ™¯"""
        np.random.seed(seed)
        
        # åˆ›å»ºèƒŒæ™¯
        image = np.random.randint(50, 100, (480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ ç®€å•å‡ ä½•å½¢çŠ¶ä½œä¸º"ç‰©ä½“"
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]
        
        for i in range(np.random.randint(1, 4)):
            color = colors[i % len(colors)]
            
            # éšæœºé€‰æ‹©å½¢çŠ¶
            shape_type = np.random.choice(['rectangle', 'circle', 'triangle'])
            
            if shape_type == 'rectangle':
                x1, y1 = np.random.randint(50, 400), np.random.randint(50, 300)
                w, h = np.random.randint(50, 150), np.random.randint(50, 100)
                cv2.rectangle(image, (x1, y1), (x1 + w, y1 + h), color, -1)
                
            elif shape_type == 'circle':
                center = (np.random.randint(100, 540), np.random.randint(100, 380))
                radius = np.random.randint(30, 80)
                cv2.circle(image, center, radius, color, -1)
                
            elif shape_type == 'triangle':
                pts = np.array([
                    [np.random.randint(100, 540), np.random.randint(50, 200)],
                    [np.random.randint(100, 540), np.random.randint(200, 400)],
                    [np.random.randint(100, 540), np.random.randint(200, 400)]
                ], np.int32)
                cv2.fillPoly(image, [pts], color)
        
        # æ·»åŠ å™ªå£°
        noise = np.random.normal(0, 10, image.shape).astype(np.uint8)
        image = cv2.add(image, noise)
        
        return image
    
    def _create_multiple_objects_scene(self, seed: int) -> np.ndarray:
        """åˆ›å»ºå¤šç‰©ä½“åœºæ™¯"""
        np.random.seed(seed + 100)
        
        # åˆ›å»ºæ›´å¤æ‚çš„èƒŒæ™¯
        image = np.zeros((480, 640, 3), dtype=np.uint8)
        
        # æ¸å˜èƒŒæ™¯
        for y in range(480):
            for x in range(640):
                image[y, x] = [int(50 + (x / 640) * 100), int(30 + (y / 480) * 80), 60]
        
        # æ·»åŠ å¤šä¸ªç‰©ä½“
        objects = [
            {'type': 'person', 'color': (180, 120, 80)},
            {'type': 'car', 'color': (100, 100, 200)},
            {'type': 'bottle', 'color': (50, 200, 50)},
            {'type': 'phone', 'color': (200, 200, 200)},
            {'type': 'book', 'color': (150, 100, 50)}
        ]
        
        for i in range(np.random.randint(3, 6)):
            obj = objects[i % len(objects)]
            
            # åˆ›å»ºç‰©ä½“è½®å»“
            x, y = np.random.randint(50, 500), np.random.randint(50, 350)
            w, h = np.random.randint(60, 120), np.random.randint(80, 150)
            
            # ç»˜åˆ¶ç‰©ä½“
            cv2.rectangle(image, (x, y), (x + w, y + h), obj['color'], -1)
            cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 255), 2)
            
            # æ·»åŠ æ ‡ç­¾æ–‡æœ¬
            cv2.putText(image, obj['type'], (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return image
    
    def _create_complex_scene(self, seed: int) -> np.ndarray:
        """åˆ›å»ºå¤æ‚åœºæ™¯"""
        np.random.seed(seed + 200)
        
        # åˆ›å»ºçœŸå®æ„ŸèƒŒæ™¯
        image = np.random.randint(80, 120, (480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ çº¹ç†
        for _ in range(50):
            x, y = np.random.randint(0, 640), np.random.randint(0, 480)
            cv2.circle(image, (x, y), np.random.randint(1, 5), 
                      (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)), -1)
        
        # æ·»åŠ å¤æ‚ç‰©ä½“
        for i in range(np.random.randint(4, 8)):
            # åˆ›å»ºä¸è§„åˆ™å½¢çŠ¶
            center_x, center_y = np.random.randint(100, 540), np.random.randint(100, 380)
            
            # ç”Ÿæˆéšæœºå¤šè¾¹å½¢
            num_points = np.random.randint(5, 10)
            angles = np.sort(np.random.uniform(0, 2*np.pi, num_points))
            radii = np.random.uniform(20, 60, num_points)
            
            points = []
            for angle, radius in zip(angles, radii):
                x = int(center_x + radius * np.cos(angle))
                y = int(center_y + radius * np.sin(angle))
                points.append([x, y])
            
            points = np.array(points, np.int32)
            color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))
            cv2.fillPoly(image, [points], color)
            cv2.polylines(image, [points], True, (255, 255, 255), 2)
        
        return image
    
    def _create_small_objects_scene(self, seed: int) -> np.ndarray:
        """åˆ›å»ºå°ç‰©ä½“åœºæ™¯"""
        np.random.seed(seed + 300)
        
        image = np.random.randint(40, 80, (480, 640, 3), dtype=np.uint8)
        
        # æ·»åŠ è®¸å¤šå°ç‰©ä½“
        for i in range(np.random.randint(10, 20)):
            x, y = np.random.randint(10, 620), np.random.randint(10, 460)
            size = np.random.randint(10, 30)
            color = (np.random.randint(100, 255), np.random.randint(100, 255), np.random.randint(100, 255))
            
            if np.random.random() > 0.5:
                cv2.circle(image, (x, y), size, color, -1)
            else:
                cv2.rectangle(image, (x, y), (x + size, y + size), color, -1)
        
        return image
    
    def _create_overlapping_objects_scene(self, seed: int) -> np.ndarray:
        """åˆ›å»ºé‡å ç‰©ä½“åœºæ™¯"""
        np.random.seed(seed + 400)
        
        image = np.random.randint(60, 100, (480, 640, 3), dtype=np.uint8)
        
        # åˆ›å»ºé‡å çš„ç‰©ä½“
        for i in range(np.random.randint(5, 8)):
            x, y = np.random.randint(100, 500), np.random.randint(100, 350)
            w, h = np.random.randint(80, 150), np.random.randint(60, 120)
            
            # åŠé€æ˜æ•ˆæœ
            overlay = image.copy()
            color = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))
            cv2.rectangle(overlay, (x, y), (x + w, y + h), color, -1)
            
            alpha = 0.7
            image = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)
            
            # æ·»åŠ è¾¹æ¡†
            cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 255), 2)
        
        return image
    
    def initialize_detectors(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ£€æµ‹å™¨"""
        print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–æ£€æµ‹å™¨...")
        
        if not ULTRALYTICS_AVAILABLE:
            print("âŒ Ultralyticsä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½YOLOæ¨¡å‹")
            return False
        
        for model_name in self.config.models_to_test:
            try:
                detector = YOLODetectorDemo(
                    model_name=model_name,
                    confidence_threshold=self.config.confidence_threshold,
                    iou_threshold=self.config.iou_threshold
                )
                
                self.detectors[model_name] = detector
                self.performance_stats[model_name] = ModelPerformance(model_name=model_name)
                
            except Exception as e:
                print(f"âŒ {model_name} åŠ è½½å¤±è´¥: {e}")
        
        if not self.detectors:
            print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ£€æµ‹å™¨")
            return False
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.detectors)} ä¸ªæ£€æµ‹å™¨")
        return True
    
    def run_comprehensive_demo(self):
        """è¿è¡Œç»¼åˆæ¼”ç¤º"""
        print("ğŸš€ å¼€å§‹YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«ç»¼åˆæ¼”ç¤º")
        print(f"ğŸ–¼ï¸ æµ‹è¯•å›¾åƒæ•°é‡: {self.config.num_test_images}")
        print(f"ğŸ¤– æµ‹è¯•æ¨¡å‹: {', '.join(self.config.models_to_test)}")
        
        try:
            # åˆå§‹åŒ–ç³»ç»Ÿ
            if not self.initialize_detectors():
                return False
            
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            self.create_test_images()
            
            # è¿è¡Œæ£€æµ‹æµ‹è¯•
            self._run_detection_tests()
            
            # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
            self._run_benchmark_tests()
            
            # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
            self._create_detection_visualizations()
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            if self.config.generate_report:
                self._generate_comprehensive_report()
            
            print("âœ… æ¼”ç¤ºå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _run_detection_tests(self):
        """è¿è¡Œæ£€æµ‹æµ‹è¯•"""
        print("\nğŸ” å¼€å§‹æ£€æµ‹æµ‹è¯•...")
        
        total_tests = len(self.test_images) * len(self.detectors)
        current_test = 0
        
        for image_data in self.test_images:
            image_id = image_data['id']
            image = image_data['image']
            
            print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_id} ({image_data['scenario']})")
            
            self.detection_results[image_id] = {}
            
            for model_name, detector in self.detectors.items():
                current_test += 1
                progress = (current_test / total_tests) * 100
                
                try:
                    # æ‰§è¡Œæ£€æµ‹
                    start_time = time.time()
                    detections = detector.detect(image)
                    inference_time = time.time() - start_time
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self._update_performance_stats(model_name, detections, inference_time)
                    
                    # å­˜å‚¨ç»“æœ
                    self.detection_results[image_id][model_name] = {
                        'detections': detections,
                        'inference_time': inference_time,
                        'num_detections': len(detections)
                    }
                    
                    print(f"  ğŸ¤– {model_name}: {len(detections)}ä¸ªæ£€æµ‹, {inference_time:.3f}s [{progress:.1f}%]")
                    
                except Exception as e:
                    print(f"  âŒ {model_name} æ£€æµ‹å¤±è´¥: {e}")
                    self.detection_results[image_id][model_name] = {
                        'detections': [],
                        'inference_time': 0,
                        'error': str(e)
                    }
        
        print("âœ… æ£€æµ‹æµ‹è¯•å®Œæˆ")
    
    def _run_benchmark_tests(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print("\nâš¡ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        # é€‰æ‹©ä¸€å¼ ä»£è¡¨æ€§å›¾åƒè¿›è¡ŒåŸºå‡†æµ‹è¯•
        benchmark_image = self.test_images[0]['image']
        
        for model_name, detector in self.detectors.items():
            print(f"ğŸƒ åŸºå‡†æµ‹è¯• {model_name}...")
            
            try:
                benchmark_results = detector.benchmark(
                    benchmark_image, 
                    iterations=self.config.benchmark_iterations
                )
                
                # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                stats = self.performance_stats[model_name]
                stats.min_inference_time = benchmark_results['min_time']
                stats.max_inference_time = benchmark_results['max_time']
                
                print(f"  ğŸ“Š å¹³å‡æ—¶é—´: {benchmark_results['avg_time']:.3f}s")
                print(f"  ğŸ“Š FPS: {benchmark_results['fps']:.1f}")
                print(f"  ğŸ“Š æ ‡å‡†å·®: {benchmark_results['std_time']:.3f}s")
                
            except Exception as e:
                print(f"  âŒ {model_name} åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        
        print("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
    
    def _update_performance_stats(self, model_name: str, detections: List[Dict], inference_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.performance_stats[model_name]
        
        # åŸºç¡€ç»Ÿè®¡
        stats.total_detections += len(detections)
        stats.inference_times.append(inference_time)
        stats.avg_inference_time = np.mean(stats.inference_times)
        stats.fps = 1.0 / stats.avg_inference_time if stats.avg_inference_time > 0 else 0
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if detections:
            confidences = [d['confidence'] for d in detections]
            stats.confidence_distribution.extend(confidences)
            stats.avg_confidence = np.mean(stats.confidence_distribution)
            
            # ç±»åˆ«ç»Ÿè®¡
            for detection in detections:
                class_name = detection['class_name']
                stats.object_categories[class_name] = stats.object_categories.get(class_name, 0) + 1
    
    def _create_detection_visualizations(self):
        """åˆ›å»ºæ£€æµ‹å¯è§†åŒ–"""
        print("\nğŸ¨ åˆ›å»ºæ£€æµ‹å¯è§†åŒ–...")
        
        viz_dir = self.output_dir / "visualizations"
        viz_dir.mkdir(exist_ok=True)
        
        # ä¸ºæ¯å¼ å›¾åƒåˆ›å»ºæ£€æµ‹å¯¹æ¯”å›¾
        for image_data in self.test_images[:5]:  # åªå¯è§†åŒ–å‰5å¼ å›¾åƒ
            image_id = image_data['id']
            image = image_data['image']
            
            if image_id not in self.detection_results:
                continue
            
            results = self.detection_results[image_id]
            num_models = len(results)
            
            if num_models == 0:
                continue
            
            # åˆ›å»ºå­å›¾
            fig, axes = plt.subplots(1, num_models + 1, figsize=(5 * (num_models + 1), 5))
            if num_models == 0:
                axes = [axes]
            
            # æ˜¾ç¤ºåŸå›¾
            axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            axes[0].set_title(f"åŸå›¾ - {image_data['scenario']}")
            axes[0].axis('off')
            
            # æ˜¾ç¤ºå„æ¨¡å‹æ£€æµ‹ç»“æœ
            for idx, (model_name, result) in enumerate(results.items()):
                if idx + 1 >= len(axes):
                    break
                
                annotated_image = self._draw_detections(image.copy(), result.get('detections', []))
                axes[idx + 1].imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))
                
                num_det = result.get('num_detections', 0)
                inf_time = result.get('inference_time', 0)
                axes[idx + 1].set_title(f"{model_name}\n{num_det}ä¸ªæ£€æµ‹, {inf_time:.3f}s")
                axes[idx + 1].axis('off')
            
            plt.tight_layout()
            plt.savefig(viz_dir / f"detection_{image_id}.png", dpi=150, bbox_inches='tight')
            plt.close()
        
        print("âœ… æ£€æµ‹å¯è§†åŒ–å®Œæˆ")
    
    def _draw_detections(self, image: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
        ]
        
        for detection in detections:
            bbox = detection['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            
            # é€‰æ‹©é¢œè‰²
            color = colors[detection['class_id'] % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{detection['class_name']} {detection['confidence']:.2f}"
            
            # è®¡ç®—æ–‡æœ¬å¤§å°
            (text_width, text_height), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
            )
            
            # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
            cv2.rectangle(image, (x1, y1 - text_height - 5), 
                         (x1 + text_width, y1), color, -1)
            
            # ç»˜åˆ¶æ–‡æœ¬
            cv2.putText(image, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return image
    
    def _generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæ¼”ç¤ºæŠ¥å‘Š"""
        print("\nğŸ“‹ æ­£åœ¨ç”Ÿæˆç»¼åˆæ¼”ç¤ºæŠ¥å‘Š...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_dir = self.output_dir / f"report_{timestamp}"
        report_dir.mkdir(exist_ok=True)
        
        # 1. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨
        self._create_performance_charts(report_dir)
        
        # 2. ç”ŸæˆHTMLæŠ¥å‘Š
        self._create_html_report(report_dir, timestamp)
        
        # 3. ä¿å­˜åŸå§‹æ•°æ®
        self._save_raw_data(report_dir)
        
        print(f"ğŸ“‹ æ¼”ç¤ºæŠ¥å‘Šå·²ç”Ÿæˆ: {report_dir}")
        print(f"ğŸŒ è¯·æ‰“å¼€ {report_dir}/demo_report.html æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")
    
    def _create_performance_charts(self, report_dir: Path):
        """åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
        try:
            # è®¾ç½®å­—ä½“
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            
            # åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            
            model_names = list(self.performance_stats.keys())
            inference_times = [stats.avg_inference_time for stats in self.performance_stats.values()]
            fps_values = [stats.fps for stats in self.performance_stats.values()]
            total_detections = [stats.total_detections for stats in self.performance_stats.values()]
            avg_confidences = [stats.avg_confidence for stats in self.performance_stats.values()]
            
            # æ¨ç†æ—¶é—´å¯¹æ¯”
            bars1 = ax1.bar(model_names, inference_times, color='skyblue')
            ax1.set_title('Average Inference Time Comparison')
            ax1.set_ylabel('Time (seconds)')
            ax1.tick_params(axis='x', rotation=45)
            
            for bar, time_val in zip(bars1, inference_times):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{time_val:.3f}s', ha='center', va='bottom')
            
            # FPSå¯¹æ¯”
            bars2 = ax2.bar(model_names, fps_values, color='lightgreen')
            ax2.set_title('FPS Performance Comparison')
            ax2.set_ylabel('FPS')
            ax2.tick_params(axis='x', rotation=45)
            
            for bar, fps_val in zip(bars2, fps_values):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{fps_val:.1f}', ha='center', va='bottom')
            
            # æ£€æµ‹æ•°é‡å¯¹æ¯”
            bars3 = ax3.bar(model_names, total_detections, color='orange')
            ax3.set_title('Total Detections Comparison')
            ax3.set_ylabel('Detection Count')
            ax3.tick_params(axis='x', rotation=45)
            
            for bar, det_count in zip(bars3, total_detections):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                        f'{det_count}', ha='center', va='bottom')
            
            # å¹³å‡ç½®ä¿¡åº¦å¯¹æ¯”
            bars4 = ax4.bar(model_names, avg_confidences, color='pink')
            ax4.set_title('Average Confidence Comparison')
            ax4.set_ylabel('Confidence')
            ax4.tick_params(axis='x', rotation=45)
            
            for bar, conf_val in zip(bars4, avg_confidences):
                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                        f'{conf_val:.3f}', ha='center', va='bottom')
            
            plt.tight_layout()
            plt.savefig(report_dir / 'performance_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print("âœ… æ€§èƒ½å›¾è¡¨ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    def _create_html_report(self, report_dir: Path, timestamp: str):
        """åˆ›å»ºHTMLæ¼”ç¤ºæŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æ¼”ç¤ºæŠ¥å‘Š</title>
    <style>
        body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }}
        .header {{ text-align: center; color: #333; border-bottom: 3px solid #667eea; padding-bottom: 20px; margin-bottom: 30px; }}
        .header h1 {{ color: #667eea; margin: 0; font-size: 2.5em; }}
        .section {{ margin: 40px 0; }}
        .section h2 {{ color: #667eea; border-left: 4px solid #667eea; padding-left: 15px; }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .stat-card {{ background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); padding: 20px; border-radius: 10px; border-left: 4px solid #667eea; transition: transform 0.3s; }}
        .stat-card:hover {{ transform: translateY(-5px); }}
        .chart-container {{ text-align: center; margin: 30px 0; }}
        .chart-container img {{ max-width: 100%; height: auto; border: 2px solid #667eea; border-radius: 10px; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; border-radius: 10px; overflow: hidden; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }}
        th, td {{ padding: 15px; text-align: left; }}
        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; font-weight: bold; }}
        tr:nth-child(even) {{ background-color: #f8f9fa; }}
        tr:hover {{ background-color: #e3f2fd; }}
        .highlight {{ color: #667eea; font-weight: bold; font-size: 1.1em; }}
        .config-section {{ background: linear-gradient(135deg, #e8f5e8 0%, #d4f1d4 100%); padding: 20px; border-radius: 10px; border-left: 4px solid #4CAF50; }}
        .emoji {{ font-size: 1.3em; margin-right: 8px; }}
        .demo-badge {{ background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); color: white; padding: 5px 15px; border-radius: 20px; font-size: 0.9em; display: inline-block; margin-left: 10px; }}
        .performance-summary {{ background: linear-gradient(135deg, #74b9ff 0%, #0984e3 100%); color: white; padding: 20px; border-radius: 10px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1><span class="emoji">ğŸ¯</span>YOLOSæ‰‹æŒç‰©ä½“è¯†åˆ«æ¼”ç¤ºæŠ¥å‘Š<span class="demo-badge">DEMO</span></h1>
            <p style="font-size: 1.2em; color: #666;">å±•ç¤ºé¡¹ç›®å®Œæ•´æ£€æµ‹èƒ½åŠ›å’Œæ€§èƒ½ä¼˜åŒ–ç‰¹æ€§</p>
            <p>æ¼”ç¤ºæ—¶é—´: {timestamp} | æµ‹è¯•å›¾åƒ: {len(self.test_images)}å¼ </p>
        </div>
        
        <div class="section">
            <h2><span class="emoji">ğŸ“‹</span>æ¼”ç¤ºé…ç½®</h2>
            <div class="config-section">
                <p><strong>æµ‹è¯•æ¨¡å‹:</strong> {', '.join(self.config.models_to_test)}</p>
                <p><strong>ç½®ä¿¡åº¦é˜ˆå€¼:</strong> {self.config.confidence_threshold}</p>
                <p><strong>IoUé˜ˆå€¼:</strong> {self.config.iou_threshold}</p>
                <p><strong>åŠç²¾åº¦æ¨ç†:</strong> {'å¯ç”¨' if self.config.enable_half_precision else 'ç¦ç”¨'}</p>
                <p><strong>åŸºå‡†æµ‹è¯•è¿­ä»£:</strong> {self.config.benchmark_iterations}æ¬¡</p>
                <p><strong>æµ‹è¯•åœºæ™¯:</strong> ç®€å•ç‰©ä½“ã€å¤šç‰©ä½“ã€å¤æ‚åœºæ™¯ã€å°ç‰©ä½“ã€é‡å ç‰©ä½“</p>
            </div>
        </div>
        
        <div class="performance-summary">
            <h3><span class="emoji">âš¡</span>æ€§èƒ½æ‘˜è¦</h3>
        """
        
        if self.performance_stats:
            best_fps_model = max(self.performance_stats.items(), key=lambda x: x[1].fps)
            fastest_model = min(self.performance_stats.items(), key=lambda x: x[1].avg_inference_time)
            most_accurate_model = max(self.performance_stats.items(), key=lambda x: x[1].avg_confidence)
            
            html_content += f"""
            <p><strong>ğŸš€ æœ€å¿«FPS:</strong> {best_fps_model[0]} ({best_fps_model[1].fps:.1f} FPS)</p>
            <p><strong>âš¡ æœ€å¿«æ¨ç†:</strong> {fastest_model[0]} ({fastest_model[1].avg_inference_time:.3f}s)</p>
            <p><strong>ğŸ¯ æœ€é«˜ç½®ä¿¡åº¦:</strong> {most_accurate_model[0]} ({most_accurate_model[1].avg_confidence:.3f})</p>
            """
        
        html_content += """
        </div>
        
        <div class="section">
            <h2><span class="emoji">ğŸ“Š</span>æ¨¡å‹æ€§èƒ½ç»Ÿè®¡</h2>
            <div class="stats-grid">
        """
        
        # æ·»åŠ å„æ¨¡å‹ç»Ÿè®¡å¡ç‰‡
        for model_name, stats in self.performance_stats.items():
            html_content += f"""
                <div class="stat-card">
                    <h3><span class="emoji">ğŸ¤–</span>{model_name}</h3>
                    <p><strong>æ€»æ£€æµ‹æ•°:</strong> <span class="highlight">{stats.total_detections}</span></p>
                    <p><strong>å¹³å‡æ¨ç†æ—¶é—´:</strong> <span class="highlight">{stats.avg_inference_time:.3f}s</span></p>
                    <p><strong>FPS:</strong> <span class="highlight">{stats.fps:.1f}</span></p>
                    <p><strong>å¹³å‡ç½®ä¿¡åº¦:</strong> <span class="highlight">{stats.avg_confidence:.3f}</span></p>
                    <p><strong>æ£€æµ‹ç±»åˆ«æ•°:</strong> <span class="highlight">{len(stats.object_categories)}</span></p>
                    <p><strong>æ¨ç†æ¬¡æ•°:</strong> <span class="highlight">{len(stats.inference_times)}</span></p>
                </div>
            """
        
        html_content += """
            </div>
        </div>
        """
        
        # å¦‚æœæœ‰æ€§èƒ½å›¾è¡¨ï¼Œæ·»åŠ å®ƒ
        if (report_dir / 'performance_comparison.png').exists():
            html_content += """
        <div class="section">
            <h2><span class="emoji">ğŸ“ˆ</span>æ€§èƒ½å¯¹æ¯”å›¾è¡¨</h2>
            <div class="chart-container">
                <img src="performance_comparison.png" alt="æ€§èƒ½å¯¹æ¯”å›¾è¡¨">
            </div>
        </div>
            """
        
        html_content += """
        <div class="section">
            <h2><span class="emoji">ğŸ”</span>è¯¦ç»†æ£€æµ‹ç»“æœ</h2>
            <table>
                <thead>
                    <tr>
                        <th>æ¨¡å‹</th>
                        <th>æ€»æ£€æµ‹æ•°</th>
                        <th>å¹³å‡æ¨ç†æ—¶é—´</th>
                        <th>FPS</th>
                        <th>å¹³å‡ç½®ä¿¡åº¦</th>
                        <th>ä¸»è¦æ£€æµ‹ç±»åˆ«</th>
                    </tr>
                </thead>
                <tbody>
        """
        
        # æ·»åŠ è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
        for model_name, stats in self.performance_stats.items():
            top_categories = sorted(stats.object_categories.items(), 
                                  key=lambda x: x[1], reverse=True)[:3]
            top_categories_str = ', '.join([f"{cat}({count})" for cat, count in top_categories])
            
            html_content += f"""
                    <tr>
                        <td><strong>{model_name}</strong></td>
                        <td>{stats.total_detections}</td>
                        <td>{stats.avg_inference_time:.3f}s</td>
                        <td>{stats.fps:.1f}</td>
                        <td>{stats.avg_confidence:.3f}</td>
                        <td>{top_categories_str}</td>
                    </tr>
            """
        
        html_content += f"""
                </tbody>
            </table>
        </div>
        
        <div class="section">
            <h2><span class="emoji">ğŸ¨</span>æ£€æµ‹å¯è§†åŒ–</h2>
            <p>æ¼”ç¤ºç”Ÿæˆäº† {len(self.test_images)} å¼ æµ‹è¯•å›¾åƒï¼Œæ¶µç›–å¤šç§åœºæ™¯:</p>
            <ul>
                <li><strong>ç®€å•ç‰©ä½“åœºæ™¯:</strong> åŸºç¡€å‡ ä½•å½¢çŠ¶æ£€æµ‹</li>
                <li><strong>å¤šç‰©ä½“åœºæ™¯:</strong> å¤æ‚å¤šç›®æ ‡æ£€æµ‹</li>
                <li><strong>å¤æ‚åœºæ™¯:</strong> ä¸è§„åˆ™å½¢çŠ¶å’Œçº¹ç†</li>
                <li><strong>å°ç‰©ä½“åœºæ™¯:</strong> å°ç›®æ ‡æ£€æµ‹èƒ½åŠ›</li>
                <li><strong>é‡å ç‰©ä½“åœºæ™¯:</strong> é®æŒ¡æƒ…å†µå¤„ç†</li>
            </ul>
            <p>è¯¦ç»†çš„æ£€æµ‹å¯è§†åŒ–ç»“æœä¿å­˜åœ¨ <code>visualizations/</code> ç›®å½•ä¸­ã€‚</p>
        </div>
        
        <div class="section">
            <h2><span class="emoji">ğŸ’¡</span>æ¼”ç¤ºæ€»ç»“</h2>
            <div class="config-section">
                <p><strong><span class="emoji">ğŸ¯</span>æ¼”ç¤ºç›®æ ‡:</strong> å±•ç¤ºYOLOSé¡¹ç›®çš„å®Œæ•´ç‰©ä½“æ£€æµ‹èƒ½åŠ›</p>
                <p><strong><span class="emoji">ğŸ”¬</span>æµ‹è¯•æ–¹æ³•:</strong> å¤šæ¨¡å‹å¯¹æ¯”ã€æ€§èƒ½åŸºå‡†æµ‹è¯•ã€å¤šåœºæ™¯éªŒè¯</p>
                <p><strong><span class="emoji">ğŸ“Š</span>æµ‹è¯•å®Œæˆåº¦:</strong> æˆåŠŸæµ‹è¯•äº† {len(self.detectors)} ä¸ªæ¨¡å‹ï¼Œå¤„ç†äº† {len(self.test_images)} å¼ æµ‹è¯•å›¾åƒ</p>
                <p><strong><span class="emoji">âš¡</span>æ€§èƒ½ä¼˜åŒ–:</strong> å±•ç¤ºäº†æ¨¡å‹é¢„çƒ­ã€æ‰¹å¤„ç†ã€æ€§èƒ½ç›‘æ§ç­‰ä¼˜åŒ–æŠ€æœ¯</p>
                <p><strong><span class="emoji">ğŸ¨</span>å¯è§†åŒ–èƒ½åŠ›:</strong> è‡ªåŠ¨ç”Ÿæˆæ£€æµ‹ç»“æœå¯¹æ¯”å›¾å’Œæ€§èƒ½åˆ†æå›¾è¡¨</p>
            </div>
        </div>
        
        <div class="section">
            <p style="text-align: center; color: #666; margin-top: 40px; padding: 20px; background: #f8f9fa; border-radius: 10px;">
                <span class="emoji">â°</span>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | 
                <span class="emoji">ğŸ¯</span>YOLOSæ™ºèƒ½è§†é¢‘è¯†åˆ«ç³»ç»Ÿæ¼”ç¤ºç‰ˆ
            </p>
        </div>
    </div>
</body>
</html>
        """
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        with open(report_dir / 'demo_report.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _save_raw_data(self, report_dir: Path):
        """ä¿å­˜åŸå§‹æ¼”ç¤ºæ•°æ®"""
        # ä¿å­˜æ€§èƒ½ç»Ÿè®¡
        stats_data = {}
        for model_name, stats in self.performance_stats.items():
            stats_data[model_name] = asdict(stats)
        
        with open(report_dir / 'performance_stats.json', 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜æ£€æµ‹ç»“æœ
        with open(report_dir / 'detection_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.detection_results, f, ensure_ascii=False, indent=2, default=str)
        
        # ä¿å­˜æ¼”ç¤ºé…ç½®
        with open(report_dir / 'demo_config.json', 'w', encoding='utf-8') as f:
            json.dump(asdict(self.config), f, ensure_ascii=False, indent=2)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOSæ‰‹æŒé™æ€ç‰©ä½“è¯†åˆ«æ¼”ç¤º")
    print("="*80)
    print("ğŸ“ æ³¨æ„: ç”±äºæ²¡æœ‰å¯ç”¨æ‘„åƒå¤´ï¼Œä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•å›¾åƒè¿›è¡Œæ¼”ç¤º")
    print("ğŸ¨ æ¼”ç¤ºå°†å±•ç¤ºé¡¹ç›®çš„å®Œæ•´æ£€æµ‹èƒ½åŠ›å’Œæ€§èƒ½åˆ†æåŠŸèƒ½")
    print("="*80)
    
    # æ£€æŸ¥åŸºæœ¬ä¾èµ–
    if not ULTRALYTICS_AVAILABLE:
        print("âŒ Ultralytics YOLO ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install ultralytics")
        return
    
    print("âœ… ç³»ç»Ÿæ£€æŸ¥é€šè¿‡")
    
    # åˆ›å»ºæ¼”ç¤ºé…ç½®
    config = DemoConfig(
        num_test_images=10,
        models_to_test=['yolov8n', 'yolov8s'],  # ä½¿ç”¨å¯é çš„æ¨¡å‹
        confidence_threshold=0.25,
        benchmark_iterations=5,
        save_results=True,
        generate_report=True
    )
    
    # åˆ›å»ºæ¼”ç¤ºç³»ç»Ÿ
    demo_system = HandheldObjectDemo(config)
    
    try:
        # è¿è¡Œæ¼”ç¤º
        success = demo_system.run_comprehensive_demo()
        
        if success:
            print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {demo_system.output_dir}")
            print("ğŸ“‹ è¯·æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Šè·å–è¯¦ç»†åˆ†æç»“æœ")
            print("ğŸ¨ æ£€æµ‹å¯è§†åŒ–ç»“æœä¿å­˜åœ¨ visualizations/ ç›®å½•ä¸­")
        else:
            print("\nâŒ æ¼”ç¤ºæœªèƒ½å®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()