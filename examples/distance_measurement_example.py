#!/usr/bin/env python3
"""è·ç¦»æµ‹é‡åŠŸèƒ½ç¤ºä¾‹ä»£ç 

æœ¬ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨YOLOSè·ç¦»æµ‹é‡åŠŸèƒ½çš„å„ç§ç”¨æ³•ï¼š
1. åŸºç¡€è·ç¦»æµ‹é‡
2. å®æ—¶è·ç¦»æµ‹é‡
3. ç›¸æœºæ ‡å®š
4. æ‰¹é‡å›¾åƒå¤„ç†
"""

import cv2
import numpy as np
import os
import sys
from pathlib import Path
import time

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from recognition.distance_estimator import DistanceEstimator, RealTimeDistanceEstimator
from recognition.enhanced_object_detector import EnhancedObjectDetector
from recognition.camera_calibration_tool import CameraCalibrationTool


def example_1_basic_distance_measurement():
    """ç¤ºä¾‹1: åŸºç¡€è·ç¦»æµ‹é‡"""
    print("\n=== ç¤ºä¾‹1: åŸºç¡€è·ç¦»æµ‹é‡ ===")
    
    # åˆ›å»ºè·ç¦»ä¼°ç®—å™¨
    estimator = DistanceEstimator()
    
    # è®¾ç½®ç„¦è·ï¼ˆè¿™é‡Œä½¿ç”¨ç¤ºä¾‹å€¼ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ‡å®šï¼‰
    estimator.focal_length = 500.0
    print(f"ä½¿ç”¨ç„¦è·: {estimator.focal_length}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒï¼ˆæ¨¡æ‹ŸA4çº¸ï¼‰
    test_image = create_test_image_with_a4_paper()
    
    # æµ‹é‡A4çº¸çš„è·ç¦»
    known_width = 21.0  # A4çº¸å®½åº¦ (cm)
    result = estimator.estimate_distance(test_image, known_width)
    
    if result:
        print(f"âœ… æ£€æµ‹æˆåŠŸ!")
        print(f"   è·ç¦»: {result['distance']:.1f} cm")
        print(f"   åƒç´ å®½åº¦: {result['pixel_width']:.1f} pixels")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
        print(f"   è¾¹ç•Œæ¡†: {result['bbox']}")
        
        # ä¿å­˜ç»“æœå›¾åƒ
        result_image = estimator.draw_results(test_image, [result])
        cv2.imwrite('example_1_result.jpg', result_image)
        print(f"   ç»“æœå›¾åƒå·²ä¿å­˜: example_1_result.jpg")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°ç›®æ ‡ç‰©ä½“")


def example_2_real_time_measurement():
    """ç¤ºä¾‹2: å®æ—¶è·ç¦»æµ‹é‡"""
    print("\n=== ç¤ºä¾‹2: å®æ—¶è·ç¦»æµ‹é‡ ===")
    print("æŒ‰ 'q' é”®é€€å‡ºï¼ŒæŒ‰ 's' é”®æˆªå›¾")
    
    # åˆ›å»ºå®æ—¶ä¼°ç®—å™¨
    real_time_estimator = RealTimeDistanceEstimator()
    real_time_estimator.focal_length = 500.0
    
    # å°è¯•æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œä½¿ç”¨æµ‹è¯•å›¾åƒä»£æ›¿")
        # ä½¿ç”¨æµ‹è¯•å›¾åƒæ¨¡æ‹Ÿå®æ—¶æµ‹é‡
        test_image = create_test_image_with_a4_paper()
        result_frame = real_time_estimator.process_frame(test_image, known_width=21.0)
        cv2.imshow('Real-time Distance Measurement (Test Image)', result_frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return
    
    print("âœ… æ‘„åƒå¤´å·²æ‰“å¼€ï¼Œå¼€å§‹å®æ—¶æµ‹é‡...")
    
    frame_count = 0
    screenshot_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
            break
        
        # å®æ—¶æµ‹è·ï¼ˆå‡è®¾æµ‹é‡A4çº¸ï¼‰
        result_frame = real_time_estimator.process_frame(frame, known_width=21.0)
        
        # æ·»åŠ å¸®åŠ©ä¿¡æ¯
        cv2.putText(result_frame, "Press 'q' to quit, 's' to screenshot", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºç»“æœ
        cv2.imshow('Real-time Distance Measurement', result_frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            screenshot_count += 1
            filename = f'realtime_screenshot_{screenshot_count}.jpg'
            cv2.imwrite(filename, result_frame)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        
        frame_count += 1
        if frame_count % 30 == 0:  # æ¯30å¸§æ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
            stats = real_time_estimator.get_statistics()
            if stats['total_detections'] > 0:
                print(f"ğŸ“Š ç»Ÿè®¡: æ£€æµ‹ {stats['total_detections']} æ¬¡, "
                      f"å¹³å‡è·ç¦» {stats['average_distance']:.1f} cm")
    
    cap.release()
    cv2.destroyAllWindows()
    print("ğŸ å®æ—¶æµ‹é‡ç»“æŸ")


def example_3_camera_calibration():
    """ç¤ºä¾‹3: ç›¸æœºæ ‡å®š"""
    print("\n=== ç¤ºä¾‹3: ç›¸æœºæ ‡å®š ===")
    
    # åˆ›å»ºæ ‡å®šå·¥å…·
    calibration_tool = CameraCalibrationTool()
    
    # æ˜¾ç¤ºæ”¯æŒçš„ç‰©ä½“ç±»å‹
    known_objects = calibration_tool.known_objects
    print(f"æ”¯æŒçš„ç‰©ä½“ç±»å‹: {list(known_objects.keys())}")
    
    # åˆ›å»ºæ ‡å®šå›¾åƒï¼ˆA4çº¸åœ¨30cmè·ç¦»å¤„ï¼‰
    calibration_image = create_calibration_image()
    known_distance = 30.0  # cm
    object_type = 'A4_paper'
    
    print(f"ä½¿ç”¨ {object_type} åœ¨ {known_distance} cm è·ç¦»å¤„è¿›è¡Œæ ‡å®š...")
    
    # æ‰§è¡Œæ ‡å®š
    focal_length = calibration_tool.calibrate_with_known_object(
        calibration_image, object_type, known_distance
    )
    
    if focal_length:
        print(f"âœ… æ ‡å®šæˆåŠŸ!")
        print(f"   è®¡ç®—å¾—åˆ°çš„ç„¦è·: {focal_length:.2f}")
        
        # ä¿å­˜æ ‡å®šç»“æœ
        camera_name = 'example_camera'
        calibration_tool.save_calibration(camera_name, focal_length)
        print(f"   æ ‡å®šç»“æœå·²ä¿å­˜ä¸º: {camera_name}")
        
        # éªŒè¯æ ‡å®š
        verification_result = calibration_tool.verify_calibration(
            calibration_image, object_type, known_distance, focal_length
        )
        
        if verification_result:
            error_percentage = verification_result['error_percentage']
            print(f"   æ ‡å®šéªŒè¯: è¯¯å·® {error_percentage:.1f}%")
            
            if error_percentage < 10:
                print(f"   âœ… æ ‡å®šè´¨é‡: ä¼˜ç§€")
            elif error_percentage < 20:
                print(f"   âš ï¸ æ ‡å®šè´¨é‡: è‰¯å¥½")
            else:
                print(f"   âŒ æ ‡å®šè´¨é‡: éœ€è¦é‡æ–°æ ‡å®š")
    else:
        print("âŒ æ ‡å®šå¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾åƒè´¨é‡")
    
    # æ˜¾ç¤ºæ ‡å®šæ‘˜è¦
    summary = calibration_tool.get_calibration_summary()
    print(f"\nğŸ“Š æ ‡å®šæ‘˜è¦:")
    print(f"   {summary.get('message', 'æ— æ ‡å®šè®°å½•')}")
    if 'calibrations' in summary:
        for name, data in summary['calibrations'].items():
            print(f"   - {name}: ç„¦è· {data['focal_length']:.2f}")


def example_4_batch_processing():
    """ç¤ºä¾‹4: æ‰¹é‡å›¾åƒå¤„ç†"""
    print("\n=== ç¤ºä¾‹4: æ‰¹é‡å›¾åƒå¤„ç† ===")
    
    # åˆ›å»ºè·ç¦»ä¼°ç®—å™¨
    estimator = DistanceEstimator()
    estimator.focal_length = 500.0
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒé›†
    test_images = {
        'close_a4.jpg': (create_test_image_with_a4_paper(distance_simulation='close'), 21.0),
        'medium_a4.jpg': (create_test_image_with_a4_paper(distance_simulation='medium'), 21.0),
        'far_a4.jpg': (create_test_image_with_a4_paper(distance_simulation='far'), 21.0),
    }
    
    print(f"å¤„ç† {len(test_images)} å¼ æµ‹è¯•å›¾åƒ...")
    
    results = []
    
    for filename, (image, known_width) in test_images.items():
        print(f"\nå¤„ç†: {filename}")
        
        # ä¿å­˜æµ‹è¯•å›¾åƒ
        cv2.imwrite(filename, image)
        
        # æµ‹é‡è·ç¦»
        result = estimator.estimate_distance(image, known_width)
        
        if result:
            distance = result['distance']
            confidence = result['confidence']
            print(f"  âœ… è·ç¦»: {distance:.1f} cm, ç½®ä¿¡åº¦: {confidence:.2f}")
            
            # ä¿å­˜ç»“æœå›¾åƒ
            result_image = estimator.draw_results(image, [result])
            result_filename = f"result_{filename}"
            cv2.imwrite(result_filename, result_image)
            
            results.append({
                'filename': filename,
                'distance': distance,
                'confidence': confidence,
                'success': True
            })
        else:
            print(f"  âŒ æ£€æµ‹å¤±è´¥")
            results.append({
                'filename': filename,
                'success': False
            })
    
    # ç»Ÿè®¡ç»“æœ
    successful = sum(1 for r in results if r['success'])
    print(f"\nğŸ“Š æ‰¹é‡å¤„ç†ç»“æœ:")
    print(f"   æˆåŠŸ: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
    
    if successful > 0:
        distances = [r['distance'] for r in results if r['success']]
        avg_distance = sum(distances) / len(distances)
        print(f"   å¹³å‡è·ç¦»: {avg_distance:.1f} cm")
        print(f"   è·ç¦»èŒƒå›´: {min(distances):.1f} - {max(distances):.1f} cm")


def example_5_object_detection_showcase():
    """ç¤ºä¾‹5: ç‰©ä½“æ£€æµ‹åŠŸèƒ½å±•ç¤º"""
    print("\n=== ç¤ºä¾‹5: ç‰©ä½“æ£€æµ‹åŠŸèƒ½å±•ç¤º ===")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = EnhancedObjectDetector()
    
    # åˆ›å»ºåŒ…å«å¤šç§ç‰©ä½“çš„æµ‹è¯•å›¾åƒ
    test_image = create_complex_test_image()
    cv2.imwrite('complex_test_image.jpg', test_image)
    
    print("æµ‹è¯•ä¸åŒçš„æ£€æµ‹æ–¹æ³•...")
    
    # 1. è¾¹ç¼˜æ£€æµ‹
    print("\n1. è¾¹ç¼˜æ£€æµ‹:")
    rectangles = detector.detect_by_edge(test_image, 'rectangle')
    circles = detector.detect_by_edge(test_image, 'circle')
    print(f"   æ£€æµ‹åˆ° {len(rectangles)} ä¸ªçŸ©å½¢")
    print(f"   æ£€æµ‹åˆ° {len(circles)} ä¸ªåœ†å½¢")
    
    # 2. é¢œè‰²æ£€æµ‹
    print("\n2. é¢œè‰²æ£€æµ‹:")
    white_objects = detector.detect_by_color(test_image, 'white')
    red_objects = detector.detect_by_color(test_image, 'red')
    blue_objects = detector.detect_by_color(test_image, 'blue')
    print(f"   æ£€æµ‹åˆ° {len(white_objects)} ä¸ªç™½è‰²ç‰©ä½“")
    print(f"   æ£€æµ‹åˆ° {len(red_objects)} ä¸ªçº¢è‰²ç‰©ä½“")
    print(f"   æ£€æµ‹åˆ° {len(blue_objects)} ä¸ªè“è‰²ç‰©ä½“")
    
    # 3. æœ€å¤§ç‰©ä½“æ£€æµ‹
    print("\n3. æœ€å¤§ç‰©ä½“æ£€æµ‹:")
    largest = detector.detect_largest_object(test_image)
    if largest:
        print(f"   æœ€å¤§ç‰©ä½“é¢ç§¯: {largest['area']:.0f} åƒç´ ")
        print(f"   è¾¹ç•Œæ¡†: {largest['bbox']}")
    
    # 4. å½¢çŠ¶åˆ†æ
    print("\n4. å½¢çŠ¶åˆ†æ:")
    all_detections = rectangles + circles + white_objects
    for i, detection in enumerate(all_detections[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        shape_info = detector.analyze_shape(detection['contour'])
        print(f"   ç‰©ä½“ {i+1}: {shape_info}")
    
    # 5. å¯è§†åŒ–æ‰€æœ‰æ£€æµ‹ç»“æœ
    print("\n5. ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    # åˆ†åˆ«å¯è§†åŒ–ä¸åŒç±»å‹çš„æ£€æµ‹
    edge_result = detector.visualize_detection(test_image.copy(), rectangles + circles, 
                                             color=(0, 255, 0), label_prefix="Edge")
    cv2.imwrite('detection_edge_result.jpg', edge_result)
    
    color_result = detector.visualize_detection(test_image.copy(), white_objects + red_objects, 
                                              color=(255, 0, 0), label_prefix="Color")
    cv2.imwrite('detection_color_result.jpg', color_result)
    
    if largest:
        largest_result = detector.visualize_detection(test_image.copy(), [largest], 
                                                    color=(0, 0, 255), label_prefix="Largest")
        cv2.imwrite('detection_largest_result.jpg', largest_result)
    
    print("   æ£€æµ‹ç»“æœå›¾åƒå·²ä¿å­˜")


def create_test_image_with_a4_paper(distance_simulation='medium'):
    """åˆ›å»ºåŒ…å«A4çº¸çš„æµ‹è¯•å›¾åƒ"""
    # åˆ›å»º800x600çš„å›¾åƒ
    image = np.zeros((600, 800, 3), dtype=np.uint8)
    
    # æ·»åŠ èƒŒæ™¯çº¹ç†
    cv2.rectangle(image, (0, 0), (800, 600), (40, 40, 40), -1)
    
    # æ ¹æ®è·ç¦»æ¨¡æ‹Ÿè°ƒæ•´A4çº¸å¤§å°
    if distance_simulation == 'close':
        paper_width = 420  # æ¨¡æ‹Ÿ15cmè·ç¦»
    elif distance_simulation == 'far':
        paper_width = 210  # æ¨¡æ‹Ÿ60cmè·ç¦»
    else:  # medium
        paper_width = 350  # æ¨¡æ‹Ÿ30cmè·ç¦»
    
    paper_height = int(paper_width * 29.7 / 21)  # ä¿æŒA4æ¯”ä¾‹
    
    x = (800 - paper_width) // 2
    y = (600 - paper_height) // 2
    
    # ç»˜åˆ¶ç™½è‰²A4çº¸
    cv2.rectangle(image, (x, y), (x + paper_width, y + paper_height), (240, 240, 240), -1)
    
    # æ·»åŠ è¾¹æ¡†
    cv2.rectangle(image, (x, y), (x + paper_width, y + paper_height), (200, 200, 200), 2)
    
    # æ·»åŠ æ–‡å­—
    cv2.putText(image, "A4 Paper", (x + 20, y + 40), 
               cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 100, 100), 2)
    
    # æ·»åŠ ä¸€äº›å™ªå£°
    noise = np.random.randint(0, 30, image.shape, dtype=np.uint8)
    image = cv2.add(image, noise)
    
    return image


def create_calibration_image():
    """åˆ›å»ºæ ‡å®šç”¨çš„å›¾åƒ"""
    return create_test_image_with_a4_paper('medium')


def create_complex_test_image():
    """åˆ›å»ºåŒ…å«å¤šç§ç‰©ä½“çš„å¤æ‚æµ‹è¯•å›¾åƒ"""
    # åˆ›å»º1000x800çš„å›¾åƒ
    image = np.zeros((800, 1000, 3), dtype=np.uint8)
    
    # æ·»åŠ æ¸å˜èƒŒæ™¯
    for y in range(800):
        color_value = int(30 + (y / 800) * 50)
        cv2.line(image, (0, y), (1000, y), (color_value, color_value, color_value), 1)
    
    # æ·»åŠ ç™½è‰²çŸ©å½¢ï¼ˆA4çº¸ï¼‰
    cv2.rectangle(image, (100, 100), (350, 400), (240, 240, 240), -1)
    cv2.rectangle(image, (100, 100), (350, 400), (200, 200, 200), 2)
    
    # æ·»åŠ çº¢è‰²åœ†å½¢
    cv2.circle(image, (600, 200), 80, (0, 0, 255), -1)
    cv2.circle(image, (600, 200), 80, (0, 0, 200), 2)
    
    # æ·»åŠ è“è‰²çŸ©å½¢
    cv2.rectangle(image, (700, 400), (900, 600), (255, 0, 0), -1)
    cv2.rectangle(image, (700, 400), (900, 600), (200, 0, 0), 2)
    
    # æ·»åŠ ç»¿è‰²æ¤­åœ†
    cv2.ellipse(image, (300, 600), (100, 60), 0, 0, 360, (0, 255, 0), -1)
    cv2.ellipse(image, (300, 600), (100, 60), 0, 0, 360, (0, 200, 0), 2)
    
    # æ·»åŠ ä¸€äº›å°çš„ç™½è‰²åœ†ç‚¹
    for i in range(10):
        x = np.random.randint(50, 950)
        y = np.random.randint(50, 750)
        radius = np.random.randint(10, 30)
        cv2.circle(image, (x, y), radius, (255, 255, 255), -1)
    
    return image


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸ¯ YOLOS è·ç¦»æµ‹é‡åŠŸèƒ½ç¤ºä¾‹")
    print("æœ¬ç¤ºä¾‹å±•ç¤ºäº†è·ç¦»æµ‹é‡åŠŸèƒ½çš„å„ç§ç”¨æ³•")
    print("=" * 50)
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        example_1_basic_distance_measurement()
        example_3_camera_calibration()
        example_4_batch_processing()
        example_5_object_detection_showcase()
        
        # è¯¢é—®æ˜¯å¦è¿è¡Œå®æ—¶æµ‹é‡ç¤ºä¾‹
        print("\n" + "=" * 50)
        response = input("æ˜¯å¦è¿è¡Œå®æ—¶æµ‹é‡ç¤ºä¾‹ï¼Ÿ(éœ€è¦æ‘„åƒå¤´) [y/N]: ")
        if response.lower() in ['y', 'yes']:
            example_2_real_time_measurement()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        generated_files = [
            'example_1_result.jpg',
            'close_a4.jpg', 'medium_a4.jpg', 'far_a4.jpg',
            'result_close_a4.jpg', 'result_medium_a4.jpg', 'result_far_a4.jpg',
            'complex_test_image.jpg',
            'detection_edge_result.jpg', 'detection_color_result.jpg', 'detection_largest_result.jpg'
        ]
        
        for filename in generated_files:
            if os.path.exists(filename):
                print(f"  âœ… {filename}")
        
        print("\nğŸ’¡ æç¤º:")
        print("  - æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶äº†è§£æ£€æµ‹æ•ˆæœ")
        print("  - è¿è¡Œ GUI ç•Œé¢è¿›è¡Œäº¤äº’å¼æµ‹è¯•")
        print("  - é˜…è¯»ä½¿ç”¨æ–‡æ¡£äº†è§£æ›´å¤šåŠŸèƒ½")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç¤ºä¾‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ è¿è¡Œç¤ºä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()