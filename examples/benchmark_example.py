#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOS åŸºå‡†æµ‹è¯•ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿ
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.benchmark import (
    BenchmarkRunner,
    PerformanceBenchmark,
    BenchmarkConfig,
    BenchmarkType,
    TestScenario
)
from src.detection.feature_aggregation import PlatformType

def run_basic_benchmark():
    """è¿è¡ŒåŸºç¡€åŸºå‡†æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹åŸºç¡€æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # ä½¿ç”¨è¿è¡Œå™¨è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    runner = BenchmarkRunner()
    runner.run_quick_test('desktop')
    
    print("\nâœ… åŸºç¡€æµ‹è¯•å®Œæˆ")

def run_custom_benchmark():
    """è¿è¡Œè‡ªå®šä¹‰åŸºå‡†æµ‹è¯•"""
    print("\nğŸ”§ å¼€å§‹è‡ªå®šä¹‰åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    config = BenchmarkConfig(
        test_types=[
            BenchmarkType.DETECTION_SPEED,
            BenchmarkType.MEMORY_USAGE,
            BenchmarkType.TRACKING_PERFORMANCE
        ],
        test_scenarios=[
            TestScenario.SINGLE_OBJECT,
            TestScenario.MULTI_OBJECT,
            TestScenario.FAST_MOTION
        ],
        target_platforms=[
            PlatformType.DESKTOP
        ],
        test_duration=20,  # 20ç§’æµ‹è¯•
        warmup_duration=3,  # 3ç§’é¢„çƒ­
        output_dir="custom_benchmark_results"
    )
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å™¨
    benchmark = PerformanceBenchmark(config)
    
    # è¿è¡Œæµ‹è¯•
    results = benchmark.run_benchmark()
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•å®Œæˆï¼Œå…± {len(results)} é¡¹æµ‹è¯•")
    for result in results:
        print(f"  - {result.test_type.value} ({result.scenario.value}): "
              f"{result.avg_fps:.1f} FPS, {result.avg_memory_mb:.1f} MB")
    
    print("\nâœ… è‡ªå®šä¹‰æµ‹è¯•å®Œæˆ")

def run_tracking_benchmark():
    """è¿è¡Œè·Ÿè¸ªæ€§èƒ½æµ‹è¯•"""
    print("\nğŸ¯ å¼€å§‹è·Ÿè¸ªæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    runner = BenchmarkRunner()
    runner.run_tracking_test('desktop')
    
    print("\nâœ… è·Ÿè¸ªæµ‹è¯•å®Œæˆ")

def run_aggregation_benchmark():
    """è¿è¡Œèšåˆæ•ˆæœæµ‹è¯•"""
    print("\nğŸ”„ å¼€å§‹èšåˆæ•ˆæœåŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    runner = BenchmarkRunner()
    runner.run_aggregation_test('desktop')
    
    print("\nâœ… èšåˆæµ‹è¯•å®Œæˆ")

def demonstrate_benchmark_features():
    """æ¼”ç¤ºåŸºå‡†æµ‹è¯•åŠŸèƒ½"""
    print("\nğŸª åŸºå‡†æµ‹è¯•åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    print("\nğŸ“‹ å¯ç”¨çš„æµ‹è¯•ç±»å‹:")
    for test_type in BenchmarkType:
        print(f"  - {test_type.value}")
    
    print("\nğŸ¬ å¯ç”¨çš„æµ‹è¯•åœºæ™¯:")
    for scenario in TestScenario:
        print(f"  - {scenario.value}")
    
    print("\nğŸ’» æ”¯æŒçš„å¹³å°:")
    for platform in PlatformType:
        print(f"  - {platform.value}")
    
    print("\nğŸ› ï¸ åŸºå‡†æµ‹è¯•é…ç½®é€‰é¡¹:")
    print("  - test_duration: æµ‹è¯•æŒç»­æ—¶é—´")
    print("  - warmup_duration: é¢„çƒ­æ—¶é—´")
    print("  - sample_interval: é‡‡æ ·é—´éš”")
    print("  - output_dir: è¾“å‡ºç›®å½•")
    print("  - save_plots: ä¿å­˜å›¾è¡¨")
    print("  - generate_report: ç”ŸæˆæŠ¥å‘Š")
    
    print("\nğŸ“ˆ è¾“å‡ºæ–‡ä»¶:")
    print("  - detailed_results.json: è¯¦ç»†æµ‹è¯•ç»“æœ")
    print("  - benchmark_report.md: æµ‹è¯•æŠ¥å‘Š")
    print("  - system_info.json: ç³»ç»Ÿä¿¡æ¯")
    print("  - *.png: æ€§èƒ½å›¾è¡¨")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOS åŸºå‡†æµ‹è¯•ç³»ç»Ÿç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # æ¼”ç¤ºåŠŸèƒ½
        demonstrate_benchmark_features()
        
        # è¿è¡ŒåŸºç¡€æµ‹è¯•
        run_basic_benchmark()
        
        # è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•
        run_custom_benchmark()
        
        # è¿è¡Œè·Ÿè¸ªæµ‹è¯•
        run_tracking_benchmark()
        
        # è¿è¡Œèšåˆæµ‹è¯•
        run_aggregation_benchmark()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æµ‹è¯•å®Œæˆ!")
        print("\nğŸ’¡ æç¤º:")
        print("  - æŸ¥çœ‹ benchmark_results/ ç›®å½•è·å–è¯¦ç»†ç»“æœ")
        print("  - ä½¿ç”¨ benchmark_runner.py è¿›è¡Œå‘½ä»¤è¡Œæµ‹è¯•")
        print("  - æ ¹æ®éœ€è¦è°ƒæ•´æµ‹è¯•é…ç½®å‚æ•°")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()