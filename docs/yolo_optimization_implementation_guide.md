# YOLOä¼˜åŒ–å®æ–½æŒ‡å—

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡ä¸ç­–ç•¥

### ä¼˜åŒ–ç»´åº¦
1. **æ¨ç†é€Ÿåº¦**: é™ä½å»¶è¿Ÿï¼Œæé«˜FPS
2. **æ¨¡å‹ç²¾åº¦**: ä¿æŒæˆ–æå‡æ£€æµ‹å‡†ç¡®ç‡
3. **èµ„æºæ¶ˆè€—**: å‡å°‘å†…å­˜å’Œè®¡ç®—èµ„æºä½¿ç”¨
4. **éƒ¨ç½²æ•ˆç‡**: ä¼˜åŒ–ä¸åŒå¹³å°çš„éƒ¨ç½²æ€§èƒ½

### ä¼˜åŒ–ç­–ç•¥çŸ©é˜µ
| ä¼˜åŒ–æŠ€æœ¯ | é€Ÿåº¦æå‡ | ç²¾åº¦å½±å“ | å†…å­˜èŠ‚çœ | å®æ–½éš¾åº¦ | æ¨èåœºæ™¯ |
|---------|---------|---------|---------|---------|---------|
| YOLOv11å‡çº§ | â­â­â­ | â­â­â­â­ | â­â­ | â­ | æ‰€æœ‰åœºæ™¯ |
| FP16æ¨ç† | â­â­â­ | â­â­â­ | â­â­â­ | â­ | GPUéƒ¨ç½² |
| TensorRTä¼˜åŒ– | â­â­â­â­ | â­â­â­ | â­â­ | â­â­ | NVIDIA GPU |
| æ¨¡å‹å‰ªæ | â­â­ | â­â­ | â­â­â­â­ | â­â­â­ | è¾¹ç¼˜è®¾å¤‡ |
| çŸ¥è¯†è’¸é¦ | â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­â­ | ç§»åŠ¨è®¾å¤‡ |
| å¤šå°ºåº¦æ£€æµ‹ | â­â­ | â­â­â­â­ | â­ | â­â­ | å¤šæ ·åŒ–è¾“å…¥ |
| Transformeré›†æˆ | â­ | â­â­â­â­â­ | â­ | â­â­â­â­â­ | é«˜ç²¾åº¦éœ€æ±‚ |

## ğŸš€ å¿«é€Ÿä¼˜åŒ–æ–¹æ¡ˆ (1-2å¤©å®æ–½)

### 1. å‡çº§åˆ°YOLOv11
```python
# æ›¿æ¢ç°æœ‰æ£€æµ‹å™¨
from src.models.yolov11_detector import YOLOv11Detector

# åŸæœ‰ä»£ç 
# detector = YOLO('yolov8s.pt')

# ä¼˜åŒ–åä»£ç 
detector = YOLOv11Detector(
    model_size='s',
    half_precision=True,      # å¯ç”¨FP16
    tensorrt_optimize=True,   # å¯ç”¨TensorRT
    confidence_threshold=0.25,
    iou_threshold=0.45
)

# æ£€æµ‹ä½¿ç”¨
results = detector.detect(image)
```

### 2. æ¨ç†ä¼˜åŒ–é…ç½®
```python
# åˆ›å»ºä¼˜åŒ–é…ç½®
class OptimizedYOLOConfig:
    def __init__(self):
        self.model_configs = {
            'nano': {
                'model_size': 'n',
                'input_size': 640,
                'batch_size': 16,
                'use_case': 'å®æ—¶æ£€æµ‹ï¼Œèµ„æºå—é™'
            },
            'small': {
                'model_size': 's', 
                'input_size': 640,
                'batch_size': 8,
                'use_case': 'å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦'
            },
            'medium': {
                'model_size': 'm',
                'input_size': 832,
                'batch_size': 4,
                'use_case': 'é«˜ç²¾åº¦æ£€æµ‹'
            }
        }
    
    def get_optimal_config(self, device_type, performance_target):
        """æ ¹æ®è®¾å¤‡å’Œæ€§èƒ½ç›®æ ‡é€‰æ‹©æœ€ä¼˜é…ç½®"""
        if device_type == 'mobile':
            return self.model_configs['nano']
        elif device_type == 'edge':
            return self.model_configs['small']
        else:
            return self.model_configs['medium']
```

### 3. æ‰¹å¤„ç†ä¼˜åŒ–
```python
class BatchOptimizedDetector:
    def __init__(self, model_size='s', batch_size=8):
        self.detector = YOLOv11Detector(model_size=model_size)
        self.batch_size = batch_size
        
    def detect_batch_optimized(self, images):
        """ä¼˜åŒ–çš„æ‰¹å¤„ç†æ£€æµ‹"""
        results = []
        
        # æŒ‰æ‰¹æ¬¡å¤„ç†
        for i in range(0, len(images), self.batch_size):
            batch = images[i:i + self.batch_size]
            
            # é¢„å¤„ç†æ‰¹æ¬¡
            batch_tensor = self._preprocess_batch(batch)
            
            # æ‰¹é‡æ¨ç†
            with torch.no_grad():
                batch_results = self.detector.model(batch_tensor)
            
            # åå¤„ç†
            for j, result in enumerate(batch_results):
                processed_result = self._postprocess_result(result, batch[j])
                results.append(processed_result)
        
        return results
    
    def _preprocess_batch(self, images):
        """æ‰¹é‡é¢„å¤„ç†"""
        processed_images = []
        for img in images:
            # ç»Ÿä¸€å°ºå¯¸
            resized = cv2.resize(img, (640, 640))
            # å½’ä¸€åŒ–
            normalized = resized.astype(np.float32) / 255.0
            # è½¬æ¢ä¸ºtensor
            tensor = torch.from_numpy(normalized).permute(2, 0, 1)
            processed_images.append(tensor)
        
        return torch.stack(processed_images)
```

## ğŸ”§ ä¸­çº§ä¼˜åŒ–æ–¹æ¡ˆ (1-2å‘¨å®æ–½)

### 1. å¤šå°ºåº¦è‡ªé€‚åº”æ£€æµ‹
```python
from src.models.yolov11_detector import MultiScaleYOLODetector

class AdaptiveMultiScaleDetector:
    def __init__(self):
        self.multi_scale_detector = MultiScaleYOLODetector(['n', 's', 'm'])
        self.performance_tracker = {}
        
    def detect_with_adaptation(self, image):
        """è‡ªé€‚åº”å¤šå°ºåº¦æ£€æµ‹"""
        # åˆ†æå›¾åƒç‰¹å¾
        image_complexity = self._analyze_image_complexity(image)
        
        # é€‰æ‹©æœ€ä¼˜æ£€æµ‹ç­–ç•¥
        if image_complexity < 0.3:
            # ç®€å•åœºæ™¯ï¼Œä½¿ç”¨å¿«é€Ÿæ¨¡å‹
            detector = self.multi_scale_detector.detectors['n']
        elif image_complexity < 0.7:
            # ä¸­ç­‰å¤æ‚åº¦ï¼Œä½¿ç”¨å¹³è¡¡æ¨¡å‹
            detector = self.multi_scale_detector.detectors['s']
        else:
            # å¤æ‚åœºæ™¯ï¼Œä½¿ç”¨é«˜ç²¾åº¦æ¨¡å‹
            detector = self.multi_scale_detector.detectors['m']
        
        return detector.detect(image)
    
    def _analyze_image_complexity(self, image):
        """åˆ†æå›¾åƒå¤æ‚åº¦"""
        # è®¡ç®—è¾¹ç¼˜å¯†åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # è®¡ç®—é¢œè‰²å¤æ‚åº¦
        hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
        color_complexity = np.sum(hist > 0) / hist.size
        
        # ç»¼åˆå¤æ‚åº¦
        complexity = (edge_density + color_complexity) / 2
        return complexity
```

### 2. åŠ¨æ€é‡åŒ–ä¼˜åŒ–
```python
class DynamicQuantizationOptimizer:
    def __init__(self, model):
        self.model = model
        self.quantized_models = {}
        
    def create_quantized_variants(self):
        """åˆ›å»ºä¸åŒé‡åŒ–ç‰ˆæœ¬"""
        # INT8é‡åŒ–
        self.quantized_models['int8'] = self._quantize_int8(self.model)
        
        # åŠ¨æ€é‡åŒ–
        self.quantized_models['dynamic'] = self._quantize_dynamic(self.model)
        
        # FP16é‡åŒ–
        if torch.cuda.is_available():
            self.quantized_models['fp16'] = self.model.half()
    
    def _quantize_int8(self, model):
        """INT8é‡åŒ–"""
        try:
            import torch.quantization as quant
            
            # è®¾ç½®é‡åŒ–é…ç½®
            model.qconfig = quant.get_default_qconfig('fbgemm')
            
            # å‡†å¤‡é‡åŒ–
            model_prepared = quant.prepare(model)
            
            # æ ¡å‡†ï¼ˆéœ€è¦ä»£è¡¨æ€§æ•°æ®ï¼‰
            # è¿™é‡Œåº”è¯¥ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œæ ¡å‡†
            dummy_input = torch.randn(1, 3, 640, 640)
            model_prepared(dummy_input)
            
            # è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
            quantized_model = quant.convert(model_prepared)
            
            return quantized_model
        except Exception as e:
            print(f"INT8é‡åŒ–å¤±è´¥: {e}")
            return model
    
    def _quantize_dynamic(self, model):
        """åŠ¨æ€é‡åŒ–"""
        try:
            quantized_model = torch.quantization.quantize_dynamic(
                model, 
                {torch.nn.Linear, torch.nn.Conv2d}, 
                dtype=torch.qint8
            )
            return quantized_model
        except Exception as e:
            print(f"åŠ¨æ€é‡åŒ–å¤±è´¥: {e}")
            return model
    
    def benchmark_quantized_models(self, test_data):
        """åŸºå‡†æµ‹è¯•é‡åŒ–æ¨¡å‹"""
        results = {}
        
        for variant_name, model in self.quantized_models.items():
            # æµ‹è¯•æ¨ç†æ—¶é—´
            start_time = time.time()
            
            with torch.no_grad():
                for data in test_data:
                    _ = model(data)
            
            end_time = time.time()
            
            results[variant_name] = {
                'inference_time': end_time - start_time,
                'model_size': self._get_model_size(model)
            }
        
        return results
```

### 3. ç¼“å­˜å’Œé¢„åŠ è½½ä¼˜åŒ–
```python
class CacheOptimizedDetector:
    def __init__(self, model_size='s', cache_size=100):
        self.detector = YOLOv11Detector(model_size=model_size)
        self.result_cache = {}
        self.cache_size = cache_size
        self.preloaded_models = {}
        
    def detect_with_cache(self, image, use_cache=True):
        """å¸¦ç¼“å­˜çš„æ£€æµ‹"""
        if use_cache:
            # è®¡ç®—å›¾åƒå“ˆå¸Œ
            image_hash = self._compute_image_hash(image)
            
            # æ£€æŸ¥ç¼“å­˜
            if image_hash in self.result_cache:
                return self.result_cache[image_hash]
        
        # æ‰§è¡Œæ£€æµ‹
        results = self.detector.detect(image)
        
        # æ›´æ–°ç¼“å­˜
        if use_cache:
            self._update_cache(image_hash, results)
        
        return results
    
    def preload_models(self, model_sizes=['n', 's', 'm']):
        """é¢„åŠ è½½å¤šä¸ªæ¨¡å‹"""
        for size in model_sizes:
            if size not in self.preloaded_models:
                self.preloaded_models[size] = YOLOv11Detector(model_size=size)
                print(f"é¢„åŠ è½½æ¨¡å‹: YOLOv11{size}")
    
    def _compute_image_hash(self, image):
        """è®¡ç®—å›¾åƒå“ˆå¸Œ"""
        # ä½¿ç”¨æ„ŸçŸ¥å“ˆå¸Œ
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        resized = cv2.resize(gray, (8, 8))
        avg = resized.mean()
        binary = resized > avg
        return hash(binary.tobytes())
    
    def _update_cache(self, image_hash, results):
        """æ›´æ–°ç¼“å­˜"""
        if len(self.result_cache) >= self.cache_size:
            # ç§»é™¤æœ€æ—§çš„æ¡ç›®
            oldest_key = next(iter(self.result_cache))
            del self.result_cache[oldest_key]
        
        self.result_cache[image_hash] = results
```

## ğŸ¯ é«˜çº§ä¼˜åŒ–æ–¹æ¡ˆ (2-4å‘¨å®æ–½)

### 1. ç¥ç»æ¶æ„æœç´¢ä¼˜åŒ–
```python
from src.models.advanced_yolo_optimizations import NeuralArchitectureSearch

class YOLOArchitectureOptimizer:
    def __init__(self, dataset_path, target_device='cuda'):
        self.dataset_path = dataset_path
        self.target_device = target_device
        
        # å®šä¹‰æœç´¢ç©ºé—´
        self.search_space = {
            'backbone_depth': [3, 4, 5, 6],
            'neck_channels': [128, 256, 512],
            'head_layers': [2, 3, 4],
            'activation': ['ReLU', 'SiLU', 'Mish', 'Swish'],
            'attention_type': ['SE', 'CBAM', 'ECA', 'None'],
            'use_transformer': [True, False],
            'transformer_layers': [3, 6, 9]
        }
    
    def search_optimal_architecture(self, 
                                  population_size=20, 
                                  generations=50,
                                  performance_weight=0.7,
                                  efficiency_weight=0.3):
        """æœç´¢æœ€ä¼˜æ¶æ„"""
        
        # åˆ›å»ºNASå®ä¾‹
        nas = NeuralArchitectureSearch(
            search_space=self.search_space,
            population_size=population_size,
            generations=generations
        )
        
        # è‡ªå®šä¹‰è¯„ä¼°å‡½æ•°
        def custom_evaluate(config):
            # æ„å»ºæ¨¡å‹
            model = self._build_model_from_config(config)
            
            # è¯„ä¼°æ€§èƒ½
            accuracy = self._evaluate_accuracy(model)
            efficiency = self._evaluate_efficiency(model)
            
            # ç»¼åˆè¯„åˆ†
            score = (performance_weight * accuracy + 
                    efficiency_weight * efficiency)
            
            return score
        
        # æ›¿æ¢é»˜è®¤è¯„ä¼°å‡½æ•°
        nas.evaluate_architecture = custom_evaluate
        
        # æ‰§è¡Œæœç´¢
        best_config = nas.search()
        
        return best_config
    
    def _build_model_from_config(self, config):
        """æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹"""
        # è¿™é‡Œéœ€è¦å®ç°æ ¹æ®é…ç½®æ„å»ºYOLOæ¨¡å‹çš„é€»è¾‘
        # ç®€åŒ–å®ç°
        return YOLOv11Detector(model_size='s')
    
    def _evaluate_accuracy(self, model):
        """è¯„ä¼°æ¨¡å‹ç²¾åº¦"""
        # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
        # è¿”å›mAPåˆ†æ•°
        return 0.75  # ç¤ºä¾‹å€¼
    
    def _evaluate_efficiency(self, model):
        """è¯„ä¼°æ¨¡å‹æ•ˆç‡"""
        # æµ‹é‡æ¨ç†æ—¶é—´å’Œå†…å­˜ä½¿ç”¨
        # è¿”å›æ•ˆç‡åˆ†æ•°
        return 0.80  # ç¤ºä¾‹å€¼
```

### 2. çŸ¥è¯†è’¸é¦å®ç°
```python
from src.models.yolov11_detector import KnowledgeDistillationTrainer

class ProductionKnowledgeDistillation:
    def __init__(self, 
                 teacher_model_size='x',
                 student_model_size='n',
                 temperature=4.0,
                 alpha=0.7):
        
        # åˆ›å»ºæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹
        self.teacher = YOLOv11Detector(model_size=teacher_model_size)
        self.student = YOLOv11Detector(model_size=student_model_size)
        
        # åˆ›å»ºè’¸é¦è®­ç»ƒå™¨
        self.distillation_trainer = KnowledgeDistillationTrainer(
            teacher_model=self.teacher,
            student_model=self.student,
            temperature=temperature,
            alpha=alpha
        )
        
        self.training_history = []
    
    def distill_with_curriculum(self, 
                               training_data,
                               epochs=50,
                               curriculum_stages=3):
        """è¯¾ç¨‹å­¦ä¹ å¼çŸ¥è¯†è’¸é¦"""
        
        # å°†è®­ç»ƒæ•°æ®åˆ†ä¸ºä¸åŒéš¾åº¦é˜¶æ®µ
        stage_data = self._create_curriculum_stages(training_data, curriculum_stages)
        
        for stage, data in enumerate(stage_data):
            print(f"å¼€å§‹è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ {stage + 1}/{curriculum_stages}")
            
            # è°ƒæ•´å­¦ä¹ ç‡å’Œæ¸©åº¦
            stage_temperature = self.distillation_trainer.temperature * (0.8 ** stage)
            self.distillation_trainer.temperature = stage_temperature
            
            # è®­ç»ƒå½“å‰é˜¶æ®µ
            stage_stats = self.distillation_trainer.distill_knowledge(
                images=data,
                epochs=epochs // curriculum_stages
            )
            
            self.training_history.append({
                'stage': stage + 1,
                'temperature': stage_temperature,
                'stats': stage_stats
            })
            
            # è¯„ä¼°å­¦ç”Ÿæ¨¡å‹
            student_performance = self._evaluate_student_model(data[:100])
            print(f"é˜¶æ®µ {stage + 1} å­¦ç”Ÿæ¨¡å‹æ€§èƒ½: {student_performance}")
    
    def _create_curriculum_stages(self, training_data, num_stages):
        """åˆ›å»ºè¯¾ç¨‹å­¦ä¹ é˜¶æ®µ"""
        # æ ¹æ®å›¾åƒå¤æ‚åº¦æ’åº
        complexity_scores = []
        for image in training_data:
            complexity = self._calculate_image_complexity(image)
            complexity_scores.append((complexity, image))
        
        # æŒ‰å¤æ‚åº¦æ’åº
        complexity_scores.sort(key=lambda x: x[0])
        
        # åˆ†å‰²ä¸ºä¸åŒé˜¶æ®µ
        stage_size = len(complexity_scores) // num_stages
        stages = []
        
        for i in range(num_stages):
            start_idx = i * stage_size
            end_idx = (i + 1) * stage_size if i < num_stages - 1 else len(complexity_scores)
            
            stage_images = [item[1] for item in complexity_scores[start_idx:end_idx]]
            stages.append(stage_images)
        
        return stages
    
    def _calculate_image_complexity(self, image):
        """è®¡ç®—å›¾åƒå¤æ‚åº¦"""
        # ä½¿ç”¨å¤šä¸ªæŒ‡æ ‡è¯„ä¼°å¤æ‚åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # è¾¹ç¼˜å¯†åº¦
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # çº¹ç†å¤æ‚åº¦ï¼ˆä½¿ç”¨LBPï¼‰
        from skimage.feature import local_binary_pattern
        lbp = local_binary_pattern(gray, 8, 1, method='uniform')
        texture_complexity = len(np.unique(lbp)) / 256
        
        # é¢œè‰²å¤æ‚åº¦
        color_hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
        color_complexity = np.sum(color_hist > 0) / color_hist.size
        
        # ç»¼åˆå¤æ‚åº¦
        complexity = (edge_density + texture_complexity + color_complexity) / 3
        return complexity
```

### 3. Transformerå¢å¼ºYOLO
```python
from src.models.advanced_yolo_optimizations import YOLOTransformerNeck

class TransformerEnhancedYOLO:
    def __init__(self, 
                 base_model_size='s',
                 transformer_layers=6,
                 attention_heads=8):
        
        # åŸºç¡€YOLOæ¨¡å‹
        self.base_detector = YOLOv11Detector(model_size=base_model_size)
        
        # Transformerå¢å¼ºæ¨¡å—
        self.transformer_neck = YOLOTransformerNeck(
            in_channels=[256, 512, 1024],
            d_model=256,
            nhead=attention_heads,
            num_layers=transformer_layers
        )
        
        self.enhanced_model = self._create_enhanced_model()
    
    def _create_enhanced_model(self):
        """åˆ›å»ºTransformerå¢å¼ºçš„YOLOæ¨¡å‹"""
        class EnhancedYOLOModel(nn.Module):
            def __init__(self, base_model, transformer_neck):
                super().__init__()
                self.backbone = base_model.model.model[:10]  # éª¨å¹²ç½‘ç»œ
                self.transformer_neck = transformer_neck
                self.head = base_model.model.model[10:]  # æ£€æµ‹å¤´
            
            def forward(self, x):
                # éª¨å¹²ç½‘ç»œç‰¹å¾æå–
                features = []
                for i, layer in enumerate(self.backbone):
                    x = layer(x)
                    if i in [6, 8, 9]:  # P3, P4, P5ç‰¹å¾å±‚
                        features.append(x)
                
                # Transformerå¢å¼º
                enhanced_features = self.transformer_neck(features)
                
                # æ£€æµ‹å¤´å¤„ç†
                outputs = []
                for i, feat in enumerate(enhanced_features):
                    output = self.head[i](feat)
                    outputs.append(output)
                
                return outputs
        
        return EnhancedYOLOModel(self.base_detector, self.transformer_neck)
    
    def detect_with_attention(self, image):
        """ä½¿ç”¨æ³¨æ„åŠ›å¢å¼ºçš„æ£€æµ‹"""
        # é¢„å¤„ç†
        processed_image = self._preprocess_image(image)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.enhanced_model(processed_image)
        
        # åå¤„ç†
        detections = self._postprocess_outputs(outputs, image.shape)
        
        return detections
    
    def visualize_attention_maps(self, image, save_path=None):
        """å¯è§†åŒ–æ³¨æ„åŠ›å›¾"""
        # è·å–æ³¨æ„åŠ›æƒé‡
        attention_weights = self._extract_attention_weights(image)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # ä¸åŒå±‚çš„æ³¨æ„åŠ›å›¾
        for i, (layer_name, attention) in enumerate(attention_weights.items()):
            if i >= 5:  # æœ€å¤šæ˜¾ç¤º5ä¸ªæ³¨æ„åŠ›å›¾
                break
            
            row = (i + 1) // 3
            col = (i + 1) % 3
            
            # è°ƒæ•´æ³¨æ„åŠ›å›¾å°ºå¯¸
            attention_resized = cv2.resize(attention, (image.shape[1], image.shape[0]))
            
            # å åŠ æ˜¾ç¤º
            overlay = cv2.addWeighted(image, 0.7, 
                                    cv2.applyColorMap((attention_resized * 255).astype(np.uint8), 
                                                    cv2.COLORMAP_JET), 0.3, 0)
            
            axes[row, col].imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
            axes[row, col].set_title(f'Attention Layer {layer_name}')
            axes[row, col].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### 1. è‡ªåŠ¨åŒ–åŸºå‡†æµ‹è¯•
```python
from src.models.yolo_benchmark_system import YOLOBenchmarkSuite

class AutomatedOptimizationBenchmark:
    def __init__(self, test_dataset_path, output_dir="optimization_results"):
        self.test_dataset_path = test_dataset_path
        self.benchmark_suite = YOLOBenchmarkSuite(output_dir)
        
    def run_comprehensive_benchmark(self):
        """è¿è¡Œå…¨é¢çš„ä¼˜åŒ–åŸºå‡†æµ‹è¯•"""
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_images, ground_truths = self._load_test_data()
        
        # æµ‹è¯•ä¸åŒä¼˜åŒ–é…ç½®
        optimization_configs = {
            'baseline': {
                'model_size': 's',
                'half_precision': False,
                'tensorrt_optimize': False
            },
            'fp16_optimized': {
                'model_size': 's',
                'half_precision': True,
                'tensorrt_optimize': False
            },
            'tensorrt_optimized': {
                'model_size': 's',
                'half_precision': True,
                'tensorrt_optimize': True
            },
            'nano_model': {
                'model_size': 'n',
                'half_precision': True,
                'tensorrt_optimize': True
            },
            'medium_model': {
                'model_size': 'm',
                'half_precision': True,
                'tensorrt_optimize': True
            }
        }
        
        # åˆ›å»ºæ£€æµ‹å™¨
        detectors = {}
        for config_name, config in optimization_configs.items():
            detectors[config_name] = YOLOv11Detector(**config)
        
        # æ‰§è¡ŒåŸºå‡†æµ‹è¯•
        results = self.benchmark_suite.compare_models(
            detectors, test_images, ground_truths
        )
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self._generate_optimization_recommendations(results)
        
        return results, recommendations
    
    def _generate_optimization_recommendations(self, results):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åˆ†æç»“æœ
        best_fps = max(results.values(), key=lambda x: x.fps)
        best_accuracy = max(results.values(), 
                          key=lambda x: x.accuracy_metrics.get('f1_score', 0) 
                          if x.accuracy_metrics else 0)
        most_efficient = min(results.values(), key=lambda x: x.model_size_mb)
        
        recommendations.append(f"ğŸš€ æœ€é«˜æ€§èƒ½: {best_fps.model_name} (FPS: {best_fps.fps:.1f})")
        
        if best_accuracy.accuracy_metrics:
            f1_score = best_accuracy.accuracy_metrics.get('f1_score', 0)
            recommendations.append(f"ğŸ¯ æœ€é«˜ç²¾åº¦: {best_accuracy.model_name} (F1: {f1_score:.3f})")
        
        recommendations.append(f"ğŸ’¾ æœ€å°æ¨¡å‹: {most_efficient.model_name} ({most_efficient.model_size_mb:.1f}MB)")
        
        # åœºæ™¯åŒ–å»ºè®®
        recommendations.append("\nğŸ“‹ åœºæ™¯åŒ–éƒ¨ç½²å»ºè®®:")
        recommendations.append("â€¢ å®æ—¶è§†é¢‘æµ: é€‰æ‹©nanoæ¨¡å‹ + TensorRTä¼˜åŒ–")
        recommendations.append("â€¢ é«˜ç²¾åº¦æ£€æµ‹: é€‰æ‹©mediumæ¨¡å‹ + FP16ä¼˜åŒ–") 
        recommendations.append("â€¢ è¾¹ç¼˜è®¾å¤‡: é€‰æ‹©nanoæ¨¡å‹ + æ¨¡å‹å‰ªæ")
        recommendations.append("â€¢ äº‘ç«¯éƒ¨ç½²: é€‰æ‹©small/mediumæ¨¡å‹ + æ‰¹å¤„ç†ä¼˜åŒ–")
        
        return recommendations
```

### 2. æŒç»­ä¼˜åŒ–ç›‘æ§
```python
class ContinuousOptimizationMonitor:
    def __init__(self, detector, monitoring_interval=3600):  # æ¯å°æ—¶ç›‘æ§
        self.detector = detector
        self.monitoring_interval = monitoring_interval
        self.performance_history = []
        self.optimization_triggers = {
            'fps_drop': 0.1,      # FPSä¸‹é™10%è§¦å‘ä¼˜åŒ–
            'memory_increase': 0.2,  # å†…å­˜å¢åŠ 20%è§¦å‘ä¼˜åŒ–
            'accuracy_drop': 0.05    # ç²¾åº¦ä¸‹é™5%è§¦å‘ä¼˜åŒ–
        }
    
    def start_monitoring(self):
        """å¼€å§‹æŒç»­ç›‘æ§"""
        def monitor_loop():
            while True:
                try:
                    # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
                    current_metrics = self._collect_current_metrics()
                    self.performance_history.append(current_metrics)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
                    if self._should_trigger_optimization(current_metrics):
                        self._trigger_automatic_optimization()
                    
                    time.sleep(self.monitoring_interval)
                    
                except Exception as e:
                    print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        monitor_thread.start()
    
    def _collect_current_metrics(self):
        """æ”¶é›†å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        # æµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        
        # æµ‹é‡æ¨ç†æ—¶é—´
        start_time = time.time()
        results = self.detector.detect(test_image)
        inference_time = time.time() - start_time
        
        # è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨
        memory_usage = psutil.virtual_memory().percent
        
        return {
            'timestamp': time.time(),
            'inference_time': inference_time,
            'fps': 1.0 / inference_time,
            'memory_usage': memory_usage,
            'detection_count': len(results)
        }
    
    def _should_trigger_optimization(self, current_metrics):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘ä¼˜åŒ–"""
        if len(self.performance_history) < 10:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
            return False
        
        # è®¡ç®—åŸºçº¿æ€§èƒ½ï¼ˆæœ€è¿‘10æ¬¡çš„å¹³å‡å€¼ï¼‰
        recent_metrics = self.performance_history[-10:]
        baseline_fps = np.mean([m['fps'] for m in recent_metrics])
        baseline_memory = np.mean([m['memory_usage'] for m in recent_metrics])
        
        # æ£€æŸ¥æ€§èƒ½ä¸‹é™
        fps_drop = (baseline_fps - current_metrics['fps']) / baseline_fps
        memory_increase = (current_metrics['memory_usage'] - baseline_memory) / baseline_memory
        
        return (fps_drop > self.optimization_triggers['fps_drop'] or
                memory_increase > self.optimization_triggers['memory_increase'])
    
    def _trigger_automatic_optimization(self):
        """è§¦å‘è‡ªåŠ¨ä¼˜åŒ–"""
        print("ğŸ”§ æ£€æµ‹åˆ°æ€§èƒ½ä¸‹é™ï¼Œè§¦å‘è‡ªåŠ¨ä¼˜åŒ–...")
        
        # å°è¯•ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
        optimization_strategies = [
            self._optimize_batch_size,
            self._optimize_input_resolution,
            self._optimize_confidence_threshold,
            self._clear_cache_and_gc
        ]
        
        for strategy in optimization_strategies:
            try:
                strategy()
                print(f"âœ… ä¼˜åŒ–ç­–ç•¥ {strategy.__name__} æ‰§è¡ŒæˆåŠŸ")
                break
            except Exception as e:
                print(f"âŒ ä¼˜åŒ–ç­–ç•¥ {strategy.__name__} æ‰§è¡Œå¤±è´¥: {e}")
    
    def _optimize_batch_size(self):
        """ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°"""
        # åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°
        if hasattr(self.detector, 'batch_size'):
            current_batch_size = getattr(self.detector, 'batch_size', 1)
            new_batch_size = max(1, current_batch_size - 1)
            setattr(self.detector, 'batch_size', new_batch_size)
    
    def _optimize_input_resolution(self):
        """ä¼˜åŒ–è¾“å…¥åˆ†è¾¨ç‡"""
        # é™ä½è¾“å…¥åˆ†è¾¨ç‡ä»¥æé«˜é€Ÿåº¦
        if hasattr(self.detector, 'input_size'):
            current_size = getattr(self.detector, 'input_size', 640)
            new_size = max(320, current_size - 64)
            setattr(self.detector, 'input_size', new_size)
    
    def _optimize_confidence_threshold(self):
        """ä¼˜åŒ–ç½®ä¿¡åº¦é˜ˆå€¼"""
        # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼ä»¥å‡å°‘åå¤„ç†å¼€é”€
        current_threshold = self.detector.confidence_threshold
        new_threshold = min(0.8, current_threshold + 0.05)
        self.detector.confidence_threshold = new_threshold
    
    def _clear_cache_and_gc(self):
        """æ¸…ç†ç¼“å­˜å’Œåƒåœ¾å›æ”¶"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
```

## ğŸ¯ éƒ¨ç½²ä¼˜åŒ–æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¸…å•
```yaml
# deployment_checklist.yml
production_deployment:
  model_optimization:
    - âœ… å‡çº§åˆ°YOLOv11æœ€æ–°ç‰ˆæœ¬
    - âœ… å¯ç”¨FP16åŠç²¾åº¦æ¨ç†
    - âœ… é…ç½®TensorRTä¼˜åŒ–ï¼ˆNVIDIA GPUï¼‰
    - âœ… å®æ–½æ¨¡å‹é‡åŒ–ï¼ˆè¾¹ç¼˜è®¾å¤‡ï¼‰
    - âœ… è®¾ç½®åˆé€‚çš„ç½®ä¿¡åº¦å’ŒIoUé˜ˆå€¼
  
  performance_optimization:
    - âœ… é…ç½®æ‰¹å¤„ç†æ£€æµ‹
    - âœ… å®æ–½ç»“æœç¼“å­˜æœºåˆ¶
    - âœ… å¯ç”¨å¤šçº¿ç¨‹å¤„ç†
    - âœ… ä¼˜åŒ–å†…å­˜ç®¡ç†
    - âœ… è®¾ç½®æ€§èƒ½ç›‘æ§
  
  infrastructure:
    - âœ… GPUé©±åŠ¨å’ŒCUDAç‰ˆæœ¬å…¼å®¹æ€§
    - âœ… è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆæ¨è8GB+ï¼‰
    - âœ… é«˜é€Ÿå­˜å‚¨ï¼ˆSSDæ¨èï¼‰
    - âœ… ç½‘ç»œå¸¦å®½è§„åˆ’
    - âœ… è´Ÿè½½å‡è¡¡é…ç½®
  
  monitoring:
    - âœ… æ¨ç†å»¶è¿Ÿç›‘æ§
    - âœ… ååé‡ç›‘æ§
    - âœ… èµ„æºä½¿ç”¨ç›‘æ§
    - âœ… é”™è¯¯ç‡ç›‘æ§
    - âœ… æ¨¡å‹ç²¾åº¦ç›‘æ§
```

### 2. å¹³å°ç‰¹å®šä¼˜åŒ–
```python
class PlatformSpecificOptimizer:
    def __init__(self):
        self.platform_configs = {
            'nvidia_gpu': {
                'optimizations': ['tensorrt', 'fp16', 'batch_processing'],
                'recommended_batch_size': 8,
                'memory_optimization': True
            },
            'amd_gpu': {
                'optimizations': ['fp16', 'batch_processing'],
                'recommended_batch_size': 4,
                'memory_optimization': True
            },
            'cpu_intel': {
                'optimizations': ['quantization', 'threading'],
                'recommended_batch_size': 2,
                'memory_optimization': False
            },
            'cpu_arm': {
                'optimizations': ['quantization', 'pruning'],
                'recommended_batch_size': 1,
                'memory_optimization': True
            },
            'mobile': {
                'optimizations': ['quantization', 'pruning', 'distillation'],
                'recommended_batch_size': 1,
                'memory_optimization': True
            }
        }
    
    def optimize_for_platform(self, detector, platform_type):
        """ä¸ºç‰¹å®šå¹³å°ä¼˜åŒ–æ£€æµ‹å™¨"""
        config = self.platform_configs.get(platform_type, {})
        
        optimizations = config.get('optimizations', [])
        
        if 'tensorrt' in optimizations and torch.cuda.is_available():
            detector.tensorrt_optimize = True
        
        if 'fp16' in optimizations:
            detector.half_precision = True
        
        if 'quantization' in optimizations:
            detector = self._apply_quantization(detector)
        
        if 'batch_processing' in optimizations:
            batch_size = config.get('recommended_batch_size', 1)
            detector.batch_size = batch_size
        
        return detector
```

è¿™ä»½å®æ–½æŒ‡å—æä¾›äº†ä»å¿«é€Ÿä¼˜åŒ–åˆ°é«˜çº§æŠ€æœ¯çš„å®Œæ•´è·¯å¾„ï¼Œå¸®åŠ©YOLOSé¡¹ç›®å®ç°æœ€ä½³æ€§èƒ½ã€‚æ¯ä¸ªä¼˜åŒ–æ–¹æ¡ˆéƒ½åŒ…å«äº†å…·ä½“çš„ä»£ç å®ç°å’Œéƒ¨ç½²å»ºè®®ï¼Œç¡®ä¿èƒ½å¤Ÿåœ¨å®é™…é¡¹ç›®ä¸­æœ‰æ•ˆåº”ç”¨ã€‚