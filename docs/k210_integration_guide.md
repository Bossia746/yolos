# YOLOS K210é›†æˆæŒ‡å—

## æ¦‚è¿°

YOLOSç³»ç»Ÿå…¨é¢æ”¯æŒKendryte K210 AIèŠ¯ç‰‡ï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºè¾¹ç¼˜AIåº”ç”¨è®¾è®¡çš„RISC-Vå¤„ç†å™¨ã€‚æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨K210å¹³å°ä¸ŠæˆåŠŸéƒ¨ç½²YOLOç›®æ ‡æ£€æµ‹åŠŸèƒ½ã€‚

## ğŸš€ K210å¹³å°ç‰¹æ€§

### ç¡¬ä»¶è§„æ ¼
- **å¤„ç†å™¨**: åŒæ ¸RISC-V 64ä½ @ 400MHz
- **å†…å­˜**: 8MB SRAM (6MBå¯ç”¨äºåº”ç”¨)
- **å­˜å‚¨**: 16MB Flash
- **AIåŠ é€Ÿå™¨**: KPU (Knowledge Processing Unit) - 0.25 TOPS
- **ç¥ç»ç½‘ç»œæ”¯æŒ**: CNNã€RNNã€LSTM
- **åŠŸè€—**: å…¸å‹300-500mWï¼Œæœ€å¤§1W
- **å·¥ä½œæ¸©åº¦**: -40Â°C to +125Â°C
- **å°è£…**: BGA-216

### KPUç‰¹æ€§
- **é‡åŒ–æ”¯æŒ**: INT8é‡åŒ–
- **æœ€å¤§æ¨¡å‹å¤§å°**: 6MB
- **æ”¯æŒçš„å±‚ç±»å‹**: å·ç§¯ã€æ± åŒ–ã€æ¿€æ´»ã€æ‰¹å½’ä¸€åŒ–
- **å¹¶è¡Œå¤„ç†**: 64ä¸ªMACå•å…ƒ
- **å†…å­˜å¸¦å®½**: 25.6 GB/s

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒè®¾ç½®

### 1. åŸºç¡€ç¯å¢ƒå®‰è£…

#### Windowsç¯å¢ƒ
```bash
# 1. å®‰è£…Python 3.7+
# ä¸‹è½½å¹¶å®‰è£…Python: https://www.python.org/downloads/

# 2. å®‰è£…MaixPy IDE
# ä¸‹è½½åœ°å€: https://github.com/sipeed/MaixPy/releases

# 3. å®‰è£…å¿…è¦çš„PythonåŒ…
pip install maixpy
pip install nncase==1.0.0.20210830
pip install pillow
pip install numpy
pip install opencv-python
```

#### Linuxç¯å¢ƒ
```bash
# 1. å®‰è£…ä¾èµ–
sudo apt update
sudo apt install python3 python3-pip git cmake build-essential

# 2. å®‰è£…MaixPyå·¥å…·é“¾
pip3 install maixpy
pip3 install nncase==1.0.0.20210830

# 3. å®‰è£…K210å·¥å…·é“¾
wget https://github.com/kendryte/kendryte-gnu-toolchain/releases/download/v8.2.0-20190409/kendryte-toolchain-ubuntu-amd64-8.2.0-20190409.tar.xz
tar -xf kendryte-toolchain-ubuntu-amd64-8.2.0-20190409.tar.xz
export PATH=$PATH:$(pwd)/kendryte-toolchain/bin
```

### 2. YOLOS K210é€‚é…å™¨å®‰è£…

```bash
# å…‹éš†YOLOSé¡¹ç›®
git clone https://github.com/your-repo/yolos.git
cd yolos

# å®‰è£…YOLOSä¾èµ–
pip install -r requirements.txt

# éªŒè¯K210æ”¯æŒ
python -c "
from src.core.cross_platform_manager import get_cross_platform_manager
manager = get_cross_platform_manager()
print('K210æ”¯æŒ:', 'k210' in manager.platform_info)
"
```

### 3. ç¡¬ä»¶è¿æ¥

#### æ¨èå¼€å‘æ¿
- **Sipeed MAIX Bit**: å…¥é—¨çº§å¼€å‘æ¿
- **Sipeed MAIX Dock**: å¸¦å±å¹•å’Œæ‘„åƒå¤´
- **Sipeed MAIX Go**: ä¾¿æºå¼å¼€å‘æ¿
- **Sipeed MAIX Cube**: å·¥ä¸šçº§å¼€å‘æ¿

#### è¿æ¥ç¤ºä¾‹ (MAIX Dock)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        MAIX Dock K210       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ USB-C  â† è¿æ¥ç”µè„‘(ä¾›ç”µ+é€šä¿¡) â”‚
â”‚ æ‘„åƒå¤´  â† OV2640æ¨¡å—        â”‚
â”‚ å±å¹•   â† 2.4å¯¸TFT LCD       â”‚
â”‚ SDå¡   â† å­˜å‚¨æ¨¡å‹å’Œæ•°æ®     â”‚
â”‚ GPIO   â† å¤–æ¥ä¼ æ„Ÿå™¨/æ‰§è¡Œå™¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ æ¨¡å‹éƒ¨ç½²æµç¨‹

### 1. æ¨¡å‹å‡†å¤‡å’Œè½¬æ¢

#### YOLOæ¨¡å‹ä¼˜åŒ–
```python
# yolo_k210_converter.py
import onnx
import numpy as np
from nncase import *

class YOLOK210Converter:
    def __init__(self):
        self.target_input_size = (64, 64)  # K210æ¨èè¾“å…¥å°ºå¯¸
        self.max_model_size = 6 * 1024 * 1024  # 6MBé™åˆ¶
        
    def optimize_model(self, model_path):
        """ä¼˜åŒ–YOLOæ¨¡å‹ä»¥é€‚é…K210"""
        # 1. åŠ è½½åŸå§‹æ¨¡å‹
        model = onnx.load(model_path)
        
        # 2. æ¨¡å‹ç®€åŒ–
        simplified_model = self._simplify_model(model)
        
        # 3. é‡åŒ–ä¼˜åŒ–
        quantized_model = self._quantize_model(simplified_model)
        
        return quantized_model
    
    def _simplify_model(self, model):
        """ç®€åŒ–æ¨¡å‹ç»“æ„"""
        # ç§»é™¤ä¸å¿…è¦çš„å±‚
        # åˆå¹¶è¿ç»­çš„å·ç§¯å’ŒBNå±‚
        # ä¼˜åŒ–æ¿€æ´»å‡½æ•°
        pass
    
    def _quantize_model(self, model):
        """INT8é‡åŒ–"""
        # ä½¿ç”¨æ ¡å‡†æ•°æ®é›†è¿›è¡Œé‡åŒ–
        calibration_data = self._prepare_calibration_data()
        
        # é…ç½®é‡åŒ–å‚æ•°
        quant_config = {
            'quant_type': 'uint8',
            'w_quant_type': 'uint8',
            'calibrate_dataset': calibration_data,
            'input_range': [0, 255]
        }
        
        return model  # è¿”å›é‡åŒ–åçš„æ¨¡å‹
    
    def convert_to_kmodel(self, onnx_model_path, output_path):
        """è½¬æ¢ä¸ºK210 kmodelæ ¼å¼"""
        # åˆ›å»ºç¼–è¯‘å™¨
        compiler = Compiler(target='k210')
        
        # ç¼–è¯‘é…ç½®
        compile_options = CompileOptions()
        compile_options.target = 'k210'
        compile_options.input_type = 'uint8'
        compile_options.output_type = 'uint8'
        compile_options.input_shape = [1, 3, 64, 64]
        compile_options.input_range = [0, 255]
        
        # ç¼–è¯‘æ¨¡å‹
        compiler.compile(onnx_model_path, output_path, compile_options)
        
        print(f"æ¨¡å‹å·²è½¬æ¢: {output_path}")
        
        # éªŒè¯æ¨¡å‹å¤§å°
        import os
        model_size = os.path.getsize(output_path)
        if model_size > self.max_model_size:
            print(f"è­¦å‘Š: æ¨¡å‹å¤§å° {model_size/1024/1024:.2f}MB è¶…è¿‡é™åˆ¶")
        else:
            print(f"æ¨¡å‹å¤§å°: {model_size/1024/1024:.2f}MB (ç¬¦åˆè¦æ±‚)")

# ä½¿ç”¨ç¤ºä¾‹
converter = YOLOK210Converter()
converter.convert_to_kmodel('yolov11n.onnx', 'yolov11n_k210.kmodel')
```

### 2. K210æ¨ç†ä»£ç 

#### MaixPyæ¨ç†å®ç°
```python
# k210_yolo_inference.py
import sensor
import image
import lcd
import KPU as kpu
import time
import gc
import json

class K210YOLODetector:
    def __init__(self, model_path, labels_path=None):
        self.model_path = model_path
        self.labels = self._load_labels(labels_path)
        self.task = None
        self.input_size = (64, 64)
        self.anchor_num = 3
        self.classes_num = 80  # COCOç±»åˆ«æ•°
        
        # æ€§èƒ½ç›‘æ§
        self.fps_counter = 0
        self.last_time = time.ticks_ms()
        
    def _load_labels(self, labels_path):
        """åŠ è½½ç±»åˆ«æ ‡ç­¾"""
        if labels_path:
            with open(labels_path, 'r') as f:
                return [line.strip() for line in f.readlines()]
        else:
            # é»˜è®¤COCOç±»åˆ«ï¼ˆç®€åŒ–ç‰ˆï¼‰
            return ['person', 'bicycle', 'car', 'motorcycle', 'airplane']
    
    def initialize(self):
        """åˆå§‹åŒ–K210å’Œæ¨¡å‹"""
        # åˆå§‹åŒ–LCD
        lcd.init()
        lcd.clear(lcd.RED)
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        sensor.reset()
        sensor.set_pixformat(sensor.RGB565)
        sensor.set_framesize(sensor.QVGA)  # 320x240
        sensor.set_windowing((224, 224))   # è£å‰ªä¸ºæ­£æ–¹å½¢
        sensor.run(1)
        
        # åŠ è½½æ¨¡å‹
        try:
            self.task = kpu.load(self.model_path)
            kpu.set_outputs(self.task, 0, 1, 1, self.classes_num + 5)  # è¾“å‡ºæ ¼å¼
            print("æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
            
        return True
    
    def preprocess_image(self, img):
        """å›¾åƒé¢„å¤„ç†"""
        # è°ƒæ•´å¤§å°åˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸
        img_resized = img.resize(self.input_size[0], self.input_size[1])
        
        # è½¬æ¢ä¸ºRGBæ ¼å¼
        img_rgb = img_resized.to_rgb888()
        
        return img_rgb
    
    def postprocess_detections(self, output):
        """åå¤„ç†æ£€æµ‹ç»“æœ"""
        detections = []
        
        # è§£æKPUè¾“å‡º
        for i in range(len(output)):
            if output[i] > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                # è®¡ç®—è¾¹ç•Œæ¡†åæ ‡
                x = int(output[i*6 + 1] * self.input_size[0])
                y = int(output[i*6 + 2] * self.input_size[1])
                w = int(output[i*6 + 3] * self.input_size[0])
                h = int(output[i*6 + 4] * self.input_size[1])
                
                # è·å–ç±»åˆ«
                class_id = int(output[i*6 + 5])
                confidence = output[i]
                
                if class_id < len(self.labels):
                    detections.append({
                        'bbox': [x, y, w, h],
                        'confidence': confidence,
                        'class_id': class_id,
                        'class_name': self.labels[class_id]
                    })
        
        return detections
    
    def draw_detections(self, img, detections):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        for det in detections:
            x, y, w, h = det['bbox']
            confidence = det['confidence']
            class_name = det['class_name']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            img.draw_rectangle(x, y, w, h, color=(255, 0, 0), thickness=2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            img.draw_string(x, y-20, label, color=(255, 255, 255), scale=1)
        
        return img
    
    def update_fps(self):
        """æ›´æ–°FPSè®¡ç®—"""
        current_time = time.ticks_ms()
        self.fps_counter += 1
        
        if time.ticks_diff(current_time, self.last_time) >= 1000:  # æ¯ç§’æ›´æ–°
            fps = self.fps_counter * 1000 / time.ticks_diff(current_time, self.last_time)
            print(f"FPS: {fps:.2f}")
            
            self.fps_counter = 0
            self.last_time = current_time
            
            # å†…å­˜ç®¡ç†
            gc.collect()
            print(f"Free memory: {gc.mem_free()} bytes")
    
    def run_detection(self):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        if not self.initialize():
            return
        
        print("å¼€å§‹æ£€æµ‹...")
        
        while True:
            try:
                # è·å–å›¾åƒ
                img = sensor.snapshot()
                
                # é¢„å¤„ç†
                img_processed = self.preprocess_image(img)
                
                # æ¨ç†
                start_time = time.ticks_ms()
                output = kpu.run_with_output(self.task, img_processed)
                inference_time = time.ticks_diff(time.ticks_ms(), start_time)
                
                # åå¤„ç†
                detections = self.postprocess_detections(output)
                
                # ç»˜åˆ¶ç»“æœ
                img_result = self.draw_detections(img, detections)
                
                # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
                img_result.draw_string(2, 2, f"Inference: {inference_time}ms", 
                                     color=(0, 255, 0), scale=1)
                img_result.draw_string(2, 20, f"Detections: {len(detections)}", 
                                     color=(0, 255, 0), scale=1)
                
                # æ˜¾ç¤ºå›¾åƒ
                lcd.display(img_result)
                
                # æ›´æ–°FPS
                self.update_fps()
                
                # æ‰“å°æ£€æµ‹ç»“æœ
                if detections:
                    print(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡:")
                    for det in detections:
                        print(f"  {det['class_name']}: {det['confidence']:.2f}")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"æ£€æµ‹é”™è¯¯: {e}")
                time.sleep(0.1)
        
        # æ¸…ç†èµ„æº
        kpu.deinit(self.task)
        print("æ£€æµ‹ç»“æŸ")

# ä¸»ç¨‹åº
if __name__ == "__main__":
    detector = K210YOLODetector(
        model_path="/sd/yolov11n_k210.kmodel",
        labels_path="/sd/coco_labels.txt"
    )
    detector.run_detection()
```

### 3. YOLOSç³»ç»Ÿé›†æˆ

#### K210é€‚é…å™¨å®ç°
```python
# src/plugins/platform/k210_adapter.py
import serial
import json
import time
import numpy as np
from typing import Dict, List, Optional, Any
from src.core.base_plugin import BasePlugin
from src.utils.logger import get_logger

logger = get_logger(__name__)

class K210Adapter(BasePlugin):
    """K210å¹³å°é€‚é…å™¨"""
    
    def __init__(self, config: Optional[Dict] = None):
        super().__init__()
        self.config = config or self._get_default_config()
        
        # ä¸²å£é…ç½®
        self.serial_port = self.config.get('serial_port', 'COM3')
        self.baud_rate = self.config.get('baud_rate', 115200)
        self.timeout = self.config.get('timeout', 2.0)
        
        # è¿æ¥çŠ¶æ€
        self.serial_connection = None
        self.is_connected = False
        
        # K210ç‰¹å®šé…ç½®
        self.input_size = self.config.get('input_size', (64, 64))
        self.max_detections = self.config.get('max_detections', 5)
        self.confidence_threshold = self.config.get('confidence_threshold', 0.5)
        
        logger.info("K210é€‚é…å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'serial_port': 'COM3',
            'baud_rate': 115200,
            'timeout': 2.0,
            'input_size': (64, 64),
            'max_detections': 5,
            'confidence_threshold': 0.5,
            'enable_kpu_acceleration': True,
            'power_mode': 'balanced'  # performance, balanced, power_save
        }
    
    def connect(self) -> bool:
        """è¿æ¥K210è®¾å¤‡"""
        try:
            self.serial_connection = serial.Serial(
                port=self.serial_port,
                baudrate=self.baud_rate,
                timeout=self.timeout
            )
            
            # å‘é€æ¡æ‰‹ä¿¡å·
            handshake_msg = {
                'type': 'handshake',
                'timestamp': time.time()
            }
            
            self._send_message(handshake_msg)
            
            # ç­‰å¾…å“åº”
            response = self._receive_message()
            if response and response.get('type') == 'handshake_ack':
                self.is_connected = True
                logger.info(f"K210è¿æ¥æˆåŠŸ: {self.serial_port}")
                return True
            else:
                logger.error("K210æ¡æ‰‹å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"K210è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€K210è¿æ¥"""
        if self.serial_connection:
            try:
                # å‘é€æ–­å¼€ä¿¡å·
                disconnect_msg = {
                    'type': 'disconnect',
                    'timestamp': time.time()
                }
                self._send_message(disconnect_msg)
                
                self.serial_connection.close()
                self.is_connected = False
                logger.info("K210è¿æ¥å·²æ–­å¼€")
            except Exception as e:
                logger.error(f"K210æ–­å¼€è¿æ¥é”™è¯¯: {e}")
    
    def _send_message(self, message: Dict):
        """å‘é€æ¶ˆæ¯åˆ°K210"""
        if not self.serial_connection:
            raise RuntimeError("K210æœªè¿æ¥")
        
        json_str = json.dumps(message) + '\n'
        self.serial_connection.write(json_str.encode('utf-8'))
        self.serial_connection.flush()
    
    def _receive_message(self, timeout: Optional[float] = None) -> Optional[Dict]:
        """ä»K210æ¥æ”¶æ¶ˆæ¯"""
        if not self.serial_connection:
            return None
        
        try:
            # è®¾ç½®è¶…æ—¶
            original_timeout = self.serial_connection.timeout
            if timeout is not None:
                self.serial_connection.timeout = timeout
            
            # è¯»å–ä¸€è¡Œæ•°æ®
            line = self.serial_connection.readline().decode('utf-8').strip()
            
            # æ¢å¤åŸå§‹è¶…æ—¶
            self.serial_connection.timeout = original_timeout
            
            if line:
                return json.loads(line)
            else:
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æé”™è¯¯: {e}")
            return None
        except Exception as e:
            logger.error(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")
            return None
    
    def send_image_for_detection(self, image: np.ndarray) -> Optional[Dict]:
        """å‘é€å›¾åƒè¿›è¡Œæ£€æµ‹"""
        if not self.is_connected:
            logger.error("K210æœªè¿æ¥")
            return None
        
        try:
            # å›¾åƒé¢„å¤„ç†
            processed_image = self._preprocess_image(image)
            
            # æ„å»ºæ£€æµ‹è¯·æ±‚
            detection_request = {
                'type': 'detection_request',
                'image_data': processed_image.tolist(),
                'image_shape': processed_image.shape,
                'config': {
                    'confidence_threshold': self.confidence_threshold,
                    'max_detections': self.max_detections
                },
                'timestamp': time.time()
            }
            
            # å‘é€è¯·æ±‚
            self._send_message(detection_request)
            
            # æ¥æ”¶ç»“æœ
            result = self._receive_message(timeout=5.0)
            
            if result and result.get('type') == 'detection_result':
                return self._process_detection_result(result)
            else:
                logger.error("æœªæ”¶åˆ°æœ‰æ•ˆçš„æ£€æµ‹ç»“æœ")
                return None
                
        except Exception as e:
            logger.error(f"å›¾åƒæ£€æµ‹é”™è¯¯: {e}")
            return None
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†å›¾åƒä»¥é€‚é…K210"""
        import cv2
        
        # è°ƒæ•´å¤§å°
        resized = cv2.resize(image, self.input_size)
        
        # è½¬æ¢ä¸ºRGB
        if len(resized.shape) == 3 and resized.shape[2] == 3:
            rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        else:
            rgb_image = resized
        
        # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
        normalized = np.clip(rgb_image, 0, 255).astype(np.uint8)
        
        return normalized
    
    def _process_detection_result(self, result: Dict) -> Dict:
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        detections = result.get('detections', [])
        
        # è½¬æ¢æ£€æµ‹ç»“æœæ ¼å¼
        processed_detections = []
        for det in detections:
            processed_det = {
                'bbox': det.get('bbox', [0, 0, 0, 0]),
                'confidence': det.get('confidence', 0.0),
                'class_id': det.get('class_id', 0),
                'class_name': det.get('class_name', 'unknown')
            }
            processed_detections.append(processed_det)
        
        return {
            'detections': processed_detections,
            'inference_time_ms': result.get('inference_time_ms', 0),
            'fps': result.get('fps', 0.0),
            'memory_usage': result.get('memory_usage', {}),
            'timestamp': result.get('timestamp', time.time())
        }
    
    def get_device_status(self) -> Optional[Dict]:
        """è·å–K210è®¾å¤‡çŠ¶æ€"""
        if not self.is_connected:
            return None
        
        try:
            status_request = {
                'type': 'status_request',
                'timestamp': time.time()
            }
            
            self._send_message(status_request)
            response = self._receive_message(timeout=3.0)
            
            if response and response.get('type') == 'status_response':
                return response.get('status', {})
            else:
                return None
                
        except Exception as e:
            logger.error(f"è·å–è®¾å¤‡çŠ¶æ€é”™è¯¯: {e}")
            return None
    
    def set_power_mode(self, mode: str) -> bool:
        """è®¾ç½®åŠŸè€—æ¨¡å¼"""
        if not self.is_connected:
            return False
        
        valid_modes = ['performance', 'balanced', 'power_save']
        if mode not in valid_modes:
            logger.error(f"æ— æ•ˆçš„åŠŸè€—æ¨¡å¼: {mode}")
            return False
        
        try:
            power_request = {
                'type': 'power_mode_request',
                'mode': mode,
                'timestamp': time.time()
            }
            
            self._send_message(power_request)
            response = self._receive_message(timeout=2.0)
            
            return response and response.get('success', False)
            
        except Exception as e:
            logger.error(f"è®¾ç½®åŠŸè€—æ¨¡å¼é”™è¯¯: {e}")
            return False

# ä¾¿æ·å‡½æ•°
def create_k210_adapter(config: Optional[Dict] = None) -> K210Adapter:
    """åˆ›å»ºK210é€‚é…å™¨"""
    return K210Adapter(config)

def detect_k210_devices() -> List[str]:
    """æ£€æµ‹å¯ç”¨çš„K210è®¾å¤‡"""
    import serial.tools.list_ports
    
    k210_devices = []
    ports = serial.tools.list_ports.comports()
    
    for port in ports:
        # K210è®¾å¤‡é€šå¸¸ä½¿ç”¨CH340æˆ–FTDIèŠ¯ç‰‡
        if any(chip in port.description.lower() for chip in ['ch340', 'ftdi', 'usb serial']):
            k210_devices.append(port.device)
    
    return k210_devices
```

## ğŸ¯ åº”ç”¨ç¤ºä¾‹

### 1. åŸºç¡€æ£€æµ‹åº”ç”¨

```python
# basic_k210_detection.py
from src.plugins.platform.k210_adapter import create_k210_adapter
import cv2
import numpy as np
import time

def main():
    # åˆ›å»ºK210é€‚é…å™¨
    k210 = create_k210_adapter({
        'serial_port': 'COM3',  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        'confidence_threshold': 0.6,
        'max_detections': 3
    })
    
    # è¿æ¥è®¾å¤‡
    if not k210.connect():
        print("K210è¿æ¥å¤±è´¥")
        return
    
    # è·å–è®¾å¤‡çŠ¶æ€
    status = k210.get_device_status()
    if status:
        print(f"è®¾å¤‡çŠ¶æ€: {status}")
    
    # è®¾ç½®æ€§èƒ½æ¨¡å¼
    k210.set_power_mode('balanced')
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # å‘é€å›¾åƒè¿›è¡Œæ£€æµ‹
            start_time = time.time()
            result = k210.send_image_for_detection(frame)
            end_time = time.time()
            
            if result:
                detections = result['detections']
                inference_time = result['inference_time_ms']
                
                print(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
                print(f"æ¨ç†æ—¶é—´: {inference_time}ms")
                print(f"æ€»æ—¶é—´: {(end_time - start_time) * 1000:.1f}ms")
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                for det in detections:
                    x, y, w, h = det['bbox']
                    confidence = det['confidence']
                    class_name = det['class_name']
                    
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    cv2.putText(frame, f"{class_name}: {confidence:.2f}", 
                               (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('K210 Detection', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
    finally:
        cap.release()
        cv2.destroyAllWindows()
        k210.disconnect()

if __name__ == "__main__":
    main()
```

### 2. æ™ºèƒ½ç›‘æ§åº”ç”¨

```python
# smart_monitoring_k210.py
from src.plugins.platform.k210_adapter import create_k210_adapter
import cv2
import json
import time
from datetime import datetime

class SmartMonitoringSystem:
    def __init__(self, config_path):
        with open(config_path, 'r') as f:
            self.config = json.load(f)
        
        self.k210 = create_k210_adapter(self.config['k210'])
        self.alert_threshold = self.config.get('alert_threshold', 0.8)
        self.monitoring_classes = self.config.get('monitoring_classes', ['person'])
        
        # æ—¥å¿—è®°å½•
        self.detection_log = []
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if not self.k210.connect():
            print("K210è¿æ¥å¤±è´¥")
            return
        
        # è®¾ç½®ä½åŠŸè€—æ¨¡å¼ä»¥å»¶é•¿è¿è¡Œæ—¶é—´
        self.k210.set_power_mode('power_save')
        
        cap = cv2.VideoCapture(0)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    continue
                
                # æ¯2ç§’æ£€æµ‹ä¸€æ¬¡ä»¥èŠ‚çœåŠŸè€—
                time.sleep(2)
                
                result = self.k210.send_image_for_detection(frame)
                
                if result:
                    self._process_detection_result(result, frame)
                
        except KeyboardInterrupt:
            print("ç›‘æ§åœæ­¢")
        finally:
            cap.release()
            self.k210.disconnect()
            self._save_detection_log()
    
    def _process_detection_result(self, result, frame):
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        detections = result['detections']
        timestamp = datetime.now().isoformat()
        
        # ç­›é€‰å…³æ³¨çš„ç±»åˆ«
        relevant_detections = [
            det for det in detections 
            if det['class_name'] in self.monitoring_classes
        ]
        
        if relevant_detections:
            # è®°å½•æ£€æµ‹æ—¥å¿—
            log_entry = {
                'timestamp': timestamp,
                'detections': relevant_detections,
                'inference_time_ms': result['inference_time_ms']
            }
            self.detection_log.append(log_entry)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ¥è­¦
            high_confidence_detections = [
                det for det in relevant_detections 
                if det['confidence'] > self.alert_threshold
            ]
            
            if high_confidence_detections:
                self._trigger_alert(high_confidence_detections, frame)
    
    def _trigger_alert(self, detections, frame):
        """è§¦å‘æŠ¥è­¦"""
        print(f"ğŸš¨ æ£€æµ‹åˆ°é«˜ç½®ä¿¡åº¦ç›®æ ‡: {len(detections)} ä¸ª")
        
        for det in detections:
            print(f"  - {det['class_name']}: {det['confidence']:.2f}")
        
        # ä¿å­˜æŠ¥è­¦å›¾åƒ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        alert_image_path = f"alerts/alert_{timestamp}.jpg"
        cv2.imwrite(alert_image_path, frame)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–æŠ¥è­¦æœºåˆ¶ï¼Œå¦‚:
        # - å‘é€é‚®ä»¶
        # - æ¨é€é€šçŸ¥
        # - è§¦å‘å¤–éƒ¨è®¾å¤‡
    
    def _save_detection_log(self):
        """ä¿å­˜æ£€æµ‹æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_path = f"logs/detection_log_{timestamp}.json"
        
        with open(log_path, 'w') as f:
            json.dump(self.detection_log, f, indent=2)
        
        print(f"æ£€æµ‹æ—¥å¿—å·²ä¿å­˜: {log_path}")

# é…ç½®æ–‡ä»¶ç¤ºä¾‹ (monitoring_config.json)
config_example = {
    "k210": {
        "serial_port": "COM3",
        "confidence_threshold": 0.6,
        "max_detections": 5
    },
    "alert_threshold": 0.8,
    "monitoring_classes": ["person", "car", "bicycle"]
}

if __name__ == "__main__":
    monitor = SmartMonitoringSystem("monitoring_config.json")
    monitor.start_monitoring()
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. è¿æ¥é—®é¢˜
```python
# æ£€æµ‹å¯ç”¨ä¸²å£
from src.plugins.platform.k210_adapter import detect_k210_devices

devices = detect_k210_devices()
print(f"æ£€æµ‹åˆ°çš„K210è®¾å¤‡: {devices}")

# å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è®¾å¤‡:
# 1. æ£€æŸ¥USBè¿æ¥
# 2. å®‰è£…CH340é©±åŠ¨ç¨‹åº
# 3. æ£€æŸ¥è®¾å¤‡ç®¡ç†å™¨ä¸­çš„ä¸²å£
```

#### 2. æ¨¡å‹åŠ è½½å¤±è´¥
```python
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
import os

model_path = "/sd/yolov11n_k210.kmodel"
if os.path.exists(model_path):
    model_size = os.path.getsize(model_path)
    print(f"æ¨¡å‹å¤§å°: {model_size / 1024 / 1024:.2f}MB")
    
    if model_size > 6 * 1024 * 1024:
        print("è­¦å‘Š: æ¨¡å‹è¿‡å¤§ï¼Œå¯èƒ½æ— æ³•åŠ è½½")
else:
    print("æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
```

#### 3. æ€§èƒ½é—®é¢˜
```python
# æ€§èƒ½è¯Šæ–­
def diagnose_performance(k210_adapter):
    status = k210_adapter.get_device_status()
    
    if status:
        print(f"CPUé¢‘ç‡: {status.get('cpu_freq_mhz', 'unknown')}MHz")
        print(f"å†…å­˜ä½¿ç”¨: {status.get('memory_usage', 'unknown')}")
        print(f"æ¸©åº¦: {status.get('temperature', 'unknown')}Â°C")
        
        # å»ºè®®ä¼˜åŒ–ç­–ç•¥
        if status.get('memory_usage', 0) > 0.9:
            print("å»ºè®®: å‡å°‘è¾“å…¥åˆ†è¾¨ç‡æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
        
        if status.get('temperature', 0) > 70:
            print("å»ºè®®: é™ä½CPUé¢‘ç‡æˆ–æ”¹å–„æ•£çƒ­")
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹ä¼˜åŒ–
- **ä½¿ç”¨YOLOv11n**: æœ€é€‚åˆK210çš„è½»é‡çº§æ¨¡å‹
- **INT8é‡åŒ–**: å‡å°‘æ¨¡å‹å¤§å°å’Œå†…å­˜å ç”¨
- **è¾“å…¥åˆ†è¾¨ç‡**: æ¨è64x64ï¼Œæœ€å¤§ä¸è¶…è¿‡96x96
- **ç±»åˆ«æ•°é‡**: é™åˆ¶åœ¨10ä¸ªä»¥å†…ä»¥æé«˜æ€§èƒ½

### 2. ç³»ç»Ÿä¼˜åŒ–
- **å†…å­˜ç®¡ç†**: åŠæ—¶é‡Šæ”¾ä¸ç”¨çš„å†…å­˜
- **åŠŸè€—æ¨¡å¼**: æ ¹æ®åº”ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„åŠŸè€—æ¨¡å¼
- **æ•£çƒ­è®¾è®¡**: ç¡®ä¿è‰¯å¥½çš„æ•£çƒ­ä»¥ç»´æŒæ€§èƒ½

### 3. åº”ç”¨ä¼˜åŒ–
- **æ£€æµ‹é¢‘ç‡**: ä¸éœ€è¦å®æ—¶æ£€æµ‹æ—¶å¯é™ä½é¢‘ç‡
- **é¢„ç­›é€‰**: ä½¿ç”¨ä¼ æ„Ÿå™¨æ•°æ®è¿›è¡Œé¢„ç­›é€‰
- **æ‰¹å¤„ç†**: ç´¯ç§¯å¤šå¸§è¿›è¡Œæ‰¹é‡å¤„ç†

## ğŸš€ è¿›é˜¶åº”ç”¨

### 1. å¤šK210ååŒ
```python
# å¤šK210ååŒå¤„ç†
class MultiK210System:
    def __init__(self, k210_configs):
        self.k210_adapters = []
        for config in k210_configs:
            adapter = create_k210_adapter(config)
            self.k210_adapters.append(adapter)
    
    def parallel_detection(self, images):
        """å¹¶è¡Œæ£€æµ‹å¤šä¸ªå›¾åƒ"""
        results = []
        for i, (adapter, image) in enumerate(zip(self.k210_adapters, images)):
            result = adapter.send_image_for_detection(image)
            results.append(result)
        return results
```

### 2. è¾¹ç¼˜-äº‘ååŒ
```python
# K210è¾¹ç¼˜é¢„ç­›é€‰ + äº‘ç«¯ç²¾ç¡®è¯†åˆ«
class EdgeCloudSystem:
    def __init__(self, k210_adapter, cloud_api):
        self.k210 = k210_adapter
        self.cloud_api = cloud_api
        self.edge_threshold = 0.7
    
    def hybrid_detection(self, image):
        # è¾¹ç¼˜é¢„ç­›é€‰
        edge_result = self.k210.send_image_for_detection(image)
        
        # å¦‚æœè¾¹ç¼˜æ£€æµ‹ç½®ä¿¡åº¦é«˜ï¼Œç›´æ¥è¿”å›
        if edge_result and max([det['confidence'] for det in edge_result['detections']]) > self.edge_threshold:
            return edge_result
        
        # å¦åˆ™å‘é€åˆ°äº‘ç«¯è¿›è¡Œç²¾ç¡®è¯†åˆ«
        cloud_result = self.cloud_api.detect(image)
        return cloud_result
```

---

**æ›´æ–°æ—¥æœŸ**: 2024-01-15  
**ç‰ˆæœ¬**: v1.0  
**ä½œè€…**: YOLOSå¼€å‘å›¢é˜Ÿ  
**æ”¯æŒ**: support@yolos.ai