#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOS YOLOv11æ·±åº¦ä¼˜åŒ–å®æ–½è„šæœ¬
åŸºäºè¯„ä¼°ç»“æœï¼Œä¸“æ³¨äºæ·±åº¦ä¼˜åŒ–å½“å‰YOLOv11ç³»ç»Ÿè€Œéå‡çº§åˆ°YOLO12
"""

import os
import sys
import time
import torch
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import argparse
import yaml
import cv2

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

try:
    from ultralytics import YOLO
    from ultralytics.utils import ops
except ImportError:
    print("é”™è¯¯: ultralyticsæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install ultralytics")
    sys.exit(1)

from src.core.config import YOLOSConfig
from src.models.optimized_yolov11_system import OptimizedYOLOv11System
from src.utils.logging_manager import LoggingManager


class YOLOv11DeepOptimizer:
    """
    YOLOv11æ·±åº¦ä¼˜åŒ–å™¨
    
    å®æ–½ç­–ç•¥:
    1. TensorRTåŠ é€Ÿä¼˜åŒ–
    2. æ¨¡å‹é‡åŒ–å’Œå‰ªæ
    3. åŒ»ç–—åœºæ™¯ä¸“ç”¨è®­ç»ƒ
    4. è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–
    5. å¤šæ¨¡æ€èåˆå¢å¼º
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.logger = LoggingManager().get_logger("YOLOv11Optimizer")
        self.config = self._load_config(config_path)
        self.device = self._get_optimal_device()
        self.optimized_models = {}
        
        self.logger.info("ğŸš€ YOLOv11æ·±åº¦ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        
        # é»˜è®¤ä¼˜åŒ–é…ç½®
        return {
            'optimization': {
                'tensorrt': True,
                'quantization': True,
                'pruning': True,
                'medical_training': True,
                'edge_optimization': True
            },
            'models': {
                'base_model': 'yolo11s.pt',
                'target_platforms': ['pc', 'raspberry_pi', 'jetson_nano', 'esp32']
            },
            'performance': {
                'target_fps': 60,
                'max_memory_mb': 1500,
                'min_accuracy': 0.90
            }
        }
    
    def _get_optimal_device(self) -> str:
        """è·å–æœ€ä¼˜è®¾å¤‡"""
        if torch.cuda.is_available():
            return f"cuda:{torch.cuda.current_device()}"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def optimize_tensorrt(self, model_path: str, output_path: str) -> str:
        """
        TensorRTä¼˜åŒ–
        é¢„æœŸæ•ˆæœ: 2-3å€é€Ÿåº¦æå‡
        """
        self.logger.info("ğŸ”§ å¼€å§‹TensorRTä¼˜åŒ–...")
        
        try:
            # åŠ è½½æ¨¡å‹
            model = YOLO(model_path)
            
            # TensorRTå¯¼å‡º
            tensorrt_path = model.export(
                format='engine',
                device=self.device,
                half=True,  # FP16ç²¾åº¦
                workspace=4,  # 4GBå·¥ä½œç©ºé—´
                verbose=True
            )
            
            # éªŒè¯ä¼˜åŒ–æ•ˆæœ
            original_fps = self._benchmark_model(model_path)
            optimized_fps = self._benchmark_model(tensorrt_path)
            
            speedup = optimized_fps / original_fps if original_fps > 0 else 0
            
            self.logger.info(f"âœ… TensorRTä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"ğŸ“Š åŸå§‹FPS: {original_fps:.1f}")
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–FPS: {optimized_fps:.1f}")
            self.logger.info(f"ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")
            
            return tensorrt_path
            
        except Exception as e:
            self.logger.error(f"âŒ TensorRTä¼˜åŒ–å¤±è´¥: {e}")
            return model_path
    
    def optimize_quantization(self, model_path: str, output_path: str) -> str:
        """
        æ¨¡å‹é‡åŒ–ä¼˜åŒ–
        é¢„æœŸæ•ˆæœ: 50%æ¨¡å‹å¤§å°å‡å°‘ï¼Œ10-15%é€Ÿåº¦æå‡
        """
        self.logger.info("ğŸ”§ å¼€å§‹æ¨¡å‹é‡åŒ–ä¼˜åŒ–...")
        
        try:
            # åŠ è½½æ¨¡å‹
            model = YOLO(model_path)
            
            # INT8é‡åŒ–å¯¼å‡º
            quantized_path = model.export(
                format='onnx',
                int8=True,
                device=self.device,
                verbose=True
            )
            
            # éªŒè¯ä¼˜åŒ–æ•ˆæœ
            original_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            quantized_size = os.path.getsize(quantized_path) / (1024 * 1024)  # MB
            
            compression_ratio = original_size / quantized_size if quantized_size > 0 else 0
            
            self.logger.info(f"âœ… é‡åŒ–ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"ğŸ“Š åŸå§‹å¤§å°: {original_size:.1f}MB")
            self.logger.info(f"ğŸ“Š é‡åŒ–å¤§å°: {quantized_size:.1f}MB")
            self.logger.info(f"ğŸ—œï¸ å‹ç¼©æ¯”: {compression_ratio:.2f}x")
            
            return quantized_path
            
        except Exception as e:
            self.logger.error(f"âŒ é‡åŒ–ä¼˜åŒ–å¤±è´¥: {e}")
            return model_path
    
    def optimize_for_medical_scenarios(self, model_path: str, dataset_path: str) -> str:
        """
        åŒ»ç–—åœºæ™¯ä¸“ç”¨ä¼˜åŒ–
        é’ˆå¯¹è·Œå€’æ£€æµ‹ã€è¯ç‰©è¯†åˆ«ç­‰åœºæ™¯è¿›è¡Œä¸“é—¨è®­ç»ƒ
        """
        self.logger.info("ğŸ¥ å¼€å§‹åŒ»ç–—åœºæ™¯ä¸“ç”¨ä¼˜åŒ–...")
        
        try:
            # åŠ è½½åŸºç¡€æ¨¡å‹
            model = YOLO(model_path)
            
            # åŒ»ç–—åœºæ™¯è®­ç»ƒé…ç½®
            training_config = {
                'data': dataset_path,
                'epochs': 100,
                'imgsz': 640,
                'batch': 16,
                'lr0': 0.01,
                'lrf': 0.1,
                'momentum': 0.937,
                'weight_decay': 0.0005,
                'warmup_epochs': 3,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1,
                'box': 7.5,
                'cls': 0.5,
                'dfl': 1.5,
                'pose': 12.0,
                'kobj': 2.0,
                'label_smoothing': 0.0,
                'nbs': 64,
                'hsv_h': 0.015,
                'hsv_s': 0.7,
                'hsv_v': 0.4,
                'degrees': 0.0,
                'translate': 0.1,
                'scale': 0.5,
                'shear': 0.0,
                'perspective': 0.0,
                'flipud': 0.0,
                'fliplr': 0.5,
                'mosaic': 1.0,
                'mixup': 0.0,
                'copy_paste': 0.0
            }
            
            # å¼€å§‹è®­ç»ƒ
            results = model.train(**training_config)
            
            # ä¿å­˜ä¼˜åŒ–åçš„æ¨¡å‹
            medical_model_path = model_path.replace('.pt', '_medical_optimized.pt')
            model.save(medical_model_path)
            
            self.logger.info(f"âœ… åŒ»ç–—åœºæ™¯ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"ğŸ“Š è®­ç»ƒç»“æœ: {results}")
            
            return medical_model_path
            
        except Exception as e:
            self.logger.error(f"âŒ åŒ»ç–—åœºæ™¯ä¼˜åŒ–å¤±è´¥: {e}")
            return model_path
    
    def optimize_for_edge_devices(self, model_path: str, target_platform: str) -> str:
        """
        è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–
        é’ˆå¯¹ESP32ã€æ ‘è“æ´¾ã€Jetson Nanoç­‰è®¾å¤‡ä¼˜åŒ–
        """
        self.logger.info(f"ğŸ“± å¼€å§‹{target_platform}è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–...")
        
        try:
            model = YOLO(model_path)
            
            # ä¸åŒå¹³å°çš„ä¼˜åŒ–ç­–ç•¥
            platform_configs = {
                'esp32': {
                    'format': 'tflite',
                    'imgsz': 320,
                    'int8': True,
                    'half': False
                },
                'raspberry_pi': {
                    'format': 'onnx',
                    'imgsz': 416,
                    'int8': True,
                    'half': True
                },
                'jetson_nano': {
                    'format': 'engine',
                    'imgsz': 640,
                    'int8': False,
                    'half': True
                }
            }
            
            config = platform_configs.get(target_platform, platform_configs['raspberry_pi'])
            
            # å¯¼å‡ºä¼˜åŒ–æ¨¡å‹
            optimized_path = model.export(**config)
            
            self.logger.info(f"âœ… {target_platform}ä¼˜åŒ–å®Œæˆ!")
            self.logger.info(f"ğŸ“Š ä¼˜åŒ–æ¨¡å‹: {optimized_path}")
            
            return optimized_path
            
        except Exception as e:
            self.logger.error(f"âŒ {target_platform}ä¼˜åŒ–å¤±è´¥: {e}")
            return model_path
    
    def _benchmark_model(self, model_path: str, num_iterations: int = 100) -> float:
        """æ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        try:
            model = YOLO(model_path)
            
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            
            # é¢„çƒ­
            for _ in range(10):
                model(test_image, verbose=False)
            
            # åŸºå‡†æµ‹è¯•
            start_time = time.time()
            for _ in range(num_iterations):
                model(test_image, verbose=False)
            end_time = time.time()
            
            fps = num_iterations / (end_time - start_time)
            return fps
            
        except Exception as e:
            self.logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return 0.0
    
    def run_comprehensive_optimization(self, model_path: str, output_dir: str) -> Dict[str, str]:
        """è¿è¡Œç»¼åˆä¼˜åŒ–"""
        self.logger.info("ğŸš€ å¼€å§‹YOLOv11ç»¼åˆä¼˜åŒ–...")
        
        os.makedirs(output_dir, exist_ok=True)
        results = {}
        
        # 1. TensorRTä¼˜åŒ–
        if self.config['optimization']['tensorrt']:
            tensorrt_path = os.path.join(output_dir, 'yolo11_tensorrt.engine')
            results['tensorrt'] = self.optimize_tensorrt(model_path, tensorrt_path)
        
        # 2. é‡åŒ–ä¼˜åŒ–
        if self.config['optimization']['quantization']:
            quantized_path = os.path.join(output_dir, 'yolo11_quantized.onnx')
            results['quantized'] = self.optimize_quantization(model_path, quantized_path)
        
        # 3. è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–
        if self.config['optimization']['edge_optimization']:
            for platform in self.config['models']['target_platforms']:
                platform_path = os.path.join(output_dir, f'yolo11_{platform}')
                results[f'edge_{platform}'] = self.optimize_for_edge_devices(model_path, platform)
        
        # 4. æ€§èƒ½æŠ¥å‘Š
        self._generate_optimization_report(results, output_dir)
        
        self.logger.info("âœ… YOLOv11ç»¼åˆä¼˜åŒ–å®Œæˆ!")
        return results
    
    def _generate_optimization_report(self, results: Dict[str, str], output_dir: str):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'optimization_report.md')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# YOLOv11ä¼˜åŒ–æŠ¥å‘Š\n\n")
            f.write(f"## ä¼˜åŒ–æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ä¼˜åŒ–ç»“æœ\n\n")
            for opt_type, model_path in results.items():
                f.write(f"- **{opt_type}**: `{model_path}`\n")
            
            f.write("\n## æ€§èƒ½å¯¹æ¯”\n\n")
            f.write("| ä¼˜åŒ–ç±»å‹ | FPS | æ¨¡å‹å¤§å° | å†…å­˜å ç”¨ |\n")
            f.write("|---------|-----|----------|----------|\n")
            
            for opt_type, model_path in results.items():
                if os.path.exists(model_path):
                    fps = self._benchmark_model(model_path, 50)
                    size_mb = os.path.getsize(model_path) / (1024 * 1024)
                    f.write(f"| {opt_type} | {fps:.1f} | {size_mb:.1f}MB | - |\n")
        
        self.logger.info(f"ğŸ“Š ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="YOLOv11æ·±åº¦ä¼˜åŒ–å·¥å…·")
    parser.add_argument('--model', type=str, default='yolo11s.pt', help='åŸºç¡€æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output', type=str, default='./optimized_models', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--tensorrt', action='store_true', help='å¯ç”¨TensorRTä¼˜åŒ–')
    parser.add_argument('--quantize', action='store_true', help='å¯ç”¨é‡åŒ–ä¼˜åŒ–')
    parser.add_argument('--edge', action='store_true', help='å¯ç”¨è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–')
    parser.add_argument('--medical', action='store_true', help='å¯ç”¨åŒ»ç–—åœºæ™¯ä¼˜åŒ–')
    parser.add_argument('--benchmark', action='store_true', help='è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = YOLOv11DeepOptimizer(args.config)
    
    print("ğŸš€ YOLOS YOLOv11æ·±åº¦ä¼˜åŒ–å·¥å…·")
    print("=" * 50)
    print(f"ğŸ“± åŸºç¡€æ¨¡å‹: {args.model}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    print(f"ğŸ”§ è®¾å¤‡: {optimizer.device}")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("ğŸ’¡ æ­£åœ¨ä¸‹è½½é»˜è®¤æ¨¡å‹...")
        try:
            model = YOLO(args.model)  # è‡ªåŠ¨ä¸‹è½½
            print(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {args.model}")
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return
    
    # è¿è¡Œä¼˜åŒ–
    if args.benchmark:
        print("\nğŸ“Š è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        fps = optimizer._benchmark_model(args.model)
        print(f"ğŸ“ˆ åŸºå‡†FPS: {fps:.1f}")
    
    if any([args.tensorrt, args.quantize, args.edge, args.medical]):
        print("\nğŸ”§ å¼€å§‹ä¼˜åŒ–...")
        results = {}
        
        if args.tensorrt:
            results['tensorrt'] = optimizer.optimize_tensorrt(args.model, args.output)
        
        if args.quantize:
            results['quantized'] = optimizer.optimize_quantization(args.model, args.output)
        
        if args.edge:
            for platform in ['raspberry_pi', 'jetson_nano']:
                results[f'edge_{platform}'] = optimizer.optimize_for_edge_devices(args.model, platform)
        
        print("\nâœ… ä¼˜åŒ–å®Œæˆ!")
        for opt_type, path in results.items():
            print(f"ğŸ“ {opt_type}: {path}")
    
    else:
        # è¿è¡Œç»¼åˆä¼˜åŒ–
        print("\nğŸš€ è¿è¡Œç»¼åˆä¼˜åŒ–...")
        results = optimizer.run_comprehensive_optimization(args.model, args.output)
        
        print("\nğŸ‰ æ‰€æœ‰ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output}")


if __name__ == "__main__":
    main()