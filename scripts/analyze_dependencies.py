#!/usr/bin/env python3
"""
YOLOSé¡¹ç›®ä¾èµ–åˆ†æå·¥å…·
æ£€æŸ¥å¾ªç¯ä¾èµ–ã€é‡å¤è®¾è®¡å’Œæ¶æ„é—®é¢˜
"""

import os
import ast
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple
import json
from collections import defaultdict, deque
import re

class DependencyAnalyzer:
    """ä¾èµ–å…³ç³»åˆ†æå™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.src_root = self.project_root / "src"
        self.dependencies = defaultdict(set)
        self.modules = {}
        self.circular_deps = []
        self.redundant_modules = []
        self.complexity_issues = []
        
    def analyze_project(self):
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        print("ğŸ” å¼€å§‹åˆ†æYOLOSé¡¹ç›®ä¾èµ–å…³ç³»...")
        
        # 1. æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        self._scan_python_files()
        
        # 2. åˆ†æå¯¼å…¥ä¾èµ–
        self._analyze_imports()
        
        # 3. æ£€æŸ¥å¾ªç¯ä¾èµ–
        self._detect_circular_dependencies()
        
        # 4. æ£€æŸ¥é‡å¤å’Œå†—ä½™
        self._detect_redundancy()
        
        # 5. åˆ†æå¤æ‚åº¦
        self._analyze_complexity()
        
        # 6. ç”ŸæˆæŠ¥å‘Š
        self._generate_report()
        
    def _scan_python_files(self):
        """æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶"""
        print("ğŸ“ æ‰«æPythonæ–‡ä»¶...")
        
        for py_file in self.project_root.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # è§£æAST
                tree = ast.parse(content)
                
                # è·å–æ¨¡å—è·¯å¾„
                module_path = self._get_module_path(py_file)
                
                self.modules[module_path] = {
                    'file_path': str(py_file),
                    'ast': tree,
                    'content': content,
                    'imports': [],
                    'classes': [],
                    'functions': [],
                    'lines': len(content.splitlines())
                }
                
                # åˆ†ææ¨¡å—å†…å®¹
                self._analyze_module_content(module_path, tree)
                
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è§£ææ–‡ä»¶ {py_file}: {e}")
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            '__pycache__',
            '.git',
            'yolos_env',
            'archive',
            'logs',
            'test_results'
        ]
        
        return any(pattern in str(file_path) for pattern in skip_patterns)
    
    def _get_module_path(self, file_path: Path) -> str:
        """è·å–æ¨¡å—è·¯å¾„"""
        try:
            rel_path = file_path.relative_to(self.project_root)
            module_parts = list(rel_path.parts[:-1]) + [rel_path.stem]
            return '.'.join(module_parts)
        except ValueError:
            return str(file_path.stem)
    
    def _analyze_module_content(self, module_path: str, tree: ast.AST):
        """åˆ†ææ¨¡å—å†…å®¹"""
        module_info = self.modules[module_path]
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.Import, ast.ImportFrom)):
                self._extract_imports(module_path, node)
            elif isinstance(node, ast.ClassDef):
                module_info['classes'].append(node.name)
            elif isinstance(node, ast.FunctionDef):
                module_info['functions'].append(node.name)
    
    def _extract_imports(self, module_path: str, node: ast.AST):
        """æå–å¯¼å…¥ä¿¡æ¯"""
        if isinstance(node, ast.Import):
            for alias in node.names:
                import_name = alias.name
                self.dependencies[module_path].add(import_name)
                self.modules[module_path]['imports'].append(import_name)
                
        elif isinstance(node, ast.ImportFrom):
            if node.module:
                import_name = node.module
                self.dependencies[module_path].add(import_name)
                self.modules[module_path]['imports'].append(import_name)
    
    def _analyze_imports(self):
        """åˆ†æå¯¼å…¥ä¾èµ–"""
        print("ğŸ”— åˆ†æå¯¼å…¥ä¾èµ–...")
        
        # è¿‡æ»¤å†…éƒ¨ä¾èµ–
        internal_deps = defaultdict(set)
        
        for module, deps in self.dependencies.items():
            for dep in deps:
                # åªå…³æ³¨é¡¹ç›®å†…éƒ¨ä¾èµ–
                if self._is_internal_dependency(dep):
                    internal_deps[module].add(dep)
        
        self.dependencies = internal_deps
    
    def _is_internal_dependency(self, dep_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå†…éƒ¨ä¾èµ–"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡¹ç›®å†…éƒ¨æ¨¡å—
        internal_prefixes = ['src', 'config', 'scripts', 'tests']
        
        return any(dep_name.startswith(prefix) for prefix in internal_prefixes) or \
               dep_name in self.modules
    
    def _detect_circular_dependencies(self):
        """æ£€æµ‹å¾ªç¯ä¾èµ–"""
        print("ğŸ”„ æ£€æµ‹å¾ªç¯ä¾èµ–...")
        
        def dfs(node, path, visited, rec_stack):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            for neighbor in self.dependencies.get(node, []):
                if neighbor in self.modules:
                    if neighbor in rec_stack:
                        # æ‰¾åˆ°å¾ªç¯ä¾èµ–
                        cycle_start = path.index(neighbor)
                        cycle = path[cycle_start:] + [neighbor]
                        self.circular_deps.append(cycle)
                    elif neighbor not in visited:
                        dfs(neighbor, path[:], visited, rec_stack)
            
            rec_stack.remove(node)
        
        visited = set()
        for module in self.modules:
            if module not in visited:
                dfs(module, [], visited, set())
    
    def _detect_redundancy(self):
        """æ£€æµ‹é‡å¤å’Œå†—ä½™"""
        print("ğŸ” æ£€æµ‹é‡å¤å’Œå†—ä½™...")
        
        # 1. æ£€æŸ¥ç›¸ä¼¼çš„ç±»åå’Œå‡½æ•°å
        all_classes = defaultdict(list)
        all_functions = defaultdict(list)
        
        for module_path, module_info in self.modules.items():
            for class_name in module_info['classes']:
                all_classes[class_name].append(module_path)
            for func_name in module_info['functions']:
                all_functions[func_name].append(module_path)
        
        # æ‰¾å‡ºé‡å¤çš„ç±»å’Œå‡½æ•°
        duplicate_classes = {name: modules for name, modules in all_classes.items() if len(modules) > 1}
        duplicate_functions = {name: modules for name, modules in all_functions.items() if len(modules) > 1}
        
        # 2. æ£€æŸ¥ç›¸ä¼¼çš„æ¨¡å—åŠŸèƒ½
        self._detect_similar_modules()
        
        self.redundant_modules.extend([
            {'type': 'duplicate_classes', 'data': duplicate_classes},
            {'type': 'duplicate_functions', 'data': duplicate_functions}
        ])
    
    def _detect_similar_modules(self):
        """æ£€æµ‹ç›¸ä¼¼æ¨¡å—"""
        # åŸºäºæ–‡ä»¶åå’ŒåŠŸèƒ½ç›¸ä¼¼æ€§æ£€æµ‹
        gui_modules = []
        detector_modules = []
        training_modules = []
        
        for module_path, module_info in self.modules.items():
            if 'gui' in module_path.lower():
                gui_modules.append(module_path)
            elif 'detect' in module_path.lower() or 'recognition' in module_path.lower():
                detector_modules.append(module_path)
            elif 'train' in module_path.lower():
                training_modules.append(module_path)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡å¤šç›¸ä¼¼æ¨¡å—
        if len(gui_modules) > 3:
            self.redundant_modules.append({
                'type': 'excessive_gui_modules',
                'data': gui_modules,
                'recommendation': 'è€ƒè™‘åˆå¹¶ç›¸ä¼¼çš„GUIæ¨¡å—'
            })
        
        if len(detector_modules) > 5:
            self.redundant_modules.append({
                'type': 'excessive_detector_modules', 
                'data': detector_modules,
                'recommendation': 'è€ƒè™‘ç»Ÿä¸€æ£€æµ‹å™¨æ¥å£'
            })
    
    def _analyze_complexity(self):
        """åˆ†æå¤æ‚åº¦"""
        print("ğŸ“Š åˆ†æä»£ç å¤æ‚åº¦...")
        
        for module_path, module_info in self.modules.items():
            # 1. æ–‡ä»¶è¡Œæ•°å¤æ‚åº¦
            if module_info['lines'] > 500:
                self.complexity_issues.append({
                    'type': 'large_file',
                    'module': module_path,
                    'lines': module_info['lines'],
                    'severity': 'high' if module_info['lines'] > 1000 else 'medium'
                })
            
            # 2. å¯¼å…¥æ•°é‡å¤æ‚åº¦
            if len(module_info['imports']) > 20:
                self.complexity_issues.append({
                    'type': 'too_many_imports',
                    'module': module_path,
                    'import_count': len(module_info['imports']),
                    'severity': 'high' if len(module_info['imports']) > 30 else 'medium'
                })
            
            # 3. ç±»å’Œå‡½æ•°æ•°é‡
            total_definitions = len(module_info['classes']) + len(module_info['functions'])
            if total_definitions > 20:
                self.complexity_issues.append({
                    'type': 'too_many_definitions',
                    'module': module_path,
                    'definition_count': total_definitions,
                    'severity': 'medium'
                })
    
    def _generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        report = {
            'project_summary': {
                'total_modules': len(self.modules),
                'total_dependencies': sum(len(deps) for deps in self.dependencies.values()),
                'circular_dependencies': len(self.circular_deps),
                'redundancy_issues': len(self.redundant_modules),
                'complexity_issues': len(self.complexity_issues)
            },
            'circular_dependencies': self.circular_deps,
            'redundant_modules': self.redundant_modules,
            'complexity_issues': self.complexity_issues,
            'module_details': {}
        }
        
        # æ·»åŠ æ¨¡å—è¯¦æƒ…
        for module_path, module_info in self.modules.items():
            report['module_details'][module_path] = {
                'file_path': module_info['file_path'],
                'lines': module_info['lines'],
                'imports': len(module_info['imports']),
                'classes': len(module_info['classes']),
                'functions': len(module_info['functions'])
            }
        
        # ä¿å­˜æŠ¥å‘Š
        docs_dir = self.project_root / "docs"
        docs_dir.mkdir(exist_ok=True)
        report_file = docs_dir / "dependency_analysis_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self._generate_markdown_report(report)
        
        print(f"âœ… åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    def _generate_markdown_report(self, report: dict):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        md_content = f"""# YOLOSé¡¹ç›®ä¾èµ–åˆ†ææŠ¥å‘Š

## ğŸ“Š é¡¹ç›®æ¦‚è§ˆ

- **æ€»æ¨¡å—æ•°**: {report['project_summary']['total_modules']}
- **æ€»ä¾èµ–æ•°**: {report['project_summary']['total_dependencies']}
- **å¾ªç¯ä¾èµ–**: {report['project_summary']['circular_dependencies']} ä¸ª
- **å†—ä½™é—®é¢˜**: {report['project_summary']['redundancy_issues']} ä¸ª
- **å¤æ‚åº¦é—®é¢˜**: {report['project_summary']['complexity_issues']} ä¸ª

## ğŸ”„ å¾ªç¯ä¾èµ–åˆ†æ

"""
        
        if report['circular_dependencies']:
            md_content += "âš ï¸ **å‘ç°å¾ªç¯ä¾èµ–**:\n\n"
            for i, cycle in enumerate(report['circular_dependencies'], 1):
                md_content += f"{i}. {' â†’ '.join(cycle)}\n"
        else:
            md_content += "âœ… **æœªå‘ç°å¾ªç¯ä¾èµ–**\n"
        
        md_content += "\n## ğŸ” å†—ä½™åˆ†æ\n\n"
        
        if report['redundant_modules']:
            for redundancy in report['redundant_modules']:
                if redundancy['type'] == 'duplicate_classes':
                    md_content += "### é‡å¤ç±»å\n\n"
                    for class_name, modules in redundancy['data'].items():
                        md_content += f"- **{class_name}**: {', '.join(modules)}\n"
                elif redundancy['type'] == 'duplicate_functions':
                    md_content += "### é‡å¤å‡½æ•°å\n\n"
                    for func_name, modules in redundancy['data'].items():
                        md_content += f"- **{func_name}**: {', '.join(modules)}\n"
                elif redundancy['type'] == 'excessive_gui_modules':
                    md_content += f"### è¿‡å¤šGUIæ¨¡å—\n\n"
                    md_content += f"å‘ç° {len(redundancy['data'])} ä¸ªGUIæ¨¡å—:\n"
                    for module in redundancy['data']:
                        md_content += f"- {module}\n"
                    md_content += f"\n**å»ºè®®**: {redundancy['recommendation']}\n\n"
        else:
            md_content += "âœ… **æœªå‘ç°æ˜æ˜¾å†—ä½™**\n"
        
        md_content += "\n## ğŸ“Š å¤æ‚åº¦åˆ†æ\n\n"
        
        if report['complexity_issues']:
            for issue in report['complexity_issues']:
                severity_icon = "ğŸ”´" if issue['severity'] == 'high' else "ğŸŸ¡"
                md_content += f"{severity_icon} **{issue['type']}**: {issue['module']}\n"
                
                if issue['type'] == 'large_file':
                    md_content += f"  - è¡Œæ•°: {issue['lines']}\n"
                elif issue['type'] == 'too_many_imports':
                    md_content += f"  - å¯¼å…¥æ•°: {issue['import_count']}\n"
                elif issue['type'] == 'too_many_definitions':
                    md_content += f"  - å®šä¹‰æ•°: {issue['definition_count']}\n"
                md_content += "\n"
        else:
            md_content += "âœ… **å¤æ‚åº¦åœ¨åˆç†èŒƒå›´å†…**\n"
        
        md_content += f"""
## ğŸ“‹ æ¨¡å—è¯¦æƒ…

| æ¨¡å— | è¡Œæ•° | å¯¼å…¥ | ç±» | å‡½æ•° |
|------|------|------|----|----- |
"""
        
        for module_path, details in report['module_details'].items():
            md_content += f"| {module_path} | {details['lines']} | {details['imports']} | {details['classes']} | {details['functions']} |\n"
        
        md_content += f"""
## ğŸ¯ ä¼˜åŒ–å»ºè®®

### é«˜ä¼˜å…ˆçº§
1. **è§£å†³å¾ªç¯ä¾èµ–**: é‡æ„æ¨¡å—é—´çš„ä¾èµ–å…³ç³»
2. **åˆå¹¶é‡å¤æ¨¡å—**: æ¶ˆé™¤åŠŸèƒ½é‡å¤çš„æ¨¡å—
3. **æ‹†åˆ†å¤§æ–‡ä»¶**: å°†è¶…è¿‡500è¡Œçš„æ–‡ä»¶è¿›è¡Œæ¨¡å—åŒ–æ‹†åˆ†

### ä¸­ä¼˜å…ˆçº§
1. **å‡å°‘å¯¼å…¥æ•°é‡**: ä¼˜åŒ–æ¨¡å—é—´çš„è€¦åˆåº¦
2. **ç»Ÿä¸€æ¥å£è®¾è®¡**: å»ºç«‹æ ‡å‡†åŒ–çš„æ¨¡å—æ¥å£
3. **ä»£ç é‡æ„**: æé«˜ä»£ç çš„å†…èšæ€§

### ä½ä¼˜å…ˆçº§
1. **æ€§èƒ½ä¼˜åŒ–**: åŸºäºå®é™…ä½¿ç”¨æƒ…å†µä¼˜åŒ–æ€§èƒ½
2. **æ–‡æ¡£å®Œå–„**: è¡¥å……æ¨¡å—é—´çš„ä¾èµ–å…³ç³»æ–‡æ¡£

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        md_file = self.project_root / "docs" / "dependency_analysis_report.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)

def main():
    """ä¸»å‡½æ•°"""
    analyzer = DependencyAnalyzer()
    analyzer.analyze_project()

if __name__ == "__main__":
    main()