#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èšç„¦çš„ä¾èµ–åˆ†æå·¥å…·
åªåˆ†æé¡¹ç›®æ ¸å¿ƒä»£ç ï¼Œæ’é™¤ç¬¬ä¸‰æ–¹åº“
"""

import os
import ast
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Set

class FocusedDependencyAnalyzer:
    """èšç„¦ä¾èµ–åˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.imports: Dict[str, Set[str]] = defaultdict(set)
        self.files: List[str] = []
        
        # åªåˆ†æè¿™äº›ç›®å½•
        self.include_dirs = {'src', 'tests', 'examples', 'scripts', 'configs'}
        # æ’é™¤è¿™äº›ç›®å½•
        self.exclude_dirs = {'yolos_env', '__pycache__', '.git', 'node_modules', 'archive'}
        
    def scan_project(self):
        """æ‰«æé¡¹ç›®æ–‡ä»¶"""
        print("ğŸ” æ‰«æé¡¹ç›®æ ¸å¿ƒæ–‡ä»¶...")
        
        for py_file in self.project_root.rglob("*.py"):
            if not self._should_include_file(py_file):
                continue
                
            rel_path = str(py_file.relative_to(self.project_root)).replace('\\', '/')
            self.files.append(rel_path)
            
            try:
                self._analyze_file(py_file, rel_path)
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {rel_path}: {e}")
        
        print(f"ğŸ“ æ‰«æå®Œæˆï¼Œå…± {len(self.files)} ä¸ªæ ¸å¿ƒæ–‡ä»¶")
    
    def _should_include_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åŒ…å«æ–‡ä»¶"""
        parts = file_path.relative_to(self.project_root).parts
        
        # æ’é™¤ç‰¹å®šç›®å½•
        if any(exclude in parts for exclude in self.exclude_dirs):
            return False
        
        # æ ¹ç›®å½•çš„Pythonæ–‡ä»¶ä¹ŸåŒ…å«
        if len(parts) == 1:
            return True
            
        # åŒ…å«ç‰¹å®šç›®å½•
        return parts[0] in self.include_dirs
    
    def _analyze_file(self, file_path: Path, rel_path: str):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except:
                return
        
        try:
            tree = ast.parse(content)
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        # åªè®°å½•é¡¹ç›®å†…çš„å¯¼å…¥
                        if self._is_project_import(alias.name):
                            self.imports[rel_path].add(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    if node.module and self._is_project_import(node.module):
                        self.imports[rel_path].add(node.module)
        except SyntaxError:
            pass  # è·³è¿‡è¯­æ³•é”™è¯¯çš„æ–‡ä»¶
    
    def _is_project_import(self, import_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯é¡¹ç›®å†…çš„å¯¼å…¥"""
        # é¡¹ç›®å†…çš„æ¨¡å—é€šå¸¸ä»¥è¿™äº›å¼€å¤´
        project_prefixes = ['src', 'tests', 'examples', 'scripts', 'configs']
        
        # ç›¸å¯¹å¯¼å…¥
        if import_name.startswith('.'):
            return True
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®æ¨¡å—
        return any(import_name.startswith(prefix) for prefix in project_prefixes)
    
    def find_duplicate_classes(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾é‡å¤çš„ç±»å®šä¹‰"""
        print("ğŸ” æ£€æŸ¥é‡å¤ç±»...")
        
        class_definitions = defaultdict(list)
        
        for file_path in self.files:
            try:
                full_path = self.project_root / file_path
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(full_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except:
                    continue
            
            try:
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        class_definitions[node.name].append(file_path)
            except SyntaxError:
                continue
        
        # åªè¿”å›æœ‰é‡å¤çš„ç±»
        duplicates = {name: files for name, files in class_definitions.items() 
                     if len(files) > 1}
        
        return duplicates
    
    def find_duplicate_functions(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾é‡å¤çš„å‡½æ•°å®šä¹‰"""
        print("ğŸ” æ£€æŸ¥é‡å¤å‡½æ•°...")
        
        func_definitions = defaultdict(list)
        
        for file_path in self.files:
            try:
                full_path = self.project_root / file_path
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                try:
                    with open(full_path, 'r', encoding='gbk') as f:
                        content = f.read()
                except:
                    continue
            
            try:
                tree = ast.parse(content)
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        # æ’é™¤å¸¸è§çš„å‡½æ•°å
                        if node.name not in ['__init__', '__str__', '__repr__', 'main', 'test']:
                            func_definitions[node.name].append(file_path)
            except SyntaxError:
                continue
        
        # åªè¿”å›æœ‰é‡å¤çš„å‡½æ•°
        duplicates = {name: files for name, files in func_definitions.items() 
                     if len(files) > 1}
        
        return duplicates
    
    def analyze_complexity(self) -> Dict[str, int]:
        """åˆ†ææ–‡ä»¶å¤æ‚åº¦"""
        print("ğŸ“Š åˆ†æä»£ç å¤æ‚åº¦...")
        
        complexity = {}
        
        for file_path in self.files:
            try:
                full_path = self.project_root / file_path
                with open(full_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
            except UnicodeDecodeError:
                try:
                    with open(full_path, 'r', encoding='gbk') as f:
                        lines = f.readlines()
                except:
                    complexity[file_path] = 0
                    continue
            
            # è®¡ç®—å¤æ‚åº¦
            line_count = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
            
            try:
                tree = ast.parse(''.join(lines))
                class_count = len([node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)])
                func_count = len([node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)])
                
                complexity[file_path] = line_count + class_count * 5 + func_count * 2
            except:
                complexity[file_path] = line_count
        
        return complexity
    
    def check_naming_consistency(self) -> Dict[str, List[str]]:
        """æ£€æŸ¥å‘½åä¸€è‡´æ€§"""
        print("ğŸ“ æ£€æŸ¥å‘½åä¸€è‡´æ€§...")
        
        issues = defaultdict(list)
        
        for file_path in self.files:
            # æ£€æŸ¥æ–‡ä»¶å‘½å
            filename = Path(file_path).stem
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¸€è‡´çš„å‘½åé£æ ¼
            if '_' in filename and any(c.isupper() for c in filename):
                issues['mixed_case_files'].append(file_path)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡é•¿çš„æ–‡ä»¶å
            if len(filename) > 30:
                issues['long_filenames'].append(file_path)
        
        return dict(issues)
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ YOLOSé¡¹ç›®æ ¸å¿ƒæ¶æ„åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # é‡å¤ç±»
        duplicate_classes = self.find_duplicate_classes()
        print(f"\nğŸ” é‡å¤ç±»æ£€æŸ¥:")
        if duplicate_classes:
            print(f"âŒ å‘ç° {len(duplicate_classes)} ä¸ªé‡å¤ç±»:")
            for class_name, files in list(duplicate_classes.items())[:10]:
                print(f"   - {class_name}: {', '.join(files)}")
            if len(duplicate_classes) > 10:
                print(f"   ... è¿˜æœ‰ {len(duplicate_classes) - 10} ä¸ª")
        else:
            print("âœ… æœªå‘ç°é‡å¤ç±»å®šä¹‰")
        
        # é‡å¤å‡½æ•°
        duplicate_functions = self.find_duplicate_functions()
        print(f"\nğŸ”§ é‡å¤å‡½æ•°æ£€æŸ¥:")
        if duplicate_functions:
            print(f"âŒ å‘ç° {len(duplicate_functions)} ä¸ªé‡å¤å‡½æ•°:")
            for func_name, files in list(duplicate_functions.items())[:10]:
                print(f"   - {func_name}: {', '.join(files)}")
            if len(duplicate_functions) > 10:
                print(f"   ... è¿˜æœ‰ {len(duplicate_functions) - 10} ä¸ª")
        else:
            print("âœ… æœªå‘ç°é‡å¤å‡½æ•°å®šä¹‰")
        
        # å¤æ‚åº¦åˆ†æ
        complexity = self.analyze_complexity()
        high_complexity = {f: c for f, c in complexity.items() if c > 200}
        
        print(f"\nğŸ“Š å¤æ‚åº¦åˆ†æ:")
        print(f"   æ€»æ ¸å¿ƒæ–‡ä»¶æ•°: {len(self.files)}")
        print(f"   é«˜å¤æ‚åº¦æ–‡ä»¶ (>200): {len(high_complexity)}")
        
        if high_complexity:
            print("   æœ€å¤æ‚çš„æ–‡ä»¶:")
            sorted_complex = sorted(high_complexity.items(), key=lambda x: x[1], reverse=True)
            for file, comp in sorted_complex[:10]:
                print(f"     - {file}: {comp}")
        
        # å‘½åä¸€è‡´æ€§
        naming_issues = self.check_naming_consistency()
        print(f"\nğŸ“ å‘½åä¸€è‡´æ€§æ£€æŸ¥:")
        if naming_issues:
            for issue_type, files in naming_issues.items():
                print(f"   - {issue_type}: {len(files)} ä¸ªæ–‡ä»¶")
                for file in files[:5]:
                    print(f"     * {file}")
                if len(files) > 5:
                    print(f"     ... è¿˜æœ‰ {len(files) - 5} ä¸ª")
        else:
            print("âœ… å‘½åé£æ ¼ä¸€è‡´")
        
        # é¡¹ç›®ç»“æ„åˆ†æ
        print(f"\nğŸ“ é¡¹ç›®ç»“æ„åˆ†æ:")
        dir_counts = defaultdict(int)
        for file in self.files:
            if '/' in file:
                dir_counts[file.split('/')[0]] += 1
            else:
                dir_counts['root'] += 1
        
        for dir_name, count in sorted(dir_counts.items()):
            print(f"   - {dir_name}: {count} ä¸ªæ–‡ä»¶")
        
        # ä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ æ¶æ„ä¼˜åŒ–å»ºè®®:")
        suggestions = []
        
        if duplicate_classes:
            suggestions.append("åˆå¹¶é‡å¤ç±»å®šä¹‰ï¼Œæå–å…¬å…±åŸºç±»æˆ–æ¥å£")
        if duplicate_functions:
            suggestions.append("é‡æ„é‡å¤å‡½æ•°ï¼Œæå–åˆ°å·¥å…·æ¨¡å—ä¸­")
        if high_complexity:
            suggestions.append("æ‹†åˆ†é«˜å¤æ‚åº¦æ–‡ä»¶ï¼Œéµå¾ªå•ä¸€èŒè´£åŸåˆ™")
        if naming_issues:
            suggestions.append("ç»Ÿä¸€å‘½åé£æ ¼ï¼Œå»ºè®®ä½¿ç”¨snake_case")
        
        if suggestions:
            for i, suggestion in enumerate(suggestions, 1):
                print(f"   {i}. {suggestion}")
        else:
            print("   âœ… é¡¹ç›®æ¶æ„è‰¯å¥½ï¼Œç¬¦åˆæœ€ä½³å®è·µ")
        
        # é«˜å†…èšä½è€¦åˆè¯„ä¼°
        print(f"\nğŸ—ï¸ æ¶æ„è´¨é‡è¯„ä¼°:")
        total_issues = len(duplicate_classes) + len(duplicate_functions) + len(high_complexity)
        
        if total_issues == 0:
            print("   âœ… ä¼˜ç§€ - é«˜å†…èšä½è€¦åˆï¼Œæ¶æ„æ¸…æ™°")
        elif total_issues <= 5:
            print("   âš ï¸ è‰¯å¥½ - æœ‰å°‘é‡ä¼˜åŒ–ç©ºé—´")
        elif total_issues <= 15:
            print("   âš ï¸ ä¸€èˆ¬ - éœ€è¦é‡æ„ä¼˜åŒ–")
        else:
            print("   âŒ éœ€è¦æ”¹è¿› - å­˜åœ¨è¾ƒå¤šæ¶æ„é—®é¢˜")

def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    analyzer = FocusedDependencyAnalyzer(project_root)
    
    try:
        analyzer.scan_project()
        analyzer.generate_report()
        
        print(f"\nğŸ¯ åˆ†æå®Œæˆï¼é¡¹ç›®å·²å‡†å¤‡å¥½è¿›è¡ŒGitHubæ¨é€ã€‚")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())