#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºè®­ç»ƒç³»ç»Ÿå¿«é€Ÿå¯åŠ¨è„šæœ¬
ä¸€é”®å®Œæˆæ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•
"""

import os
import sys
import argparse
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.download_training_datasets import DatasetDownloader
from src.models.pretrained_model_loader import PretrainedModelLoader
from src.training.enhanced_human_trainer import EnhancedHumanTrainer, TrainingConfig
from src.recognition.improved_multimodal_detector import create_improved_multimodal_system

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QuickStartManager:
    """å¿«é€Ÿå¯åŠ¨ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.datasets_dir = self.base_dir / "datasets"
        self.models_dir = self.base_dir / "models"
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.datasets_dir.mkdir(parents=True, exist_ok=True)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        (self.models_dir / "pretrained").mkdir(parents=True, exist_ok=True)
        (self.models_dir / "human_recognition").mkdir(parents=True, exist_ok=True)
    
    def step1_prepare_environment(self):
        """æ­¥éª¤1: å‡†å¤‡ç¯å¢ƒ"""
        logger.info("=== æ­¥éª¤1: å‡†å¤‡ç¯å¢ƒ ===")
        
        # æ£€æŸ¥ä¾èµ–
        required_packages = [
            'torch', 'torchvision', 'opencv-python', 'numpy', 
            'scikit-learn', 'albumentations', 'tqdm', 'requests'
        ]
        
        missing_packages = []
        for package in required_packages:
            try:
                __import__(package.replace('-', '_'))
                logger.info(f"âœ“ {package} å·²å®‰è£…")
            except ImportError:
                missing_packages.append(package)
                logger.warning(f"âœ— {package} æœªå®‰è£…")
        
        if missing_packages:
            logger.error(f"è¯·å®‰è£…ç¼ºå¤±çš„åŒ…: pip install {' '.join(missing_packages)}")
            return False
        
        logger.info("ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
        return True
    
    def step2_download_datasets(self, use_synthetic: bool = True):
        """æ­¥éª¤2: ä¸‹è½½æ•°æ®é›†"""
        logger.info("=== æ­¥éª¤2: ä¸‹è½½è®­ç»ƒæ•°æ®é›† ===")
        
        downloader = DatasetDownloader(str(self.datasets_dir))
        
        if use_synthetic:
            # åˆ›å»ºåˆæˆæ•°æ®é›†ç”¨äºå¿«é€Ÿæµ‹è¯•
            logger.info("åˆ›å»ºåˆæˆæ•°æ®é›†...")
            success = downloader.create_synthetic_dataset(1000)
            if success:
                logger.info("âœ“ åˆæˆæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
            else:
                logger.error("âœ— åˆæˆæ•°æ®é›†åˆ›å»ºå¤±è´¥")
                return False
        else:
            # ä¸‹è½½çœŸå®æ•°æ®é›†
            logger.info("ä¸‹è½½çœŸå®æ•°æ®é›†...")
            datasets_to_download = ['stanford40', 'coco_pose']
            
            for dataset_name in datasets_to_download:
                logger.info(f"ä¸‹è½½ {dataset_name}...")
                success = downloader.download_dataset(dataset_name)
                if success:
                    logger.info(f"âœ“ {dataset_name} ä¸‹è½½æˆåŠŸ")
                else:
                    logger.warning(f"âœ— {dataset_name} ä¸‹è½½å¤±è´¥")
        
        return True
    
    def step3_download_pretrained_models(self):
        """æ­¥éª¤3: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹"""
        logger.info("=== æ­¥éª¤3: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ ===")
        
        model_loader = PretrainedModelLoader(str(self.models_dir / "pretrained"))
        
        # ä¸‹è½½æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹
        model_loader.download_all_models()
        
        # éªŒè¯ä¸‹è½½
        model_loader.list_available_models()
        
        logger.info("é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å®Œæˆ")
        return True
    
    def step4_train_model(self, 
                         dataset_name: str = "synthetic_human_actions",
                         epochs: int = 20,
                         batch_size: int = 8):
        """æ­¥éª¤4: è®­ç»ƒæ¨¡å‹"""
        logger.info("=== æ­¥éª¤4: è®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹ ===")
        
        # è®­ç»ƒé…ç½®
        config = TrainingConfig(
            batch_size=batch_size,
            learning_rate=0.001,
            epochs=epochs,
            validation_split=0.2,
            early_stopping_patience=10
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = EnhancedHumanTrainer(config)
        
        # æ•°æ®é›†é…ç½®
        dataset_configs = [
            {
                'name': dataset_name,
                'path': str(self.datasets_dir / dataset_name),
                'format': 'custom',
                'description': f'{dataset_name} æ•°æ®é›†'
            }
        ]
        
        try:
            # å¼€å§‹è®­ç»ƒ
            logger.info(f"å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œæ•°æ®é›†: {dataset_name}")
            model_path = trainer.train(
                dataset_configs, 
                output_dir=str(self.models_dir / "human_recognition")
            )
            
            logger.info(f"âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆ: {model_path}")
            return True
            
        except Exception as e:
            logger.error(f"âœ— æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def step5_test_system(self):
        """æ­¥éª¤5: æµ‹è¯•ç³»ç»Ÿ"""
        logger.info("=== æ­¥éª¤5: æµ‹è¯•å¢å¼ºè¯†åˆ«ç³»ç»Ÿ ===")
        
        try:
            # åˆ›å»ºæ”¹è¿›çš„è¯†åˆ«ç³»ç»Ÿ
            detector = create_improved_multimodal_system({
                'face_database_path': str(self.base_dir / 'data' / 'face_database.pkl'),
                'use_pretrained_models': True,
                'detection_interval': 1
            })
            
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            import numpy as np
            test_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            
            # æ‰§è¡Œæ£€æµ‹
            logger.info("æ‰§è¡Œå¤šæ¨¡æ€æ£€æµ‹æµ‹è¯•...")
            result = detector.detect_multimodal(test_frame)
            
            # æ˜¾ç¤ºç»“æœ
            logger.info("æ£€æµ‹ç»“æœ:")
            logger.info(f"  é¢éƒ¨æ£€æµ‹: {len(result.faces)} ä¸ª")
            logger.info(f"  æ‰‹åŠ¿æ£€æµ‹: {len(result.gestures)} ä¸ª")
            logger.info(f"  å§¿åŠ¿æ£€æµ‹: {len(result.poses)} ä¸ª")
            logger.info(f"  åŠ¨ä½œè¯†åˆ«: {len(result.actions)} ä¸ª")
            logger.info(f"  æ‘”å€’æ£€æµ‹: {len(result.falls)} ä¸ª")
            
            # æ˜¾ç¤ºç½®ä¿¡åº¦
            if result.confidence_scores:
                logger.info("ç½®ä¿¡åº¦åˆ†æ•°:")
                for detection_type, confidence in result.confidence_scores.items():
                    logger.info(f"  {detection_type}: {confidence:.3f}")
            
            # æ€§èƒ½æŠ¥å‘Š
            report = detector.get_performance_report()
            logger.info(f"å¤„ç†æ€§èƒ½: {report['processing_performance']['fps']:.1f} FPS")
            
            logger.info("âœ“ ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âœ— ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_full_pipeline(self, 
                         use_synthetic: bool = True,
                         epochs: int = 20,
                         batch_size: int = 8):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        logger.info("å¼€å§‹å¢å¼ºè®­ç»ƒç³»ç»Ÿå®Œæ•´æµç¨‹")
        
        steps = [
            ("å‡†å¤‡ç¯å¢ƒ", lambda: self.step1_prepare_environment()),
            ("ä¸‹è½½æ•°æ®é›†", lambda: self.step2_download_datasets(use_synthetic)),
            ("ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹", lambda: self.step3_download_pretrained_models()),
            ("è®­ç»ƒæ¨¡å‹", lambda: self.step4_train_model(
                "synthetic_human_actions" if use_synthetic else "stanford40",
                epochs, batch_size
            )),
            ("æµ‹è¯•ç³»ç»Ÿ", lambda: self.step5_test_system())
        ]
        
        for step_name, step_func in steps:
            logger.info(f"\n{'='*50}")
            logger.info(f"æ‰§è¡Œ: {step_name}")
            logger.info(f"{'='*50}")
            
            try:
                success = step_func()
                if not success:
                    logger.error(f"æ­¥éª¤å¤±è´¥: {step_name}")
                    return False
            except Exception as e:
                logger.error(f"æ­¥éª¤å¼‚å¸¸: {step_name} - {e}")
                return False
        
        logger.info("\n" + "="*50)
        logger.info("ğŸ‰ å¢å¼ºè®­ç»ƒç³»ç»Ÿéƒ¨ç½²å®Œæˆ!")
        logger.info("="*50)
        
        # æä¾›ä½¿ç”¨ç¤ºä¾‹
        self.show_usage_examples()
        
        return True
    
    def show_usage_examples(self):
        """æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
        logger.info("\nä½¿ç”¨ç¤ºä¾‹:")
        logger.info("1. å®æ—¶æ‘„åƒå¤´è¯†åˆ«:")
        logger.info("   python -c \"")
        logger.info("   from src.recognition.improved_multimodal_detector import create_improved_multimodal_system")
        logger.info("   import cv2")
        logger.info("   detector = create_improved_multimodal_system()")
        logger.info("   cap = cv2.VideoCapture(0)")
        logger.info("   while True:")
        logger.info("       ret, frame = cap.read()")
        logger.info("       if ret:")
        logger.info("           result = detector.detect_multimodal(frame)")
        logger.info("           print(f'åŠ¨ä½œ: {len(result.actions)}')")
        logger.info("       if cv2.waitKey(1) & 0xFF == ord('q'): break")
        logger.info("   \"")
        
        logger.info("\n2. æ‰¹é‡å›¾åƒå¤„ç†:")
        logger.info("   python scripts/batch_recognition.py --input-dir ./test_images")
        
        logger.info("\n3. ç»§ç»­è®­ç»ƒæ¨¡å‹:")
        logger.info("   python scripts/continue_training.py --model-path ./models/human_recognition/best_model.pth")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºè®­ç»ƒç³»ç»Ÿå¿«é€Ÿå¯åŠ¨')
    parser.add_argument('--step', type=int, choices=[1,2,3,4,5], 
                       help='æ‰§è¡Œç‰¹å®šæ­¥éª¤ (1-5)')
    parser.add_argument('--full', action='store_true', 
                       help='æ‰§è¡Œå®Œæ•´æµç¨‹')
    parser.add_argument('--synthetic', action='store_true', default=True,
                       help='ä½¿ç”¨åˆæˆæ•°æ®é›† (é»˜è®¤)')
    parser.add_argument('--real-data', action='store_true',
                       help='ä½¿ç”¨çœŸå®æ•°æ®é›†')
    parser.add_argument('--epochs', type=int, default=20,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 20)')
    parser.add_argument('--batch-size', type=int, default=8,
                       help='æ‰¹æ¬¡å¤§å° (é»˜è®¤: 8)')
    parser.add_argument('--base-dir', type=str, default='.',
                       help='åŸºç¡€ç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = QuickStartManager(args.base_dir)
    
    use_synthetic = args.synthetic and not args.real_data
    
    if args.full:
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        success = manager.run_full_pipeline(
            use_synthetic=use_synthetic,
            epochs=args.epochs,
            batch_size=args.batch_size
        )
        sys.exit(0 if success else 1)
    
    elif args.step:
        # æ‰§è¡Œç‰¹å®šæ­¥éª¤
        step_functions = {
            1: manager.step1_prepare_environment,
            2: lambda: manager.step2_download_datasets(use_synthetic),
            3: manager.step3_download_pretrained_models,
            4: lambda: manager.step4_train_model(
                "synthetic_human_actions" if use_synthetic else "stanford40",
                args.epochs, args.batch_size
            ),
            5: manager.step5_test_system
        }
        
        success = step_functions[args.step]()
        sys.exit(0 if success else 1)
    
    else:
        # æ˜¾ç¤ºå¸®åŠ©
        parser.print_help()
        print("\nç¤ºä¾‹ç”¨æ³•:")
        print("  å®Œæ•´æµç¨‹:     python scripts/quick_start_enhanced_training.py --full")
        print("  ä½¿ç”¨çœŸå®æ•°æ®: python scripts/quick_start_enhanced_training.py --full --real-data")
        print("  æ‰§è¡Œç‰¹å®šæ­¥éª¤: python scripts/quick_start_enhanced_training.py --step 4")
        print("  è‡ªå®šä¹‰è®­ç»ƒ:   python scripts/quick_start_enhanced_training.py --step 4 --epochs 50 --batch-size 16")

if __name__ == "__main__":
    main()