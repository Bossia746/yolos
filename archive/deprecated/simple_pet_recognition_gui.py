#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–å® ç‰©è¯†åˆ«GUI - åŸºäºYOLOçš„å® ç‰©æ£€æµ‹ç³»ç»Ÿ
æ”¯æŒå¤šç§å® ç‰©è¯†åˆ«å’ŒåŸºç¡€è¡Œä¸ºåˆ†æ
"""

import cv2
import numpy as np
import time
import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import sys
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pet_recognition.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥YOLO
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("Warning: ultralytics not available, using basic detection")
    YOLO_AVAILABLE = False


class SimplePetRecognizer:
    """ç®€åŒ–çš„å® ç‰©è¯†åˆ«å™¨"""
    
    def __init__(self, model_path: str = "yolov8n.pt"):
        self.model = None
        self.model_path = model_path
        
        # å® ç‰©ç±»åˆ«æ˜ å°„ (COCOæ•°æ®é›†ä¸­çš„åŠ¨ç‰©ç±»åˆ«)
        self.pet_classes = {
            15: 'bird',      # é¸Ÿ
            16: 'cat',       # çŒ«
            17: 'dog',       # ç‹—
            18: 'horse',     # é©¬
            19: 'sheep',     # ç¾Š
            20: 'cow',       # ç‰›
            21: 'elephant',  # å¤§è±¡
            22: 'bear',      # ç†Š
            23: 'zebra',     # æ–‘é©¬
            24: 'giraffe'    # é•¿é¢ˆé¹¿
        }
        
        # å® ç‰©é¢œè‰²æ˜ å°„
        self.pet_colors = {
            'bird': (0, 255, 255),    # é»„è‰²
            'cat': (255, 0, 0),       # è“è‰²
            'dog': (0, 255, 0),       # ç»¿è‰²
            'horse': (255, 255, 0),   # é’è‰²
            'sheep': (255, 255, 255), # ç™½è‰²
            'cow': (0, 0, 0),         # é»‘è‰²
            'elephant': (128, 128, 128), # ç°è‰²
            'bear': (139, 69, 19),    # æ£•è‰²
            'zebra': (255, 0, 255),   # æ´‹çº¢
            'giraffe': (255, 165, 0)  # æ©™è‰²
        }
        
        self.initialize_model()
    
    def initialize_model(self):
        """åˆå§‹åŒ–YOLOæ¨¡å‹"""
        if not YOLO_AVAILABLE:
            logger.warning("YOLO not available, using dummy detection")
            return
        
        try:
            self.model = YOLO(self.model_path)
            logger.info(f"YOLO model loaded: {self.model_path}")
        except Exception as e:
            logger.error(f"Failed to load YOLO model: {e}")
            self.model = None
    
    def detect_pets(self, frame: np.ndarray, confidence_threshold: float = 0.5) -> List[Dict]:
        """æ£€æµ‹å® ç‰©"""
        if not self.model:
            return []
        
        try:
            # YOLOæ£€æµ‹
            results = self.model(frame, verbose=False)
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        # è·å–æ£€æµ‹ä¿¡æ¯
                        cls_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        
                        # åªå¤„ç†å® ç‰©ç±»åˆ«ä¸”ç½®ä¿¡åº¦è¶³å¤Ÿé«˜çš„æ£€æµ‹
                        if cls_id in self.pet_classes and confidence >= confidence_threshold:
                            # è·å–è¾¹ç•Œæ¡†
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            x, y, w, h = int(x1), int(y1), int(x2-x1), int(y2-y1)
                            
                            # åˆ›å»ºæ£€æµ‹ç»“æœ
                            detection = {
                                'species': self.pet_classes[cls_id],
                                'confidence': confidence,
                                'bbox': (x, y, w, h),
                                'class_id': cls_id,
                                'center': (x + w//2, y + h//2),
                                'area': w * h
                            }
                            
                            # æ·»åŠ å°ºå¯¸åˆ†ç±»
                            detection['size'] = self.classify_size(w * h, frame.shape)
                            
                            # æ·»åŠ åŸºç¡€è¡Œä¸ºåˆ†æ
                            detection['behavior'] = self.analyze_basic_behavior(detection, frame.shape)
                            
                            detections.append(detection)
            
            return detections
            
        except Exception as e:
            logger.debug(f"Detection error: {e}")
            return []
    
    def classify_size(self, area: int, frame_shape: Tuple[int, int]) -> str:
        """åˆ†ç±»å® ç‰©å°ºå¯¸"""
        frame_area = frame_shape[0] * frame_shape[1]
        ratio = area / frame_area
        
        if ratio > 0.3:
            return "Large"
        elif ratio > 0.1:
            return "Medium"
        else:
            return "Small"
    
    def analyze_basic_behavior(self, detection: Dict, frame_shape: Tuple[int, int]) -> str:
        """åŸºç¡€è¡Œä¸ºåˆ†æ"""
        x, y, w, h = detection['bbox']
        center_x, center_y = detection['center']
        
        # åŸºäºä½ç½®çš„ç®€å•è¡Œä¸ºæ¨æ–­
        frame_height = frame_shape[0]
        
        # å¦‚æœåœ¨ç”»é¢ä¸‹æ–¹ï¼Œå¯èƒ½åœ¨åœ°é¢æ´»åŠ¨
        if center_y > frame_height * 0.7:
            return "Ground Activity"
        # å¦‚æœåœ¨ç”»é¢ä¸­ä¸Šæ–¹ï¼Œå¯èƒ½åœ¨ä¼‘æ¯æˆ–è§‚å¯Ÿ
        elif center_y < frame_height * 0.4:
            return "Resting/Observing"
        else:
            return "Active"


class SimplePetRecognitionGUI:
    """ç®€åŒ–å® ç‰©è¯†åˆ«GUI"""
    
    def __init__(self, config_path: str = "camera_config.json"):
        self.config_path = config_path
        self.config = self.load_config()
        
        # æ‘„åƒå¤´ç›¸å…³
        self.cap = None
        self.frame_width = 640
        self.frame_height = 480
        
        # è¯†åˆ«å™¨
        self.pet_recognizer = SimplePetRecognizer()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.frame_count = 0
        self.start_time = time.time()
        self.fps = 0
        
        # æ£€æµ‹æ§åˆ¶
        self.detection_interval = 8  # æ¯8å¸§æ£€æµ‹ä¸€æ¬¡
        self.display_interval = 3    # æ¯3å¸§æ›´æ–°æ˜¾ç¤º
        self.result_hold_frames = 25 # ç»“æœä¿æŒ25å¸§
        
        # ç»“æœç¼“å­˜
        self.cached_results = []
        self.result_cache_time = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_detections': 0,
            'species_count': {},
            'session_start': time.time()
        }
        
        self.initialize_camera()
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            "camera": {
                "preferred_index": 1,
                "fallback_indices": [0, 2, 3, 4],
                "use_builtin": False,
                "width": 640,
                "height": 480
            },
            "detection": {
                "confidence_threshold": 0.5,
                "interval": 8
            }
        }
        
        try:
            if Path(self.config_path).exists():
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                # åˆå¹¶é»˜è®¤é…ç½®
                for key, value in default_config.items():
                    if key not in config:
                        config[key] = value
                return config
            else:
                return default_config
        except Exception as e:
            logger.error(f"Error loading config: {e}")
            return default_config
    
    def initialize_camera(self) -> bool:
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        camera_config = self.config.get('camera', {})
        
        # å°è¯•å¤–éƒ¨æ‘„åƒå¤´
        if not camera_config.get('use_builtin', False):
            preferred_index = camera_config.get('preferred_index', 1)
            fallback_indices = camera_config.get('fallback_indices', [0, 2, 3, 4])
            
            indices_to_try = [preferred_index] + [i for i in fallback_indices if i != preferred_index]
            
            for index in indices_to_try:
                logger.info(f"Trying camera index {index}")
                cap = cv2.VideoCapture(index)
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        self.cap = cap
                        logger.info(f"Camera {index} OK: {frame.shape}")
                        break
                    else:
                        cap.release()
                else:
                    cap.release()
        
        if self.cap is None:
            logger.error("No camera available")
            return False
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        width = camera_config.get('width', 640)
        height = camera_config.get('height', 480)
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        
        # è·å–å®é™…å°ºå¯¸
        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        logger.info(f"Camera setup complete: {self.frame_width}x{self.frame_height}")
        return True
    
    def draw_info_panel(self, frame: np.ndarray, results: List[Dict]) -> np.ndarray:
        """ç»˜åˆ¶ä¿¡æ¯é¢æ¿"""
        # å·¦ä¸Šè§’ä¿¡æ¯é¢æ¿
        panel_width = 180
        panel_height = 60
        
        # åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (5, 5), (panel_width, panel_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ç»Ÿè®¡ä¿¡æ¯
        species_in_frame = set(r['species'] for r in results)
        
        # æ˜¾ç¤ºä¿¡æ¯
        font_scale = 0.4
        thickness = 1
        y_offset = 18
        
        cv2.putText(frame, f"Pets Detected: {len(results)}", 
                   (8, y_offset), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        cv2.putText(frame, f"Species: {len(species_in_frame)}", 
                   (8, y_offset + 15), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        cv2.putText(frame, f"FPS: {self.fps:.1f} | Frame: {self.frame_count}", 
                   (8, y_offset + 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        return frame
    
    def draw_legend(self, frame: np.ndarray) -> np.ndarray:
        """ç»˜åˆ¶å›¾ä¾‹"""
        # åº•éƒ¨å›¾ä¾‹
        legend_height = 25
        legend_y = self.frame_height - legend_height
        
        # åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, legend_y), (self.frame_width, self.frame_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # å›¾ä¾‹æ–‡æœ¬
        legend_text = "Pets: DogğŸ• CatğŸ± BirdğŸ¦ HorseğŸ´ | Behaviors: Ground Activity, Resting, Active"
        font_scale = 0.35
        thickness = 1
        
        cv2.putText(frame, legend_text, (5, legend_y + 15), 
                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        return frame
    
    def draw_detections(self, frame: np.ndarray, results: List[Dict]) -> np.ndarray:
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        for detection in results:
            species = detection['species']
            confidence = detection['confidence']
            x, y, w, h = detection['bbox']
            
            # è·å–é¢œè‰²
            color = self.pet_recognizer.pet_colors.get(species, (128, 128, 128))
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{species.title()} {confidence:.2f}"
            if 'size' in detection:
                label += f" ({detection['size']})"
            
            # æ ‡ç­¾èƒŒæ™¯
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(frame, (x, y - label_h - 8), (x + label_w + 4, y), color, -1)
            cv2.putText(frame, label, (x + 2, y - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # ç»˜åˆ¶è¡Œä¸ºä¿¡æ¯
            if 'behavior' in detection:
                behavior_text = f"Behavior: {detection['behavior']}"
                cv2.putText(frame, behavior_text, (x, y + h + 15), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹
            center_x, center_y = detection['center']
            cv2.circle(frame, (center_x, center_y), 3, color, -1)
        
        return frame
    
    def log_detections(self, results: List[Dict]):
        """è®°å½•æ£€æµ‹ç»“æœ"""
        for detection in results:
            species = detection['species']
            confidence = detection['confidence']
            size = detection.get('size', 'Unknown')
            behavior = detection.get('behavior', 'Unknown')
            
            log_msg = f"[PET DETECTED] Species: {species}, Confidence: {confidence:.3f}, Size: {size}, Behavior: {behavior}"
            logger.info(log_msg)
            print(f"ğŸ¾ {log_msg}")
            
            # æ›´æ–°ç»Ÿè®¡
            if species not in self.stats['species_count']:
                self.stats['species_count'][species] = 0
            self.stats['species_count'][species] += 1
            self.stats['total_detections'] += 1
    
    def run(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        if not self.cap:
            logger.error("Camera not initialized")
            return
        
        logger.info("Starting simple pet recognition GUI...")
        logger.info("Controls: 'q' or ESC to quit, 's' to save screenshot, 'r' to reset stats")
        
        # ç¨³å®šåŒ–ç­‰å¾…
        logger.info("Camera stabilizing... (30 frames)")
        for i in range(30):
            ret, frame = self.cap.read()
            if not ret:
                logger.error("Failed to read frame during stabilization")
                return
            cv2.imshow('Pet Recognition - Stabilizing...', frame)
            cv2.waitKey(1)
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    logger.error("Failed to read frame from camera")
                    break
                
                self.frame_count += 1
                current_time = time.time()
                
                # è®¡ç®—FPS
                if self.frame_count % 30 == 0:
                    elapsed = current_time - self.start_time
                    self.fps = self.frame_count / elapsed if elapsed > 0 else 0
                
                # æ£€æµ‹æ§åˆ¶
                should_detect = (self.frame_count % self.detection_interval == 0)
                should_update_display = (self.frame_count % self.display_interval == 0)
                
                # æ‰§è¡Œæ£€æµ‹
                if should_detect:
                    confidence_threshold = self.config.get('detection', {}).get('confidence_threshold', 0.5)
                    results = self.pet_recognizer.detect_pets(frame, confidence_threshold)
                    
                    if results:
                        self.cached_results = results
                        self.result_cache_time = self.frame_count
                        self.log_detections(results)
                
                # ä½¿ç”¨ç¼“å­˜ç»“æœ
                display_results = []
                if self.cached_results and (self.frame_count - self.result_cache_time) < self.result_hold_frames:
                    display_results = self.cached_results
                
                # ç»˜åˆ¶ç»“æœ
                if display_results and should_update_display:
                    frame = self.draw_detections(frame, display_results)
                
                # ç»˜åˆ¶ç•Œé¢å…ƒç´ 
                frame = self.draw_info_panel(frame, display_results)
                frame = self.draw_legend(frame)
                
                # æ˜¾ç¤ºç”»é¢
                cv2.imshow('Pet Recognition - Simple Detection System', frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # 'q' or ESC
                    break
                elif key == ord('s'):  # ä¿å­˜æˆªå›¾
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    filename = f"pet_screenshot_{timestamp}.jpg"
                    cv2.imwrite(filename, frame)
                    logger.info(f"Screenshot saved: {filename}")
                    print(f"ğŸ“¸ Screenshot saved: {filename}")
                elif key == ord('r'):  # é‡ç½®ç»Ÿè®¡
                    self.stats = {
                        'total_detections': 0,
                        'species_count': {},
                        'session_start': time.time()
                    }
                    logger.info("Statistics reset")
                    print("ğŸ“Š Statistics reset")
        
        except KeyboardInterrupt:
            logger.info("Interrupted by user")
        except Exception as e:
            logger.error(f"Error in main loop: {e}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("Cleaning up resources...")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        session_duration = time.time() - self.stats['session_start']
        
        stats_text = f"""
ğŸ¾ Pet Recognition Session Summary
==================================
Duration: {session_duration:.1f} seconds
Total Frames: {self.frame_count}
Average FPS: {self.fps:.1f}
Total Detections: {self.stats['total_detections']}

Species Detected:
"""
        
        for species, count in self.stats['species_count'].items():
            stats_text += f"  {species.title()}: {count} detections\n"
        
        print(stats_text)
        logger.info("Session completed")
        
        # é‡Šæ”¾æ‘„åƒå¤´
        if self.cap:
            self.cap.release()
        
        # å…³é—­çª—å£
        cv2.destroyAllWindows()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¾ Simple Pet Recognition System")
    print("Based on YOLO Object Detection")
    print("=" * 40)
    
    if not YOLO_AVAILABLE:
        print("âš ï¸ YOLO not available - install ultralytics: pip install ultralytics")
        print("Running in basic mode...")
    
    try:
        gui = SimplePetRecognitionGUI()
        gui.run()
        
    except Exception as e:
        logger.error(f"Failed to start pet recognition system: {e}")
        print(f"âŒ Error: {e}")


if __name__ == "__main__":
    main()