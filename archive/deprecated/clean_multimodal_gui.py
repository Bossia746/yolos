#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ç®€æ´ç‰ˆå¤šæ¨¡æ€è¯†åˆ«GUI - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½ï¼Œé¿å…è¿‡åº¦è®¾è®¡"""

import sys
import os
import cv2
import numpy as np
import time
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / 'src'))

# è®¾ç½®ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('clean_multimodal_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class ActivityLogger:
    """æ´»åŠ¨è½¨è¿¹æ—¥å¿—è®°å½•å™¨ - ç”¨äºä¸šåŠ¡åˆ†æ"""
    
    def __init__(self, log_file="activity_analysis.log"):
        self.log_file = log_file
        self.activity_data = []
        
    def log_detection(self, timestamp, faces, hands, pose_keypoints):
        """è®°å½•æ£€æµ‹æ•°æ®ç”¨äºä¸šåŠ¡åˆ†æ"""
        activity_record = {
            'timestamp': timestamp,
            'face_count': len(faces),
            'hand_count': len(hands),
            'pose_keypoints_count': len(pose_keypoints),
            'face_positions': [face.get('center', (0, 0)) for face in faces],
            'hand_positions': [hand.get('wrist_pos', (0, 0)) for hand in hands],
            'key_pose_points': [(kp.get('name', ''), kp.get('position', (0, 0))) 
                               for kp in pose_keypoints if kp.get('name') in 
                               ['nose', 'left_wrist', 'right_wrist', 'left_shoulder', 'right_shoulder']]
        }
        self.activity_data.append(activity_record)
        
        # æ¯100æ¡è®°å½•å†™å…¥ä¸€æ¬¡æ–‡ä»¶
        if len(self.activity_data) >= 100:
            self.save_to_file()
    
    def save_to_file(self):
        """ä¿å­˜æ´»åŠ¨æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                for record in self.activity_data:
                    f.write(f"{record}\n")
            self.activity_data.clear()
            logger.debug(f"Activity data saved to {self.log_file}")
        except Exception as e:
            logger.error(f"Failed to save activity data: {e}")


class CleanMultimodalTester:
    """ç®€æ´ç‰ˆå¤šæ¨¡æ€è¯†åˆ«æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.face_recognizer = None
        self.gesture_recognizer = None
        self.pose_recognizer = None
        self.cap = None
        self.running = False
        self.frame_count = 0
        self.activity_logger = ActivityLogger()
        
        # ç®€åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.detection_stats = {
            'faces': 0,
            'hands': 0,
            'poses': 0,
            'gestures': 0
        }
        
        # æ€§èƒ½ä¼˜åŒ–è®¾ç½®
        self.detection_interval = 2  # æ¯2å¸§æ£€æµ‹ä¸€æ¬¡
        self.frame_skip_counter = 0
        
    def initialize_recognizers(self):
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–è¯†åˆ«å™¨...")
        
        # åˆå§‹åŒ–é¢éƒ¨è¯†åˆ«å™¨
        try:
            from recognition.face_recognizer import FaceRecognizer
            self.face_recognizer = FaceRecognizer(min_detection_confidence=0.6)
            logger.info("âœ… Face recognizer initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Face recognizer failed: {e}")
        
        # åˆå§‹åŒ–æ‰‹åŠ¿è¯†åˆ«å™¨
        try:
            from recognition.gesture_recognizer import GestureRecognizer
            self.gesture_recognizer = GestureRecognizer(
                min_detection_confidence=0.6,
                min_tracking_confidence=0.5,
                max_num_hands=2
            )
            logger.info("âœ… Gesture recognizer initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Gesture recognizer failed: {e}")
        
        # åˆå§‹åŒ–å§¿åŠ¿è¯†åˆ«å™¨
        try:
            from recognition.pose_recognizer import PoseRecognizer
            self.pose_recognizer = PoseRecognizer(
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5,
                model_complexity=1
            )
            logger.info("âœ… Pose recognizer initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Pose recognizer failed: {e}")
        
        return True
    
    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        logger.info("ğŸ“· Initializing camera...")
        
        try:
            self.cap = cv2.VideoCapture(0)
            
            if not self.cap.isOpened():
                logger.error("âŒ Cannot open camera")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            # æµ‹è¯•è¯»å–
            ret, frame = self.cap.read()
            if ret and frame is not None:
                logger.info(f"âœ… Camera initialized: {frame.shape}")
                return True
            else:
                logger.error("âŒ Camera test failed")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Camera initialization failed: {e}")
            return False
    
    def detect_faces_clean(self, frame):
        """ç®€æ´ç‰ˆé¢éƒ¨æ£€æµ‹"""
        faces_info = []
        
        if self.face_recognizer:
            try:
                annotated_frame, face_results = self.face_recognizer.detect_faces(frame)
                
                for i, face in enumerate(face_results):
                    face_info = {
                        'id': i,
                        'bbox': face.get('bbox', None),
                        'identity': face.get('identity', 'Unknown'),
                        'confidence': face.get('confidence', 0.0)
                    }
                    
                    # è®¡ç®—é¢éƒ¨ä¸­å¿ƒç‚¹
                    if face_info['bbox']:
                        x1, y1, x2, y2 = face_info['bbox']
                        center = (int((x1 + x2) / 2), int((y1 + y2) / 2))
                        face_info['center'] = center
                    
                    faces_info.append(face_info)
                    self.detection_stats['faces'] += 1
                
                return annotated_frame, faces_info
                
            except Exception as e:
                logger.debug(f"Face detection error: {e}")
        
        return frame, faces_info
    
    def detect_gestures_clean(self, frame):
        """ç®€æ´ç‰ˆæ‰‹åŠ¿æ£€æµ‹"""
        hands_info = []
        
        if self.gesture_recognizer:
            try:
                annotated_frame, gesture_results = self.gesture_recognizer.detect_hands(frame)
                
                for i, hand in enumerate(gesture_results):
                    hand_info = {
                        'id': i,
                        'hand_label': hand.get('hand_label', 'Unknown'),
                        'gesture': hand.get('gesture', 'unknown'),
                        'landmarks': hand.get('landmarks', [])
                    }
                    
                    # æå–æ‰‹è…•ä½ç½®
                    if hand_info['landmarks'] and len(hand_info['landmarks']) > 0:
                        wrist_pos = hand_info['landmarks'][0]
                        hand_info['wrist_pos'] = wrist_pos
                    
                    hands_info.append(hand_info)
                    self.detection_stats['hands'] += 1
                    
                    if hand_info['gesture'] != 'unknown':
                        self.detection_stats['gestures'] += 1
                
                return annotated_frame, hands_info
                
            except Exception as e:
                logger.debug(f"Gesture detection error: {e}")
        
        return frame, hands_info
    
    def detect_pose_clean(self, frame):
        """ç®€æ´ç‰ˆå§¿åŠ¿æ£€æµ‹ - é‡ç‚¹æ˜¾ç¤º33ä¸ªå…³é”®ç‚¹"""
        pose_keypoints = []
        
        if self.pose_recognizer:
            try:
                annotated_frame, pose_result = self.pose_recognizer.detect_pose(frame)
                
                if pose_result and pose_result.get('pose_detected', False):
                    landmarks = pose_result.get('landmarks', [])
                    
                    if landmarks:
                        # MediaPipe 33ä¸ªå§¿åŠ¿å…³é”®ç‚¹åç§°
                        keypoint_names = [
                            'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer',
                            'right_eye_inner', 'right_eye', 'right_eye_outer',
                            'left_ear', 'right_ear', 'mouth_left', 'mouth_right',
                            'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
                            'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky',
                            'left_index', 'right_index', 'left_thumb', 'right_thumb',
                            'left_hip', 'right_hip', 'left_knee', 'right_knee',
                            'left_ankle', 'right_ankle', 'left_heel', 'right_heel',
                            'left_foot_index', 'right_foot_index'
                        ]
                        
                        # ç»˜åˆ¶æ‰€æœ‰33ä¸ªå…³é”®ç‚¹
                        for i, landmark in enumerate(landmarks):
                            if i < len(keypoint_names) and len(landmark) >= 4:
                                x, y, z, visibility = landmark
                                
                                if visibility > 0.3:  # é™ä½å¯è§æ€§é˜ˆå€¼ä»¥æ˜¾ç¤ºæ›´å¤šç‚¹
                                    keypoint_info = {
                                        'name': keypoint_names[i],
                                        'position': (int(x), int(y)),
                                        'visibility': visibility
                                    }
                                    pose_keypoints.append(keypoint_info)
                                    
                                    # æ ¹æ®å…³é”®ç‚¹ç±»å‹ä½¿ç”¨ä¸åŒé¢œè‰²
                                    if 'eye' in keypoint_names[i] or 'ear' in keypoint_names[i] or keypoint_names[i] == 'nose':
                                        color = (255, 255, 0)  # é»„è‰² - å¤´éƒ¨
                                        radius = 3
                                    elif 'shoulder' in keypoint_names[i] or 'elbow' in keypoint_names[i] or 'wrist' in keypoint_names[i]:
                                        color = (0, 255, 0)    # ç»¿è‰² - ä¸Šè‚¢
                                        radius = 4
                                    elif 'hip' in keypoint_names[i] or 'knee' in keypoint_names[i] or 'ankle' in keypoint_names[i]:
                                        color = (0, 0, 255)    # çº¢è‰² - ä¸‹è‚¢
                                        radius = 4
                                    else:
                                        color = (255, 0, 255)  # ç´«è‰² - å…¶ä»–
                                        radius = 2
                                    
                                    # ç»˜åˆ¶å…³é”®ç‚¹
                                    cv2.circle(annotated_frame, (int(x), int(y)), radius, color, -1)
                                    
                                    # ä¸ºé‡è¦å…³é”®ç‚¹æ·»åŠ æ ‡ç­¾
                                    if keypoint_names[i] in ['nose', 'left_shoulder', 'right_shoulder', 
                                                           'left_hip', 'right_hip', 'left_knee', 'right_knee']:
                                        cv2.putText(annotated_frame, keypoint_names[i][:4], 
                                                  (int(x)+5, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, 
                                                  0.3, color, 1)
                    
                    self.detection_stats['poses'] += 1
                
                return annotated_frame, pose_keypoints
                
            except Exception as e:
                logger.debug(f"Pose detection error: {e}")
        
        return frame, pose_keypoints
    
    def detect_multimodal_clean(self, frame):
        """ç®€æ´ç‰ˆå¤šæ¨¡æ€æ£€æµ‹"""
        # è·³å¸§ä¼˜åŒ–
        self.frame_skip_counter += 1
        if self.frame_skip_counter % self.detection_interval != 0:
            return frame, {'faces': [], 'hands': [], 'pose_keypoints': []}
        
        # æ‰§è¡Œæ£€æµ‹
        annotated_frame = frame.copy()
        
        # é¢éƒ¨æ£€æµ‹
        face_frame, faces = self.detect_faces_clean(annotated_frame)
        annotated_frame = face_frame
        
        # æ‰‹åŠ¿æ£€æµ‹
        gesture_frame, hands = self.detect_gestures_clean(annotated_frame)
        annotated_frame = gesture_frame
        
        # å§¿åŠ¿æ£€æµ‹ - é‡ç‚¹æ˜¾ç¤º33ä¸ªå…³é”®ç‚¹
        pose_frame, pose_keypoints = self.detect_pose_clean(annotated_frame)
        annotated_frame = pose_frame
        
        # è®°å½•æ´»åŠ¨æ•°æ®ç”¨äºä¸šåŠ¡åˆ†æ
        self.activity_logger.log_detection(time.time(), faces, hands, pose_keypoints)
        
        detections = {
            'faces': faces,
            'hands': hands,
            'pose_keypoints': pose_keypoints
        }
        
        return annotated_frame, detections
    
    def draw_clean_overlay(self, frame, fps):
        """ç»˜åˆ¶ç®€æ´ä¿¡æ¯è¦†ç›–å±‚"""
        # é¡¶éƒ¨çŠ¶æ€æ 
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 60), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        color = (255, 255, 255)
        thickness = 1
        
        # åŸºæœ¬ä¿¡æ¯
        current_time = datetime.now().strftime("%H:%M:%S")
        cv2.putText(frame, f"Time: {current_time}", (10, 25), font, font_scale, color, thickness)
        cv2.putText(frame, f"FPS: {fps:.1f} | Frame: {self.frame_count}", (10, 50), font, 0.5, color, thickness)
        
        # æ£€æµ‹ç»Ÿè®¡
        stats_text = (f"Faces: {self.detection_stats['faces']} | "
                     f"Hands: {self.detection_stats['hands']} | "
                     f"Poses: {self.detection_stats['poses']} | "
                     f"Gestures: {self.detection_stats['gestures']}")
        cv2.putText(frame, stats_text, (200, 25), font, 0.5, color, thickness)
        
        # å…³é”®ç‚¹è¯´æ˜
        legend_text = "Yellow: Head | Green: Arms | Red: Legs | Purple: Others"
        cv2.putText(frame, legend_text, (200, 50), font, 0.4, (200, 200, 200), thickness)
        
        # æ§åˆ¶è¯´æ˜
        control_text = "Controls: [Q]uit | [S]ave | [R]eset"
        cv2.putText(frame, control_text, (10, frame.shape[0] - 10), font, 0.4, (0, 255, 0), 1)
    
    def save_screenshot(self, frame):
        """ä¿å­˜æˆªå›¾"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"clean_multimodal_{timestamp}.jpg"
            cv2.imwrite(filename, frame)
            logger.info(f"ğŸ“¸ Screenshot saved: {filename}")
        except Exception as e:
            logger.error(f"Save screenshot failed: {e}")
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.detection_stats = {'faces': 0, 'hands': 0, 'poses': 0, 'gestures': 0}
        self.frame_count = 0
        logger.info("ğŸ“Š Statistics reset")
    
    def run_test(self):
        """è¿è¡Œç®€æ´ç‰ˆæµ‹è¯•"""
        logger.info("ğŸ–¥ï¸ Starting clean multimodal recognition GUI test")
        
        # åˆå§‹åŒ–è¯†åˆ«å™¨
        if not self.initialize_recognizers():
            logger.error("âŒ Recognizer initialization failed")
            return False
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        if not self.initialize_camera():
            logger.error("âŒ Camera initialization failed")
            return False
        
        # åˆ›å»ºçª—å£
        window_name = "Clean Multimodal Recognition - 33 Pose Keypoints"
        cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)
        
        logger.info("ğŸ¬ Starting clean real-time detection...")
        
        self.running = True
        fps_counter = 0
        fps_start_time = time.time()
        current_fps = 0
        
        try:
            while self.running:
                # è¯»å–æ‘„åƒå¤´å¸§
                ret, frame = self.cap.read()
                
                if not ret or frame is None:
                    logger.warning("âš ï¸ Cannot read camera frame")
                    continue
                
                self.frame_count += 1
                fps_counter += 1
                
                # æ‰§è¡Œç®€æ´ç‰ˆå¤šæ¨¡æ€æ£€æµ‹
                start_time = time.time()
                try:
                    annotated_frame, detections = self.detect_multimodal_clean(frame)
                    processing_time = time.time() - start_time
                except Exception as e:
                    logger.warning(f"Detection failed: {e}")
                    annotated_frame = frame
                    processing_time = 0
                
                # è®¡ç®—FPS
                current_time = time.time()
                if current_time - fps_start_time >= 1.0:
                    current_fps = fps_counter / (current_time - fps_start_time)
                    fps_counter = 0
                    fps_start_time = current_time
                
                # ç»˜åˆ¶ç®€æ´ä¿¡æ¯è¦†ç›–å±‚
                self.draw_clean_overlay(annotated_frame, current_fps)
                
                # æ˜¾ç¤ºå¸§
                cv2.imshow(window_name, annotated_frame)
                
                # å¤„ç†é”®ç›˜è¾“å…¥
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # 'q' æˆ– ESC é€€å‡º
                    logger.info("User requested exit")
                    break
                elif key == ord('s'):  # 's' ä¿å­˜æˆªå›¾
                    if 'annotated_frame' in locals():
                        self.save_screenshot(annotated_frame)
                elif key == ord('r'):  # 'r' é‡ç½®ç»Ÿè®¡
                    self.reset_stats()
                
                # æ£€æŸ¥çª—å£æ˜¯å¦è¢«å…³é—­
                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:
                    logger.info("Window closed")
                    break
            
            # ç”Ÿæˆç®€æ´æµ‹è¯•æŠ¥å‘Š
            self.generate_clean_report(current_fps)
            
            logger.info("âœ… Clean test completed")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Test error: {e}")
            return False
        
        finally:
            self.cleanup()
    
    def generate_clean_report(self, fps):
        """ç”Ÿæˆç®€æ´æµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š Clean Multimodal Recognition Test Report")
        logger.info("="*60)
        logger.info(f"Total frames processed: {self.frame_count}")
        logger.info(f"Average FPS: {fps:.1f}")
        logger.info(f"Detection interval: Every {self.detection_interval} frames")
        
        logger.info("\nğŸ¯ Detection Statistics:")
        logger.info(f"  Face detections: {self.detection_stats['faces']}")
        logger.info(f"  Hand detections: {self.detection_stats['hands']}")
        logger.info(f"  Pose detections: {self.detection_stats['poses']}")
        logger.info(f"  Gesture classifications: {self.detection_stats['gestures']}")
        
        logger.info("\nâœ¨ Core Features Verified:")
        logger.info("  âœ… Multi-face detection and recognition")
        logger.info("  âœ… Dual-hand 21-keypoint tracking")
        logger.info("  âœ… Multiple gesture classification")
        logger.info("  âœ… Complete 33 pose keypoints display")
        logger.info("  âœ… Real-time activity logging for analysis")
        logger.info("  âœ… Clean UI without visual clutter")
        
        # ä¿å­˜æ´»åŠ¨æ—¥å¿—
        self.activity_logger.save_to_file()
        logger.info(f"  âœ… Activity data saved to {self.activity_logger.log_file}")
        
        logger.info("="*60)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ Cleaning up resources...")
        
        self.running = False
        
        # ä¿å­˜æœ€åçš„æ´»åŠ¨æ•°æ®
        self.activity_logger.save_to_file()
        
        # é‡Šæ”¾æ‘„åƒå¤´
        if self.cap:
            self.cap.release()
        
        # å…³é—­æ‰€æœ‰OpenCVçª—å£
        cv2.destroyAllWindows()
        
        # æ¸…ç†è¯†åˆ«å™¨
        if self.face_recognizer and hasattr(self.face_recognizer, 'close'):
            self.face_recognizer.close()
        if self.gesture_recognizer and hasattr(self.gesture_recognizer, 'close'):
            self.gesture_recognizer.close()
        if self.pose_recognizer and hasattr(self.pose_recognizer, 'close'):
            self.pose_recognizer.close()
        
        logger.info("âœ… Cleanup completed")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ–¥ï¸ Clean Multimodal Recognition GUI Test")
    print("=" * 50)
    print("ğŸ¯ Core Features:")
    print("  â€¢ Multi-face detection and recognition")
    print("  â€¢ Dual-hand 21-keypoint tracking")
    print("  â€¢ Multiple gesture classification")
    print("  â€¢ Complete 33 pose keypoints display")
    print("  â€¢ Activity logging for business analysis")
    print("  â€¢ Clean UI without visual clutter")
    print()
    print("ğŸ® Controls:")
    print("  â€¢ Press 'q' or ESC to exit")
    print("  â€¢ Press 's' to save screenshot")
    print("  â€¢ Press 'r' to reset statistics")
    print()
    print("ğŸ¨ Keypoint Colors:")
    print("  â€¢ Yellow: Head (eyes, ears, nose)")
    print("  â€¢ Green: Arms (shoulders, elbows, wrists)")
    print("  â€¢ Red: Legs (hips, knees, ankles)")
    print("  â€¢ Purple: Others (fingers, feet)")
    print("=" * 50)
    
    try:
        tester = CleanMultimodalTester()
        success = tester.run_test()
        
        if success:
            print("\nğŸ‰ Clean test completed successfully!")
            sys.exit(0)
        else:
            print("\nâŒ Test failed!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Test interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Test exception: {e}")
        logger.error(f"Main program exception: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()