#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºé™ç‰©è¯†åˆ«GUI - æ”¯æŒäºŒç»´ç ã€æ¡å½¢ç ã€è½¦ç‰Œã€äº¤é€šç¬¦å·ç­‰
åŸºäºOpenCVå’Œæ·±åº¦å­¦ä¹ çš„å¤šåŠŸèƒ½è¯†åˆ«ç³»ç»Ÿ
"""

import cv2
import numpy as np
import os
import sys
import logging
import time
import json
from datetime import datetime
import locale

# è®¾ç½®ç¼–ç å’Œlocale
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LC_ALL'] = 'C'
locale.setlocale(locale.LC_ALL, 'C')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(project_root, 'src')
if src_path not in sys.path:
    sys.path.insert(0, src_path)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_object_recognition.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class EnhancedObjectRecognitionGUI:
    """å¢å¼ºé™ç‰©è¯†åˆ«GUIç±» - æ”¯æŒå¤šç§ç‰¹æ®Šå¯¹è±¡è¯†åˆ«"""
    
    def __init__(self):
        self.enhanced_recognizer = None
        self.cap = None
        self.config = self.load_config()
        self.detection_stats = {
            'qr_codes': 0,
            'barcodes': 0,
            'license_plates': 0,
            'traffic_signs': 0,
            'traffic_lights': 0,
            'facility_signs': 0,
            'basic_objects': 0,
            'total_objects': 0,
            'frames': 0
        }
        self.start_time = time.time()
        self.detection_interval = self.config['detection']['detection_interval']  # 15å¸§æ£€æµ‹ä¸€æ¬¡ï¼Œå¤§å¹…é™ä½åˆ·æ–°
        self.display_interval = self.config['detection']['display_interval']     # 8å¸§æ›´æ–°æ˜¾ç¤ºä¸€æ¬¡
        self.result_hold_frames = self.config['detection']['result_hold_frames'] # 45å¸§ä¿æŒç»“æœæ˜¾ç¤º
        self.frame_count = 0
        self.last_results = None    # ç¼“å­˜ä¸Šæ¬¡æ£€æµ‹ç»“æœ
        self.last_detection_frame = 0  # ä¸Šæ¬¡æ£€æµ‹çš„å¸§æ•°
        self.focus_stabilize_frames = self.config['detection']['focus_stabilize_frames']
        
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open('camera_config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info("Configuration loaded successfully")
            return config
        except Exception as e:
            logger.warning(f"Failed to load config, using defaults: {e}")
            return {
                "camera": {
                    "preferred_index": 1,
                    "fallback_indices": [2, 3],
                    "use_builtin": False,
                    "width": 640,
                    "height": 480,
                    "fps": 30
                },
                "detection": {
                    "detection_interval": 15,
                    "display_interval": 8,
                    "result_hold_frames": 45,
                    "focus_stabilize_frames": 30,
                    "confidence_threshold": 0.5
                },
                "display": {
                    "show_fps": True,
                    "show_categories": True,
                    "show_summary": True,
                    "panel_transparency": 0.8
                }
            }
        
    def initialize_recognizer(self):
        """åˆå§‹åŒ–å¢å¼ºé™ç‰©è¯†åˆ«å™¨"""
        logger.info("Initializing enhanced object recognizer...")
        
        try:
            from recognition.enhanced_object_recognizer import EnhancedObjectRecognizer
            self.enhanced_recognizer = EnhancedObjectRecognizer()
            logger.info("Enhanced object recognizer OK")
        except Exception as e:
            logger.error(f"Enhanced object recognizer failed: {e}")
            raise
    
    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´ - å¼ºåˆ¶ä½¿ç”¨å¤–éƒ¨USBæ‘„åƒå¤´"""
        logger.info("Initializing camera (USB external only)...")
        
        # æ ¹æ®é…ç½®å¼ºåˆ¶ä½¿ç”¨å¤–éƒ¨æ‘„åƒå¤´
        camera_config = self.config['camera']
        
        if camera_config['use_builtin']:
            camera_indices = [0, int(camera_config['preferred_index'])] + list(camera_config['fallback_indices'])
        else:
            # å¼ºåˆ¶ä¸ä½¿ç”¨å†…ç½®æ‘„åƒå¤´(ç´¢å¼•0)
            camera_indices = [int(camera_config['preferred_index'])] + list(camera_config['fallback_indices'])
            logger.info("Built-in camera disabled, using external USB camera only")
        
        camera_found = False
        for camera_index in camera_indices:
            logger.info(f"Trying camera index {camera_index}...")
            self.cap = cv2.VideoCapture(int(camera_index))
            
            if self.cap.isOpened():
                # æµ‹è¯•æ˜¯å¦èƒ½è¯»å–å¸§
                ret, frame = self.cap.read()
                if ret:
                    logger.info(f"Camera {camera_index} OK: {frame.shape}")
                    camera_found = True
                    break
                else:
                    self.cap.release()
            else:
                if self.cap:
                    self.cap.release()
        
        if not camera_found:
            if not camera_config['use_builtin']:
                logger.error("No external USB camera found! Please:")
                logger.error("1. Connect USB camera")
                logger.error("2. Or set 'use_builtin': true in camera_config.json")
                raise RuntimeError("No external USB camera available")
            else:
                raise RuntimeError("Cannot open any camera")
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, int(camera_config['width']))
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, int(camera_config['height']))
        self.cap.set(cv2.CAP_PROP_FPS, int(camera_config['fps']))
        
        # éªŒè¯æœ€ç»ˆè®¾ç½®
        ret, frame = self.cap.read()
        if ret:
            logger.info(f"Final camera setup OK: {frame.shape}")
        else:
            raise RuntimeError("Cannot read from selected camera")
    
    def detect_enhanced_objects(self, frame):
        """æ£€æµ‹å¢å¼ºé™ç‰©å¯¹è±¡ - ä¼˜åŒ–å¯¹ç„¦å’Œåˆ·æ–°é¢‘ç‡"""
        results = {
            'objects': [],
            'summary': {
                'qr_codes': 0,
                'barcodes': 0,
                'license_plates': 0,
                'traffic_signs': 0,
                'traffic_lights': 0,
                'facility_signs': 0,
                'basic_objects': 0,
                'total_objects': 0
            }
        }
        
        try:
            # å‰30å¸§ç”¨äºå¯¹ç„¦ç¨³å®šï¼Œä¸è¿›è¡Œæ£€æµ‹
            if self.frame_count < int(self.focus_stabilize_frames):
                # æ˜¾ç¤ºå¯¹ç„¦æç¤º
                focus_frame = frame.copy()
                remaining_frames = int(self.focus_stabilize_frames) - self.frame_count
                focus_text = f"Camera focusing... {remaining_frames} frames remaining"
                cv2.putText(focus_frame, focus_text, (50, 50), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                cv2.putText(focus_frame, "Please hold objects steady for better detection", (50, 80), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                return focus_frame, results
            
            # æ¯éš”15å¸§è¿›è¡Œä¸€æ¬¡æ£€æµ‹ï¼Œå¤§å¹…é™ä½åˆ·æ–°é¢‘ç‡
            if self.frame_count % self.detection_interval == 0:
                annotated_frame, object_results = self.enhanced_recognizer.detect_objects(frame)
                
                # ç»Ÿè®¡å„ç±»å‹å¯¹è±¡å¹¶è¾“å‡ºè¯†åˆ«å†…å®¹åˆ°æ—¥å¿—å’Œæ§åˆ¶å°
                for obj in object_results:
                    obj_type = obj.get('type', 'unknown')
                    results['summary']['total_objects'] += 1
                    
                    # è¾“å‡ºè¯†åˆ«å†…å®¹åˆ°æ—¥å¿—å’Œæ§åˆ¶å°
                    self._log_detection_content(obj)
                    
                    if obj_type == 'qr_code':
                        results['summary']['qr_codes'] += 1
                        self.detection_stats['qr_codes'] += 1
                    elif obj_type == 'barcode':
                        results['summary']['barcodes'] += 1
                        self.detection_stats['barcodes'] += 1
                    elif obj_type == 'license_plate':
                        results['summary']['license_plates'] += 1
                        self.detection_stats['license_plates'] += 1
                    elif obj_type == 'traffic_sign':
                        results['summary']['traffic_signs'] += 1
                        self.detection_stats['traffic_signs'] += 1
                    elif obj_type == 'traffic_light':
                        results['summary']['traffic_lights'] += 1
                        self.detection_stats['traffic_lights'] += 1
                    elif obj_type == 'facility_sign':
                        results['summary']['facility_signs'] += 1
                        self.detection_stats['facility_signs'] += 1
                    elif obj_type == 'basic_object':
                        results['summary']['basic_objects'] += 1
                        self.detection_stats['basic_objects'] += 1
                    
                    self.detection_stats['total_objects'] += 1
                
                results['objects'] = object_results
                self.last_results = (annotated_frame, results)  # ç¼“å­˜ç»“æœ
                self.last_detection_frame = self.frame_count
                return annotated_frame, results
            
            # åœ¨ç»“æœä¿æŒæœŸå†…ï¼Œç»§ç»­æ˜¾ç¤ºä¸Šæ¬¡æ£€æµ‹ç»“æœï¼Œé¿å…é—ªçƒ
            elif (self.last_results is not None and 
                  self.frame_count - self.last_detection_frame < int(self.result_hold_frames)):
                # ä½¿ç”¨ç¼“å­˜çš„æ£€æµ‹ç»“æœï¼Œä½†åœ¨åŸå§‹å¸§ä¸Šé‡æ–°ç»˜åˆ¶ï¼Œä¿æŒç¨³å®šæ˜¾ç¤º
                cached_frame, cached_results = self.last_results
                return cached_frame, cached_results
            else:
                # è¶…å‡ºä¿æŒæœŸï¼Œæ˜¾ç¤ºåŸå§‹å¸§
                return frame, results
                
        except Exception as e:
            logger.debug(f"Enhanced object detection error: {e}")
            return frame, results
    
    def _log_detection_content(self, obj):
        """è¾“å‡ºè¯†åˆ«å†…å®¹åˆ°æ—¥å¿—å’Œæ§åˆ¶å°"""
        try:
            obj_type = obj.get('type', 'unknown')
            timestamp = datetime.now().strftime("%H:%M:%S")
            
            if obj_type == 'qr_code':
                content = obj.get('content', 'No content')
                message = f"[{timestamp}] QR Code detected: {content}"
                logger.info(message)
                print(f"ğŸ” {message}")
                
            elif obj_type == 'barcode':
                content = obj.get('content', 'No content')
                format_type = obj.get('format', 'Unknown')
                message = f"[{timestamp}] Barcode detected ({format_type}): {content}"
                logger.info(message)
                print(f"ğŸ“Š {message}")
                
            elif obj_type == 'basic_object' and 'text' in obj:
                text_content = obj.get('text', '')
                if text_content and text_content.strip():
                    message = f"[{timestamp}] Text detected: {text_content.strip()}"
                    logger.info(message)
                    print(f"ğŸ“ {message}")
                    
            elif obj_type == 'license_plate':
                plate_number = obj.get('content', 'Unknown')
                message = f"[{timestamp}] License plate detected: {plate_number}"
                logger.info(message)
                print(f"ğŸš— {message}")
                
            elif obj_type == 'traffic_sign':
                sign_type = obj.get('content', 'Unknown sign')
                message = f"[{timestamp}] Traffic sign detected: {sign_type}"
                logger.info(message)
                print(f"ğŸš¦ {message}")
                
            elif obj_type == 'traffic_light':
                light_state = obj.get('content', 'Unknown state')
                message = f"[{timestamp}] Traffic light detected: {light_state}"
                logger.info(message)
                print(f"ğŸš¥ {message}")
                
            elif obj_type == 'facility_sign':
                facility_type = obj.get('content', 'Unknown facility')
                message = f"[{timestamp}] Facility sign detected: {facility_type}"
                logger.info(message)
                print(f"ğŸ¢ {message}")
                
        except Exception as e:
            logger.debug(f"Log detection content error: {e}")
    
    def draw_enhanced_summary_info(self, frame, results):
        """ç»˜åˆ¶å¢å¼ºæ±‡æ€»ä¿¡æ¯ - ç´§å‡‘ç‰ˆæœ¬"""
        try:
            summary = results['summary']
            
            # å‡†å¤‡ç´§å‡‘ä¿¡æ¯æ–‡æœ¬
            info_lines = [
                f"Enhanced Detection",
                f"QR:{summary['qr_codes']} Bar:{summary['barcodes']} Plate:{summary['license_plates']}",
                f"Sign:{summary['traffic_signs']} Light:{summary['traffic_lights']} Total:{summary['total_objects']}"
            ]
            
            # ç»˜åˆ¶ç´§å‡‘ä¿¡æ¯é¢æ¿èƒŒæ™¯
            panel_height = len(info_lines) * 16 + 10
            panel_width = 180
            cv2.rectangle(frame, (5, 5), (panel_width, panel_height), (0, 0, 0), -1)
            cv2.rectangle(frame, (5, 5), (panel_width, panel_height), (255, 255, 255), 1)
            
            # ç»˜åˆ¶ä¿¡æ¯æ–‡æœ¬
            for i, line in enumerate(info_lines):
                y_pos = 18 + i * 16
                color = (0, 255, 255) if i == 0 else (255, 255, 255)
                font_scale = 0.4 if i == 0 else 0.35
                cv2.putText(frame, line, (8, y_pos), 
                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 1)
            
        except Exception as e:
            logger.debug(f"Draw enhanced summary info error: {e}")
    
    def draw_detection_categories(self, frame):
        """ç»˜åˆ¶æ£€æµ‹ç±»åˆ«è¯´æ˜ - ç´§å‡‘ç‰ˆæœ¬"""
        try:
            categories = [
                "Categories: QR(Green) Bar(Blue) Plate(Cyan) Sign(Magenta) Light(Color) Facility(Yellow)"
            ]
            
            # ç»˜åˆ¶ç´§å‡‘ç±»åˆ«é¢æ¿
            start_y = frame.shape[0] - 25
            panel_width = min(frame.shape[1] - 10, 600)
            
            cv2.rectangle(frame, (5, start_y), (panel_width, frame.shape[0] - 5), (50, 50, 50), -1)
            cv2.rectangle(frame, (5, start_y), (panel_width, frame.shape[0] - 5), (200, 200, 200), 1)
            
            cv2.putText(frame, categories[0], (8, start_y + 15), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.35, (200, 200, 200), 1)
            
        except Exception as e:
            logger.debug(f"Draw detection categories error: {e}")
    
    def run(self):
        """è¿è¡Œå¢å¼ºGUI"""
        try:
            self.initialize_recognizer()
            self.initialize_camera()
            
            logger.info("Starting enhanced object detection...")
            
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    break
                
                self.detection_stats['frames'] += 1
                self.frame_count += 1
                
                # å¢å¼ºé™ç‰©æ£€æµ‹
                annotated_frame, results = self.detect_enhanced_objects(frame)
                
                # ç»˜åˆ¶å¢å¼ºæ±‡æ€»ä¿¡æ¯
                self.draw_enhanced_summary_info(annotated_frame, results)
                
                # ç»˜åˆ¶æ£€æµ‹ç±»åˆ«è¯´æ˜
                self.draw_detection_categories(annotated_frame)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                elapsed_time = time.time() - self.start_time
                fps = self.detection_stats['frames'] / elapsed_time if elapsed_time > 0 else 0
                
                stats_text = f"FPS: {fps:.1f} | QR: {self.detection_stats['qr_codes']} | Barcode: {self.detection_stats['barcodes']} | License: {self.detection_stats['license_plates']} | Traffic: {self.detection_stats['traffic_signs']} | Lights: {self.detection_stats['traffic_lights']} | Facility: {self.detection_stats['facility_signs']} | Objects: {self.detection_stats['basic_objects']}"
                
                # ç»˜åˆ¶çŠ¶æ€æ 
                cv2.rectangle(annotated_frame, (0, 0), (annotated_frame.shape[1], 25), (0, 0, 0), -1)
                cv2.putText(annotated_frame, stats_text, (5, 18), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
                
                # æ˜¾ç¤ºå¸§
                cv2.imshow('Enhanced Object Recognition GUI', annotated_frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:  # ESC
                    break
                elif key == ord('s'):
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"enhanced_detection_{timestamp}.jpg"
                    cv2.imwrite(filename, annotated_frame)
                    logger.info(f"Screenshot saved: {filename}")
                elif key == ord('r'):
                    self.detection_stats = {
                        'qr_codes': 0, 'barcodes': 0, 'license_plates': 0,
                        'traffic_signs': 0, 'traffic_lights': 0, 'facility_signs': 0,
                        'basic_objects': 0, 'total_objects': 0, 'frames': 0
                    }
                    self.start_time = time.time()
                    self.frame_count = 0
                    logger.info("Statistics reset")
                elif key == ord('h'):
                    self._show_enhanced_help()
        
        except Exception as e:
            logger.error(f"Error in enhanced main loop: {e}")
        
        finally:
            if self.cap:
                self.cap.release()
            cv2.destroyAllWindows()
            logger.info("Enhanced object recognition GUI closed")
            
            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self._generate_enhanced_final_report()
    
    def _show_enhanced_help(self):
        """æ˜¾ç¤ºå¢å¼ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
Enhanced Object Recognition GUI Help
===================================

Controls:
â€¢ 'q' or ESC - Exit program
â€¢ 's' - Save screenshot
â€¢ 'r' - Reset statistics
â€¢ 'h' - Show this help

Enhanced Detection Features:
â€¢ QR Code Recognition - Decodes QR code content
â€¢ Barcode Detection - Identifies various barcode formats
â€¢ License Plate Detection - Recognizes vehicle plates
â€¢ Traffic Sign Recognition - Identifies road signs
â€¢ Traffic Light Detection - Detects red/yellow/green lights
â€¢ Facility Sign Recognition - Public facility symbols
â€¢ Basic Object Analysis - Color, shape, text detection

Detection Categories:
â€¢ QR Codes - Green boxes with decoded content
â€¢ Barcodes - Blue boxes with barcode data
â€¢ License Plates - Cyan boxes with plate numbers
â€¢ Traffic Signs - Magenta boxes with sign types
â€¢ Traffic Lights - Color-coded boxes (red/yellow/green)
â€¢ Facility Signs - Yellow boxes with facility types
â€¢ Basic Objects - Various colors based on object properties

Tips for Better Detection:
â€¢ Use good lighting conditions
â€¢ Hold objects steady for text/code detection
â€¢ Ensure clear view of signs and symbols
â€¢ USB camera recommended for better quality
        """
        print(help_text)
    
    def _generate_enhanced_final_report(self):
        """ç”Ÿæˆå¢å¼ºæœ€ç»ˆæŠ¥å‘Š"""
        try:
            elapsed_time = time.time() - self.start_time
            avg_fps = self.detection_stats['frames'] / elapsed_time if elapsed_time > 0 else 0
            
            report = f"""
Enhanced Object Recognition Session Report
=========================================
Duration: {elapsed_time:.1f} seconds
Average FPS: {avg_fps:.1f}
Total Frames: {self.detection_stats['frames']}

Enhanced Detection Results:
â€¢ QR Codes Detected: {self.detection_stats['qr_codes']}
â€¢ Barcodes Detected: {self.detection_stats['barcodes']}
â€¢ License Plates Detected: {self.detection_stats['license_plates']}
â€¢ Traffic Signs Detected: {self.detection_stats['traffic_signs']}
â€¢ Traffic Lights Detected: {self.detection_stats['traffic_lights']}
â€¢ Facility Signs Detected: {self.detection_stats['facility_signs']}
â€¢ Basic Objects Detected: {self.detection_stats['basic_objects']}
â€¢ Total Objects Detected: {self.detection_stats['total_objects']}

Performance Metrics:
â€¢ Detection Rate: {self.detection_stats['total_objects']/max(1, self.detection_stats['frames']*1.0):.3f} objects/frame
â€¢ QR Code Detection Rate: {self.detection_stats['qr_codes']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ Barcode Detection Rate: {self.detection_stats['barcodes']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ License Plate Detection Rate: {self.detection_stats['license_plates']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ Traffic Sign Detection Rate: {self.detection_stats['traffic_signs']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ Traffic Light Detection Rate: {self.detection_stats['traffic_lights']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ Facility Sign Detection Rate: {self.detection_stats['facility_signs']/max(1, self.detection_stats['total_objects']):.2%}
â€¢ Basic Object Detection Rate: {self.detection_stats['basic_objects']/max(1, self.detection_stats['total_objects']):.2%}

System Capabilities:
â€¢ Multi-format code recognition (QR, barcodes)
â€¢ Vehicle identification (license plates)
â€¢ Traffic infrastructure detection (signs, lights)
â€¢ Public facility recognition (restrooms, exits, etc.)
â€¢ Basic object analysis (color, shape, text)
â€¢ Real-time processing with optimized performance
            """
            
            print(report)
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_filename = f"enhanced_recognition_report_{timestamp}.txt"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(report)
            
            logger.info(f"Enhanced final report saved: {report_filename}")
            
        except Exception as e:
            logger.error(f"Generate enhanced final report error: {e}")


def main():
    print("Enhanced Object Recognition GUI")
    print("=" * 50)
    print("Advanced Features:")
    print("  â€¢ QR Code Recognition - Decodes QR code content")
    print("  â€¢ Barcode Detection - Identifies various barcode formats")
    print("  â€¢ License Plate Detection - Recognizes vehicle plates")
    print("  â€¢ Traffic Sign Recognition - Identifies road signs")
    print("  â€¢ Traffic Light Detection - Detects red/yellow/green lights")
    print("  â€¢ Facility Sign Recognition - Public facility symbols")
    print("  â€¢ Basic Object Analysis - Color, shape, text detection")
    print("  â€¢ Real-time Processing - Optimized USB camera support")
    print()
    print("Controls:")
    print("  â€¢ Press 'q' or ESC to exit")
    print("  â€¢ Press 's' to save screenshot")
    print("  â€¢ Press 'r' to reset statistics")
    print("  â€¢ Press 'h' for detailed help")
    print()
    print("Detection Capabilities:")
    print("  â€¢ Codes: QR codes, various barcode formats")
    print("  â€¢ Vehicles: License plate recognition")
    print("  â€¢ Traffic: Road signs, traffic lights")
    print("  â€¢ Facilities: Restrooms, exits, parking, hospitals")
    print("  â€¢ Objects: Colors, shapes, text, surface analysis")
    print("=" * 50)
    
    gui = EnhancedObjectRecognitionGUI()
    gui.run()

if __name__ == "__main__":
    main()