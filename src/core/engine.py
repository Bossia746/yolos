#!/usr/bin/env python3
"""
YOLOSæ ¸å¿ƒå¼•æ“
ç»Ÿä¸€çš„ç³»ç»Ÿå…¥å£ç‚¹ï¼Œå®ç°é«˜å†…èšä½è€¦åˆçš„æ¶æ„è®¾è®¡
"""

import cv2
import numpy as np
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import threading
import queue
import time
from dataclasses import dataclass
from enum import Enum

from .config import YOLOSConfig
from .logger import YOLOSLogger

class ProcessingMode(Enum):
    """å¤„ç†æ¨¡å¼"""
    REALTIME = "realtime"
    BATCH = "batch"
    SINGLE = "single"

@dataclass
class DetectionResult:
    """æ£€æµ‹ç»“æœæ•°æ®ç»“æ„"""
    bbox: List[int]  # [x, y, w, h]
    confidence: float
    class_id: int
    class_name: str
    timestamp: float

@dataclass
class RecognitionResult:
    """è¯†åˆ«ç»“æœæ•°æ®ç»“æ„"""
    detection: DetectionResult
    features: Dict[str, Any]
    metadata: Dict[str, Any]
    processing_time: float

@dataclass
class FrameResult:
    """å¸§å¤„ç†ç»“æœ"""
    frame_id: int
    timestamp: float
    detections: List[DetectionResult]
    recognitions: List[RecognitionResult]
    processing_time: float
    frame_shape: tuple

class YOLOSEngine:
    """
    YOLOSæ ¸å¿ƒå¼•æ“
    
    è®¾è®¡åŸåˆ™:
    1. å•ä¸€å…¥å£ç‚¹ - æ‰€æœ‰åŠŸèƒ½é€šè¿‡å¼•æ“è®¿é—®
    2. é«˜å†…èš - ç›¸å…³åŠŸèƒ½é›†ä¸­ç®¡ç†
    3. ä½è€¦åˆ - æ¨¡å—é—´é€šè¿‡æ¥å£é€šä¿¡
    4. å¯æ‰©å±• - æ”¯æŒæ’ä»¶å¼æ‰©å±•
    """
    
    def __init__(self, config: Optional[YOLOSConfig] = None):
        """åˆå§‹åŒ–å¼•æ“"""
        self.config = config or YOLOSConfig()
        self.logger = YOLOSLogger.get_logger("engine")
        
        # æ ¸å¿ƒç»„ä»¶
        self._detector = None
        self._recognizer = None
        self._preprocessor = None
        self._postprocessor = None
        
        # çŠ¶æ€ç®¡ç†
        self._initialized = False
        self._running = False
        self._frame_counter = 0
        
        # æ€§èƒ½ç›‘æ§
        self._performance_stats = {
            'total_frames': 0,
            'total_processing_time': 0.0,
            'average_fps': 0.0,
            'last_fps': 0.0
        }
        
        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.RLock()
        self._result_queue = queue.Queue(maxsize=100)
        
        self.logger.info("YOLOSå¼•æ“åˆ›å»ºæˆåŠŸ")
    
    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–å¼•æ“
        
        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._lock:
                if self._initialized:
                    self.logger.warning("å¼•æ“å·²ç»åˆå§‹åŒ–")
                    return True
                
                self.logger.info("å¼€å§‹åˆå§‹åŒ–YOLOSå¼•æ“...")
                
                # 1. åˆå§‹åŒ–æ£€æµ‹å™¨
                self._initialize_detector()
                
                # 2. åˆå§‹åŒ–è¯†åˆ«å™¨
                self._initialize_recognizer()
                
                # 3. åˆå§‹åŒ–é¢„å¤„ç†å™¨
                self._initialize_preprocessor()
                
                # 4. åˆå§‹åŒ–åå¤„ç†å™¨
                self._initialize_postprocessor()
                
                self._initialized = True
                self.logger.info("YOLOSå¼•æ“åˆå§‹åŒ–å®Œæˆ")
                return True
                
        except Exception as e:
            self.logger.error(f"å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _initialize_detector(self):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        from ..detection.factory import DetectorFactory
        
        detector_config = self.config.detection_config
        detector_type = detector_config.get('type', 'yolo')
        
        self._detector = DetectorFactory.create_detector(detector_type, detector_config)
        self.logger.info(f"æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ: {detector_type}")
    
    def _initialize_recognizer(self):
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        from ..recognition.factory import RecognizerFactory
        
        recognizer_config = self.config.recognition_config
        recognizer_types = recognizer_config.get('types', ['face', 'gesture', 'object'])
        
        self._recognizer = RecognizerFactory.create_multi_recognizer(
            recognizer_types, recognizer_config
        )
        self.logger.info(f"è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ: {recognizer_types}")
    
    def _initialize_preprocessor(self):
        """åˆå§‹åŒ–é¢„å¤„ç†å™¨"""
        from ..preprocessing.factory import PreprocessorFactory
        
        preprocess_config = self.config.preprocessing_config
        self._preprocessor = PreprocessorFactory.create_preprocessor(preprocess_config)
        self.logger.info("é¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_postprocessor(self):
        """åˆå§‹åŒ–åå¤„ç†å™¨"""
        from ..postprocessing.factory import PostprocessorFactory
        
        postprocess_config = self.config.postprocessing_config
        self._postprocessor = PostprocessorFactory.create_postprocessor(postprocess_config)
        self.logger.info("åå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_frame(self, frame: np.ndarray, frame_id: Optional[int] = None) -> FrameResult:
        """
        å¤„ç†å•å¸§å›¾åƒ
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            frame_id: å¸§IDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            FrameResult: å¤„ç†ç»“æœ
        """
        if not self._initialized:
            raise RuntimeError("å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
        
        start_time = time.time()
        
        if frame_id is None:
            frame_id = self._frame_counter
            self._frame_counter += 1
        
        try:
            # 1. é¢„å¤„ç†
            processed_frame = self._preprocessor.process(frame)
            
            # 2. æ£€æµ‹
            detections = self._detector.detect(processed_frame)
            
            # 3. è¯†åˆ«
            recognitions = []
            for detection in detections:
                recognition = self._recognizer.recognize(processed_frame, detection)
                if recognition:
                    recognitions.append(recognition)
            
            # 4. åå¤„ç†
            final_result = self._postprocessor.process(
                frame, detections, recognitions
            )
            
            processing_time = time.time() - start_time
            
            # 5. åˆ›å»ºç»“æœ
            result = FrameResult(
                frame_id=frame_id,
                timestamp=start_time,
                detections=detections,
                recognitions=recognitions,
                processing_time=processing_time,
                frame_shape=frame.shape
            )
            
            # 6. æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            self._update_performance_stats(processing_time)
            
            # 7. è®°å½•æ—¥å¿—
            self.logger.debug(
                f"å¸§ {frame_id} å¤„ç†å®Œæˆ",
                processing_time=processing_time,
                detections_count=len(detections),
                recognitions_count=len(recognitions)
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"å¸§ {frame_id} å¤„ç†å¤±è´¥: {e}")
            raise
    
    def process_video(self, video_source: Union[str, int], 
                     mode: ProcessingMode = ProcessingMode.REALTIME) -> None:
        """
        å¤„ç†è§†é¢‘æµ
        
        Args:
            video_source: è§†é¢‘æº (æ–‡ä»¶è·¯å¾„æˆ–æ‘„åƒå¤´ID)
            mode: å¤„ç†æ¨¡å¼
        """
        if not self._initialized:
            raise RuntimeError("å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
        
        self.logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_source}, æ¨¡å¼: {mode.value}")
        
        # æ‰“å¼€è§†é¢‘æº
        cap = cv2.VideoCapture(video_source)
        if not cap.isOpened():
            raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘æº: {video_source}")
        
        try:
            self._running = True
            frame_id = 0
            
            while self._running:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # å¤„ç†å¸§
                result = self.process_frame(frame, frame_id)
                
                # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
                try:
                    self._result_queue.put_nowait(result)
                except queue.Full:
                    # é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒæœ€æ—§çš„ç»“æœ
                    try:
                        self._result_queue.get_nowait()
                        self._result_queue.put_nowait(result)
                    except queue.Empty:
                        pass
                
                frame_id += 1
                
                # å®æ—¶æ¨¡å¼ä¸‹çš„å¸§ç‡æ§åˆ¶
                if mode == ProcessingMode.REALTIME:
                    target_fps = self.config.camera_config.get('fps', 30)
                    time.sleep(max(0, 1.0/target_fps - result.processing_time))
                
        finally:
            cap.release()
            self._running = False
            self.logger.info("è§†é¢‘å¤„ç†å®Œæˆ")
    
    def process_image(self, image_path: str) -> FrameResult:
        """
        å¤„ç†å•å¼ å›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            FrameResult: å¤„ç†ç»“æœ
        """
        if not self._initialized:
            raise RuntimeError("å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
        
        # åŠ è½½å›¾åƒ
        frame = cv2.imread(image_path)
        if frame is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        
        self.logger.info(f"å¤„ç†å›¾åƒ: {image_path}")
        return self.process_frame(frame)
    
    def get_result(self, timeout: Optional[float] = None) -> Optional[FrameResult]:
        """
        è·å–å¤„ç†ç»“æœ
        
        Args:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            FrameResult: å¤„ç†ç»“æœï¼Œå¦‚æœè¶…æ—¶è¿”å›None
        """
        try:
            return self._result_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def stop(self):
        """åœæ­¢å¼•æ“"""
        self._running = False
        self.logger.info("å¼•æ“å·²åœæ­¢")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        with self._lock:
            return self._performance_stats.copy()
    
    def _update_performance_stats(self, processing_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        with self._lock:
            self._performance_stats['total_frames'] += 1
            self._performance_stats['total_processing_time'] += processing_time
            
            if self._performance_stats['total_frames'] > 0:
                avg_time = (self._performance_stats['total_processing_time'] / 
                           self._performance_stats['total_frames'])
                self._performance_stats['average_fps'] = 1.0 / avg_time if avg_time > 0 else 0
            
            self._performance_stats['last_fps'] = 1.0 / processing_time if processing_time > 0 else 0
    
    def reset_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        with self._lock:
            self._performance_stats = {
                'total_frames': 0,
                'total_processing_time': 0.0,
                'average_fps': 0.0,
                'last_fps': 0.0
            }
            self.logger.info("æ€§èƒ½ç»Ÿè®¡å·²é‡ç½®")
    
    def is_initialized(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self._initialized
    
    def is_running(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return self._running
    
    def get_supported_formats(self) -> Dict[str, List[str]]:
        """è·å–æ”¯æŒçš„æ ¼å¼"""
        return {
            'image_formats': ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'],
            'video_formats': ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv'],
            'detection_types': self._detector.get_supported_classes() if self._detector else [],
            'recognition_types': self._recognizer.get_supported_types() if self._recognizer else []
        }
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        if not self.initialize():
            raise RuntimeError("å¼•æ“åˆå§‹åŒ–å¤±è´¥")
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.stop()

# ä¾¿æ·å‡½æ•°
def create_engine(config_path: Optional[str] = None) -> YOLOSEngine:
    """
    åˆ›å»ºYOLOSå¼•æ“å®ä¾‹
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        YOLOSEngine: å¼•æ“å®ä¾‹
    """
    if config_path:
        config = YOLOSConfig.from_file(config_path)
    else:
        config = YOLOSConfig()
    
    return YOLOSEngine(config)

def quick_detect(image_path: str, config_path: Optional[str] = None) -> FrameResult:
    """
    å¿«é€Ÿæ£€æµ‹å•å¼ å›¾åƒ
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        FrameResult: æ£€æµ‹ç»“æœ
    """
    with create_engine(config_path) as engine:
        return engine.process_image(image_path)

if __name__ == "__main__":
    # æµ‹è¯•å¼•æ“
    engine = create_engine()
    
    if engine.initialize():
        print("âœ… å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“Š æ”¯æŒçš„æ ¼å¼: {engine.get_supported_formats()}")
        
        # æµ‹è¯•æ€§èƒ½ç»Ÿè®¡
        stats = engine.get_performance_stats()
        print(f"ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡: {stats}")
    else:
        print("âŒ å¼•æ“åˆå§‹åŒ–å¤±è´¥")