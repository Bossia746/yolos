#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ··åˆç¨³å®šç‰ˆYOLOS GUI - ç»“åˆç¨³å®šæ‘„åƒå¤´å¤„ç†å’ŒTkinteræ˜¾ç¤º
è§£å†³OpenCV GUIåœ¨Windowsä¸Šçš„å…¼å®¹æ€§é—®é¢˜
"""

import cv2
import numpy as np
import tkinter as tk
from tkinter import ttk, messagebox
import threading
import time
import json
import logging
import random
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import sys
import os
from PIL import Image, ImageTk

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hybrid_stable_yolos.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class StableYOLOSDetector:
    """ç¨³å®šç‰ˆYOLOSæ£€æµ‹å™¨ - æ¨¡æ‹ŸYOLOæ£€æµ‹"""
    
    def __init__(self):
        # æ£€æµ‹å‚æ•°
        self.confidence_threshold = 0.5
        self.nms_threshold = 0.4
        
        # æ¨¡æ‹Ÿæ£€æµ‹å†å²
        self.detection_history = []
        self.max_history = 10
        
        # ç›®æ ‡ç±»åˆ«åˆ†ç±» - æŒ‰è¿åŠ¨ç‰¹æ€§åˆ†ç»„
        self.moving_objects = ['person', 'car', 'dog', 'cat', 'bicycle']  # åŠ¨æ€ç›®æ ‡
        self.static_objects = ['bottle', 'chair', 'book', 'cup', 'laptop']  # é™æ€ç›®æ ‡
        self.all_classes = self.moving_objects + self.static_objects
        
        # æ£€æµ‹é¢‘ç‡æ§åˆ¶
        self.moving_detection_interval = 2   # åŠ¨æ€ç›®æ ‡æ¯2å¸§æ£€æµ‹ä¸€æ¬¡
        self.static_detection_interval = 10  # é™æ€ç›®æ ‡æ¯10å¸§æ£€æµ‹ä¸€æ¬¡
        self.last_moving_detection = 0
        self.last_static_detection = 0
        
        # ç›®æ ‡ç¨³å®šæ€§è·Ÿè¸ª
        self.object_positions = {}  # è·Ÿè¸ªç›®æ ‡ä½ç½®å˜åŒ–
        self.position_threshold = 30  # ä½ç½®å˜åŒ–é˜ˆå€¼
        
    def update_parameters(self, confidence: float, nms: float):
        """æ›´æ–°æ£€æµ‹å‚æ•°"""
        self.confidence_threshold = confidence
        self.nms_threshold = nms
        
    def should_detect_moving_objects(self, frame_count: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ£€æµ‹åŠ¨æ€ç›®æ ‡"""
        return (frame_count - self.last_moving_detection) >= self.moving_detection_interval
    
    def should_detect_static_objects(self, frame_count: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ£€æµ‹é™æ€ç›®æ ‡"""
        return (frame_count - self.last_static_detection) >= self.static_detection_interval
    
    def detect_objects(self, frame: np.ndarray, frame_count: int) -> List[Dict]:
        """æ™ºèƒ½ç›®æ ‡æ£€æµ‹ - æ ¹æ®ç›®æ ‡ç±»å‹è°ƒæ•´æ£€æµ‹é¢‘ç‡"""
        detections = []
        h, w = frame.shape[:2]
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ£€æµ‹åŠ¨æ€ç›®æ ‡
        detect_moving = self.should_detect_moving_objects(frame_count)
        detect_static = self.should_detect_static_objects(frame_count)
        
        if not detect_moving and not detect_static:
            return detections
        
        # åŠ¨æ€ç›®æ ‡æ£€æµ‹
        if detect_moving:
            self.last_moving_detection = frame_count
            moving_detections = self._detect_moving_objects(frame, h, w)
            detections.extend(moving_detections)
        
        # é™æ€ç›®æ ‡æ£€æµ‹
        if detect_static:
            self.last_static_detection = frame_count
            static_detections = self._detect_static_objects(frame, h, w)
            detections.extend(static_detections)
        
        # æ›´æ–°ç›®æ ‡ä½ç½®è·Ÿè¸ª
        self._update_object_tracking(detections)
        
        # è®°å½•æ£€æµ‹å†å²
        self.detection_history.append(len(detections))
        if len(self.detection_history) > self.max_history:
            self.detection_history.pop(0)
            
        return detections
    
    def _detect_moving_objects(self, frame: np.ndarray, h: int, w: int) -> List[Dict]:
        """æ£€æµ‹åŠ¨æ€ç›®æ ‡"""
        detections = []
        num_moving = random.randint(0, 2)  # åŠ¨æ€ç›®æ ‡é€šå¸¸è¾ƒå°‘
        
        for i in range(num_moving):
            class_name = random.choice(self.moving_objects)
            
            # åŠ¨æ€ç›®æ ‡ä½ç½®å˜åŒ–è¾ƒå¤§
            if class_name in self.object_positions:
                # åŸºäºä¸Šæ¬¡ä½ç½®ç”Ÿæˆæ–°ä½ç½®ï¼ˆæ¨¡æ‹Ÿè¿åŠ¨ï¼‰
                last_x, last_y = self.object_positions[class_name]
                x = max(50, min(w-200, last_x + random.randint(-50, 50)))
                y = max(50, min(h-150, last_y + random.randint(-30, 30)))
            else:
                x = random.randint(50, max(51, w - 200))
                y = random.randint(50, max(51, h - 150))
            
            width = random.randint(80, min(200, w - x))
            height = random.randint(60, min(150, h - y))
            
            # åŠ¨æ€ç›®æ ‡ç½®ä¿¡åº¦é€šå¸¸è¾ƒé«˜
            confidence = random.uniform(max(0.6, self.confidence_threshold), 1.0)
            
            detection = {
                'class': class_name,
                'confidence': confidence,
                'bbox': (x, y, width, height),
                'center': (x + width//2, y + height//2),
                'type': 'moving',
                'detection_time': time.time()
            }
            
            detections.append(detection)
        
        return detections
    
    def _detect_static_objects(self, frame: np.ndarray, h: int, w: int) -> List[Dict]:
        """æ£€æµ‹é™æ€ç›®æ ‡"""
        detections = []
        num_static = random.randint(1, 3)  # é™æ€ç›®æ ‡é€šå¸¸è¾ƒå¤š
        
        for i in range(num_static):
            class_name = random.choice(self.static_objects)
            
            # é™æ€ç›®æ ‡ä½ç½®å˜åŒ–å¾ˆå°
            if class_name in self.object_positions:
                # åŸºäºä¸Šæ¬¡ä½ç½®ï¼Œä½ç½®å˜åŒ–å¾ˆå°
                last_x, last_y = self.object_positions[class_name]
                x = max(50, min(w-200, last_x + random.randint(-10, 10)))
                y = max(50, min(h-150, last_y + random.randint(-5, 5)))
            else:
                x = random.randint(50, max(51, w - 200))
                y = random.randint(50, max(51, h - 150))
            
            width = random.randint(60, min(150, w - x))
            height = random.randint(40, min(120, h - y))
            
            # é™æ€ç›®æ ‡ç½®ä¿¡åº¦ç›¸å¯¹ç¨³å®š
            confidence = random.uniform(self.confidence_threshold, 0.9)
            
            detection = {
                'class': class_name,
                'confidence': confidence,
                'bbox': (x, y, width, height),
                'center': (x + width//2, y + height//2),
                'type': 'static',
                'detection_time': time.time()
            }
            
            detections.append(detection)
        
        return detections
    
    def _update_object_tracking(self, detections: List[Dict]):
        """æ›´æ–°ç›®æ ‡ä½ç½®è·Ÿè¸ª"""
        for detection in detections:
            class_name = detection['class']
            center = detection['center']
            self.object_positions[class_name] = center


class HybridStableYOLOSGUI:
    """æ··åˆç¨³å®šç‰ˆYOLOS GUI - Tkinterç•Œé¢ + ç¨³å®šæ‘„åƒå¤´å¤„ç†"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("YOLOS - æ··åˆç¨³å®šç‰ˆç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
        self.root.geometry("1200x800")
        
        # æ‘„åƒå¤´ç›¸å…³
        self.cap = None
        self.is_camera_running = False
        self.camera_thread = None
        self.current_frame = None
        
        # æ£€æµ‹å™¨
        self.detector = StableYOLOSDetector()
        
        # æ£€æµ‹æ§åˆ¶
        self.is_detecting = False
        self.result_hold_frames = 30 # ç»“æœä¿æŒ30å¸§ï¼ˆé™æ€ç›®æ ‡ä¿æŒæ›´ä¹…ï¼‰
        
        # æ€§èƒ½ç»Ÿè®¡
        self.frame_count = 0
        self.start_time = time.time()
        self.fps = 0
        
        # ç»“æœç¼“å­˜
        self.cached_results = []
        self.result_cache_time = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_detections': 0,
            'session_start': time.time()
        }
        
        # åˆ›å»ºç•Œé¢
        self.setup_ui()
        
    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        control_frame = ttk.LabelFrame(main_frame, text="æ§åˆ¶é¢æ¿", width=300)
        control_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))
        control_frame.pack_propagate(False)
        
        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ
        display_frame = ttk.LabelFrame(main_frame, text="è§†é¢‘æ˜¾ç¤º")
        display_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)
        
        self.setup_control_panel(control_frame)
        self.setup_display_area(display_frame)
        
    def setup_control_panel(self, parent):
        """è®¾ç½®æ§åˆ¶é¢æ¿"""
        # æ‘„åƒå¤´æ§åˆ¶
        camera_frame = ttk.LabelFrame(parent, text="æ‘„åƒå¤´æ§åˆ¶")
        camera_frame.pack(fill=tk.X, pady=5)
        
        button_frame = ttk.Frame(camera_frame)
        button_frame.pack(fill=tk.X, pady=5)
        
        self.start_btn = ttk.Button(button_frame, text="å¯åŠ¨æ‘„åƒå¤´", 
                                   command=self.start_camera)
        self.start_btn.pack(side=tk.LEFT, padx=2)
        
        self.stop_btn = ttk.Button(button_frame, text="åœæ­¢æ‘„åƒå¤´", 
                                  command=self.stop_camera, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=2)
        
        # æ£€æµ‹æ§åˆ¶
        detection_frame = ttk.LabelFrame(parent, text="æ£€æµ‹æ§åˆ¶")
        detection_frame.pack(fill=tk.X, pady=5)
        
        self.detect_btn = ttk.Button(detection_frame, text="å¼€å§‹æ£€æµ‹", 
                                    command=self.toggle_detection, state=tk.DISABLED)
        self.detect_btn.pack(pady=5)
        
        # å‚æ•°è®¾ç½®
        params_frame = ttk.LabelFrame(parent, text="æ£€æµ‹å‚æ•°")
        params_frame.pack(fill=tk.X, pady=5)
        
        ttk.Label(params_frame, text="ç½®ä¿¡åº¦é˜ˆå€¼:").pack(anchor=tk.W)
        self.conf_var = tk.DoubleVar(value=0.5)
        conf_scale = ttk.Scale(params_frame, from_=0.1, to=1.0, 
                              variable=self.conf_var, orient=tk.HORIZONTAL,
                              command=self.update_parameters)
        conf_scale.pack(fill=tk.X, pady=2)
        
        self.conf_label = ttk.Label(params_frame, text="0.50")
        self.conf_label.pack(anchor=tk.W)
        
        ttk.Label(params_frame, text="NMSé˜ˆå€¼:").pack(anchor=tk.W, pady=(10,0))
        self.nms_var = tk.DoubleVar(value=0.4)
        nms_scale = ttk.Scale(params_frame, from_=0.1, to=1.0, 
                             variable=self.nms_var, orient=tk.HORIZONTAL,
                             command=self.update_parameters)
        nms_scale.pack(fill=tk.X, pady=2)
        
        self.nms_label = ttk.Label(params_frame, text="0.40")
        self.nms_label.pack(anchor=tk.W)
        
        # æ£€æµ‹é¢‘ç‡æ§åˆ¶
        frequency_frame = ttk.LabelFrame(parent, text="æ™ºèƒ½æ£€æµ‹é¢‘ç‡")
        frequency_frame.pack(fill=tk.X, pady=5)
        
        ttk.Label(frequency_frame, text="åŠ¨æ€ç›®æ ‡é—´éš”:").pack(anchor=tk.W)
        self.moving_interval_var = tk.IntVar(value=2)
        moving_scale = ttk.Scale(frequency_frame, from_=1, to=10, 
                                variable=self.moving_interval_var, orient=tk.HORIZONTAL,
                                command=self.update_detection_intervals)
        moving_scale.pack(fill=tk.X, pady=2)
        
        self.moving_label = ttk.Label(frequency_frame, text="2å¸§")
        self.moving_label.pack(anchor=tk.W)
        
        ttk.Label(frequency_frame, text="é™æ€ç›®æ ‡é—´éš”:").pack(anchor=tk.W, pady=(5,0))
        self.static_interval_var = tk.IntVar(value=10)
        static_scale = ttk.Scale(frequency_frame, from_=5, to=30, 
                                variable=self.static_interval_var, orient=tk.HORIZONTAL,
                                command=self.update_detection_intervals)
        static_scale.pack(fill=tk.X, pady=2)
        
        self.static_label = ttk.Label(frequency_frame, text="10å¸§")
        self.static_label.pack(anchor=tk.W)
        
        # çŠ¶æ€ä¿¡æ¯
        status_frame = ttk.LabelFrame(parent, text="çŠ¶æ€ä¿¡æ¯")
        status_frame.pack(fill=tk.X, pady=5)
        
        self.status_text = tk.Text(status_frame, height=10, width=30)
        scrollbar = ttk.Scrollbar(status_frame, orient=tk.VERTICAL, 
                                 command=self.status_text.yview)
        self.status_text.configure(yscrollcommand=scrollbar.set)
        
        self.status_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        self.log_message("YOLOSæ··åˆç¨³å®šç‰ˆç³»ç»Ÿå·²å¯åŠ¨")
        
    def setup_display_area(self, parent):
        """è®¾ç½®æ˜¾ç¤ºåŒºåŸŸ"""
        # åˆ›å»ºCanvasç”¨äºæ˜¾ç¤ºè§†é¢‘
        self.canvas = tk.Canvas(parent, bg='black')
        self.canvas.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ˜¾ç¤ºæç¤ºä¿¡æ¯
        self.canvas.create_text(400, 300, text="è¯·å¯åŠ¨æ‘„åƒå¤´å¼€å§‹æ£€æµ‹", 
                               fill='white', font=('Arial', 16))
        
    def log_message(self, message):
        """è®°å½•æ—¥å¿—ä¿¡æ¯"""
        timestamp = time.strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"
        
        self.status_text.insert(tk.END, log_entry)
        self.status_text.see(tk.END)
        
        # é™åˆ¶æ—¥å¿—é•¿åº¦
        lines = self.status_text.get("1.0", tk.END).split('\n')
        if len(lines) > 100:
            self.status_text.delete("1.0", "10.0")
            
    def update_parameters(self, value=None):
        """æ›´æ–°æ£€æµ‹å‚æ•°"""
        conf = self.conf_var.get()
        nms = self.nms_var.get()
        
        self.conf_label.config(text=f"{conf:.2f}")
        self.nms_label.config(text=f"{nms:.2f}")
        
        # æ›´æ–°æ£€æµ‹å™¨å‚æ•°
        self.detector.update_parameters(conf, nms)
        
    def update_detection_intervals(self, value=None):
        """æ›´æ–°æ£€æµ‹é—´éš”"""
        moving_interval = int(self.moving_interval_var.get())
        static_interval = int(self.static_interval_var.get())
        
        self.moving_label.config(text=f"{moving_interval}å¸§")
        self.static_label.config(text=f"{static_interval}å¸§")
        
        # æ›´æ–°æ£€æµ‹å™¨é—´éš”
        self.detector.moving_detection_interval = moving_interval
        self.detector.static_detection_interval = static_interval
        
        self.log_message(f"æ£€æµ‹é—´éš”å·²æ›´æ–°: åŠ¨æ€{moving_interval}å¸§, é™æ€{static_interval}å¸§")
        
    def initialize_camera(self) -> bool:
        """åˆå§‹åŒ–æ‘„åƒå¤´ - ä½¿ç”¨ç¨³å®šçš„åˆå§‹åŒ–é€»è¾‘"""
        logger.info("æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
        
        # é¦–å…ˆå°è¯•å†…ç½®æ‘„åƒå¤´ (index 0)
        logger.info("å°è¯•å†…ç½®æ‘„åƒå¤´ (ç´¢å¼• 0)")
        cap = cv2.VideoCapture(0)
        if cap.isOpened():
            ret, frame = cap.read()
            if ret and frame is not None:
                self.cap = cap
                logger.info(f"å†…ç½®æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ: {frame.shape}")
                self.log_message("å†…ç½®æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
                return True
            else:
                cap.release()
        
        # å¦‚æœå†…ç½®æ‘„åƒå¤´å¤±è´¥ï¼Œå°è¯•å¤–éƒ¨æ‘„åƒå¤´
        for index in [1, 2, 3, 4]:
            logger.info(f"å°è¯•æ‘„åƒå¤´ç´¢å¼• {index}")
            cap = cv2.VideoCapture(index)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    self.cap = cap
                    logger.info(f"æ‘„åƒå¤´ {index} å¯åŠ¨æˆåŠŸ: {frame.shape}")
                    self.log_message(f"æ‘„åƒå¤´ {index} å¯åŠ¨æˆåŠŸ")
                    return True
                else:
                    cap.release()
            else:
                cap.release()
        
        logger.error("æ²¡æœ‰å¯ç”¨çš„æ‘„åƒå¤´")
        self.log_message("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ‘„åƒå¤´")
        return False
    
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        if not self.initialize_camera():
            messagebox.showerror("é”™è¯¯", "æ— æ³•å¯åŠ¨æ‘„åƒå¤´")
            return
            
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        self.is_camera_running = True
        self.start_time = time.time()
        self.frame_count = 0
        
        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        self.detect_btn.config(state=tk.NORMAL)
        
        # å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹
        self.camera_thread = threading.Thread(target=self.camera_loop, daemon=True)
        self.camera_thread.start()
        
        self.log_message("æ‘„åƒå¤´å·²å¯åŠ¨")
        
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_camera_running = False
        self.is_detecting = False
        
        if self.cap:
            self.cap.release()
            self.cap = None
            
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.camera_thread and self.camera_thread.is_alive():
            self.camera_thread.join(timeout=2.0)
        
        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        self.start_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.DISABLED)
        self.detect_btn.config(state=tk.DISABLED)
        
        # æ¸…ç©ºæ˜¾ç¤º
        self.canvas.delete("all")
        self.canvas.create_text(400, 300, text="æ‘„åƒå¤´å·²åœæ­¢", 
                               fill='white', font=('Arial', 16))
        
        self.log_message("æ‘„åƒå¤´å·²åœæ­¢")
        
    def toggle_detection(self):
        """åˆ‡æ¢æ£€æµ‹çŠ¶æ€"""
        self.is_detecting = not self.is_detecting
        
        if self.is_detecting:
            self.detect_btn.config(text="åœæ­¢æ£€æµ‹")
            self.log_message("å¼€å§‹ç›®æ ‡æ£€æµ‹")
        else:
            self.detect_btn.config(text="å¼€å§‹æ£€æµ‹")
            self.log_message("åœæ­¢ç›®æ ‡æ£€æµ‹")
            
    def camera_loop(self):
        """æ‘„åƒå¤´å¾ªç¯çº¿ç¨‹ - ä½¿ç”¨ç¨³å®šçš„å¤„ç†é€»è¾‘"""
        while self.is_camera_running:
            try:
                if self.cap and self.cap.isOpened():
                    ret, frame = self.cap.read()
                    if ret:
                        self.frame_count += 1
                        self.current_frame = frame.copy()
                        
                        # è®¡ç®—FPS
                        if self.frame_count % 30 == 0:
                            elapsed = time.time() - self.start_time
                            self.fps = self.frame_count / elapsed if elapsed > 0 else 0
                        
                        # æ™ºèƒ½æ£€æµ‹æ§åˆ¶
                        if self.is_detecting:
                            results = self.detector.detect_objects(frame, self.frame_count)
                            if results:
                                self.cached_results = results
                                self.result_cache_time = self.frame_count
                                self.root.after(0, lambda: self.log_detections(results))
                        
                        # ä½¿ç”¨ç¼“å­˜ç»“æœ
                        display_results = []
                        if self.cached_results and (self.frame_count - self.result_cache_time) < self.result_hold_frames:
                            display_results = self.cached_results
                        
                        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                        if display_results:
                            frame = self.draw_detections(frame, display_results)
                        
                        # ç»˜åˆ¶ä¿¡æ¯
                        frame = self.draw_info_overlay(frame, display_results)
                        
                        # åœ¨ä¸»çº¿ç¨‹ä¸­æ˜¾ç¤ºå¸§
                        self.root.after(0, lambda f=frame: self.display_frame(f))
                        
                time.sleep(0.033)  # ~30 FPS
                
            except Exception as e:
                logger.error(f"æ‘„åƒå¤´å¾ªç¯é”™è¯¯: {e}")
                self.root.after(0, lambda: self.log_message(f"æ‘„åƒå¤´é”™è¯¯: {e}"))
                break
                
    def draw_detections(self, frame: np.ndarray, results: List[Dict]) -> np.ndarray:
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ - åŒºåˆ†åŠ¨æ€å’Œé™æ€ç›®æ ‡"""
        for detection in results:
            class_name = detection['class']
            confidence = detection['confidence']
            x, y, w, h = detection['bbox']
            obj_type = detection.get('type', 'unknown')
            
            # æ ¹æ®ç›®æ ‡ç±»å‹å’Œç½®ä¿¡åº¦é€‰æ‹©é¢œè‰²
            if obj_type == 'moving':
                # åŠ¨æ€ç›®æ ‡ä½¿ç”¨æš–è‰²è°ƒ
                if confidence > 0.8:
                    color = (0, 255, 0)    # ç»¿è‰² - é«˜ç½®ä¿¡åº¦åŠ¨æ€ç›®æ ‡
                elif confidence > 0.6:
                    color = (0, 255, 255)  # é»„è‰² - ä¸­ç­‰ç½®ä¿¡åº¦åŠ¨æ€ç›®æ ‡
                else:
                    color = (0, 165, 255)  # æ©™è‰² - ä½ç½®ä¿¡åº¦åŠ¨æ€ç›®æ ‡
                thickness = 3  # åŠ¨æ€ç›®æ ‡è¾¹æ¡†æ›´ç²—
            else:
                # é™æ€ç›®æ ‡ä½¿ç”¨å†·è‰²è°ƒ
                if confidence > 0.8:
                    color = (255, 0, 0)    # è“è‰² - é«˜ç½®ä¿¡åº¦é™æ€ç›®æ ‡
                elif confidence > 0.6:
                    color = (255, 255, 0)  # é’è‰² - ä¸­ç­‰ç½®ä¿¡åº¦é™æ€ç›®æ ‡
                else:
                    color = (255, 0, 255)  # ç´«è‰² - ä½ç½®ä¿¡åº¦é™æ€ç›®æ ‡
                thickness = 2  # é™æ€ç›®æ ‡è¾¹æ¡†è¾ƒç»†
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness)
            
            # ç»˜åˆ¶æ ‡ç­¾
            type_indicator = "ğŸƒ" if obj_type == 'moving' else "ğŸ“¦"
            label = f"{type_indicator}{class_name}: {confidence:.2f}"
            
            # æ ‡ç­¾èƒŒæ™¯
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(frame, (x, y - label_h - 10), (x + label_w + 4, y), color, -1)
            cv2.putText(frame, label, (x + 2, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # ç»˜åˆ¶ä¸­å¿ƒç‚¹ - åŠ¨æ€ç›®æ ‡ç”¨åœ†å½¢ï¼Œé™æ€ç›®æ ‡ç”¨æ–¹å½¢
            center_x, center_y = detection['center']
            if obj_type == 'moving':
                cv2.circle(frame, (center_x, center_y), 4, color, -1)
            else:
                cv2.rectangle(frame, (center_x-3, center_y-3), (center_x+3, center_y+3), color, -1)
        
        return frame
    
    def draw_info_overlay(self, frame: np.ndarray, results: List[Dict]) -> np.ndarray:
        """ç»˜åˆ¶ä¿¡æ¯è¦†ç›–å±‚"""
        # å·¦ä¸Šè§’ä¿¡æ¯é¢æ¿ - æ‰©å¤§é¢æ¿
        overlay = frame.copy()
        cv2.rectangle(overlay, (5, 5), (350, 140), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„ç›®æ ‡
        moving_count = len([r for r in results if r.get('type') == 'moving'])
        static_count = len([r for r in results if r.get('type') == 'static'])
        
        # æ˜¾ç¤ºä¿¡æ¯
        font_scale = 0.4
        thickness = 1
        y_offset = 20
        
        cv2.putText(frame, f"æ€»æ£€æµ‹: {len(results)} (åŠ¨æ€:{moving_count} é™æ€:{static_count})", 
                   (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        cv2.putText(frame, f"æ£€æµ‹çŠ¶æ€: {'æ™ºèƒ½æ£€æµ‹å¼€å¯' if self.is_detecting else 'æ£€æµ‹å…³é—­'}", 
                   (10, y_offset + 18), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0) if self.is_detecting else (0, 0, 255), thickness)
        
        cv2.putText(frame, f"FPS: {self.fps:.1f} | å¸§æ•°: {self.frame_count}", 
                   (10, y_offset + 36), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
        
        cv2.putText(frame, f"ç½®ä¿¡åº¦: {self.conf_var.get():.2f} | NMS: {self.nms_var.get():.2f}", 
                   (10, y_offset + 54), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 0), thickness)
        
        # æ˜¾ç¤ºæ£€æµ‹é—´éš”ç­–ç•¥
        moving_interval = getattr(self, 'moving_interval_var', None)
        static_interval = getattr(self, 'static_interval_var', None)
        if moving_interval and static_interval:
            cv2.putText(frame, f"æ£€æµ‹é—´éš” - åŠ¨æ€:{moving_interval.get()}å¸§ é™æ€:{static_interval.get()}å¸§", 
                       (10, y_offset + 72), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 255), thickness)
        
        # æ˜¾ç¤ºå½“å‰æ£€æµ‹çš„ç›®æ ‡ç±»å‹
        if results:
            detected_classes = list(set([r['class'] for r in results]))
            class_text = "å½“å‰ç›®æ ‡: " + ", ".join(detected_classes[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ª
            if len(detected_classes) > 3:
                class_text += f" +{len(detected_classes)-3}ä¸ª"
            cv2.putText(frame, class_text, 
                       (10, y_offset + 90), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 165, 0), thickness)
        
        return frame
        
    def display_frame(self, frame):
        """æ˜¾ç¤ºå¸§åˆ°Canvas"""
        try:
            # è°ƒæ•´å¸§å¤§å°ä»¥é€‚åº”Canvas
            canvas_width = self.canvas.winfo_width()
            canvas_height = self.canvas.winfo_height()
            
            if canvas_width > 1 and canvas_height > 1:
                # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                h, w = frame.shape[:2]
                scale = min(canvas_width/w, canvas_height/h)
                
                new_w = int(w * scale)
                new_h = int(h * scale)
                
                # è°ƒæ•´å¤§å°
                frame_resized = cv2.resize(frame, (new_w, new_h))
                
                # è½¬æ¢é¢œè‰²æ ¼å¼
                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)
                
                # è½¬æ¢ä¸ºPILå›¾åƒ
                pil_image = Image.fromarray(frame_rgb)
                photo = ImageTk.PhotoImage(pil_image)
                
                # æ¸…ç©ºCanvaså¹¶æ˜¾ç¤ºæ–°å›¾åƒ
                self.canvas.delete("all")
                
                # å±…ä¸­æ˜¾ç¤º
                x = (canvas_width - new_w) // 2
                y = (canvas_height - new_h) // 2
                
                self.canvas.create_image(x, y, anchor=tk.NW, image=photo)
                self.canvas.image = photo  # ä¿æŒå¼•ç”¨
                
        except Exception as e:
            logger.error(f"æ˜¾ç¤ºå¸§é”™è¯¯: {e}")
            
    def log_detections(self, results: List[Dict]):
        """è®°å½•æ£€æµ‹ç»“æœ"""
        if results:
            for detection in results:
                class_name = detection['class']
                confidence = detection['confidence']
                
                log_msg = f"æ£€æµ‹åˆ° {class_name} (ç½®ä¿¡åº¦: {confidence:.3f})"
                self.log_message(log_msg)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['total_detections'] += len(results)
    
    def on_closing(self):
        """å…³é—­ç¨‹åºæ—¶çš„æ¸…ç†å·¥ä½œ"""
        self.is_camera_running = False
        self.is_detecting = False
        
        if self.cap:
            self.cap.release()
            
        if hasattr(self, 'camera_thread') and self.camera_thread and self.camera_thread.is_alive():
            self.camera_thread.join(timeout=2.0)
            
        self.root.destroy()
        
    def run(self):
        """è¿è¡ŒGUI"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        
        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            self.on_closing()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOS æ··åˆç¨³å®šç‰ˆç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
    print("ç»“åˆç¨³å®šæ‘„åƒå¤´å¤„ç†å’ŒTkinterç•Œé¢")
    print("=" * 45)
    print("åŠŸèƒ½ç‰¹æ€§:")
    print("  ğŸ¥ ç¨³å®šçš„æ‘„åƒå¤´å¤„ç†")
    print("  ğŸ–¥ï¸ Tkinterå›¾å½¢ç•Œé¢")
    print("  ğŸ¯ å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡æ‹Ÿ")
    print("  âš™ï¸ åŠ¨æ€å‚æ•°è°ƒæ•´")
    print("  ğŸ“Š æ€§èƒ½ç›‘æ§")
    print()
    
    try:
        app = HybridStableYOLOSGUI()
        app.run()
        
    except Exception as e:
        logger.error(f"å¯åŠ¨ç³»ç»Ÿå¤±è´¥: {e}")
        print(f"âŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    main()