#!/usr/bin/env python3
"""
YOLOSæ ¸å¿ƒè®­ç»ƒç•Œé¢ç®¡ç†å™¨
ä¸“æ³¨äºè§†é¢‘æ•æ‰ã€å›¾åƒè¯†åˆ«å’Œæ¨¡å‹è®­ç»ƒçš„æ ¸å¿ƒåŠŸèƒ½
é¿å…è¿‡åº¦æ‰©å±•åˆ°ä¸“ä¸šé¢†åŸŸï¼Œé€šè¿‡APIä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’
"""

import cv2
import numpy as np
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import threading
import time
import json
import os
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging
from datetime import datetime

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from ..training.dataset_manager import DatasetManager
    from ..training.trainer import YOLOSTrainer
    from ..training.offline_training_manager import OfflineTrainingManager
    from ..detection.yolos_detector import YOLOSDetector
    from ..utils.logger import setup_logger
except ImportError:
    # å¤‡ç”¨å¯¼å…¥
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
    
    class DatasetManager:
        def __init__(self): pass
        def load_dataset(self, path): return {"images": [], "labels": []}
        def save_dataset(self, data, path): pass
    
    class YOLOSTrainer:
        def __init__(self): pass
        def train(self, config): return {"status": "success", "model_path": "model.pt"}
    
    class OfflineTrainingManager:
        def __init__(self): pass
        def start_training(self, config): return True
    
    class YOLOSDetector:
        def __init__(self): pass
        def detect(self, image): return []
    
    def setup_logger(name):
        logger = logging.getLogger(name)
        logger.setLevel(logging.INFO)
        return logger

class VideoCapture:
    """è§†é¢‘æ•æ‰ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cap = None
        self.is_recording = False
        self.frame_buffer = []
        self.max_buffer_size = 100
        self.current_frame = None
        self.frame_count = 0
        
    def initialize_camera(self, camera_id: int = 0) -> bool:
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(camera_id)
            if not self.cap.isOpened():
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            return True
        except Exception as e:
            logging.error(f"æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def read_frame(self) -> Optional[np.ndarray]:
        """è¯»å–ä¸€å¸§"""
        if not self.cap or not self.cap.isOpened():
            return None
        
        ret, frame = self.cap.read()
        if ret:
            self.current_frame = frame.copy()
            self.frame_count += 1
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            if self.is_recording:
                self.frame_buffer.append(frame.copy())
                if len(self.frame_buffer) > self.max_buffer_size:
                    self.frame_buffer.pop(0)
            
            return frame
        return None
    
    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        self.is_recording = True
        self.frame_buffer = []
    
    def stop_recording(self) -> List[np.ndarray]:
        """åœæ­¢å½•åˆ¶å¹¶è¿”å›å¸§"""
        self.is_recording = False
        return self.frame_buffer.copy()
    
    def capture_image(self) -> Optional[np.ndarray]:
        """æ•è·å½“å‰å¸§"""
        return self.current_frame.copy() if self.current_frame is not None else None
    
    def release(self):
        """é‡Šæ”¾æ‘„åƒå¤´"""
        if self.cap:
            self.cap.release()

class TrainingDataCollector:
    """è®­ç»ƒæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, save_dir: str = "training_data"):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.save_dir / "images").mkdir(exist_ok=True)
        (self.save_dir / "labels").mkdir(exist_ok=True)
        (self.save_dir / "videos").mkdir(exist_ok=True)
        
        self.current_class = "unknown"
        self.image_count = 0
        self.annotations = []
    
    def set_current_class(self, class_name: str):
        """è®¾ç½®å½“å‰æ ‡æ³¨ç±»åˆ«"""
        self.current_class = class_name
    
    def save_image_with_annotation(self, image: np.ndarray, bbox: Optional[Tuple[int, int, int, int]] = None):
        """ä¿å­˜å›¾åƒå’Œæ ‡æ³¨"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        image_filename = f"{self.current_class}_{timestamp}_{self.image_count:04d}.jpg"
        image_path = self.save_dir / "images" / image_filename
        
        # ä¿å­˜å›¾åƒ
        cv2.imwrite(str(image_path), image)
        
        # ä¿å­˜æ ‡æ³¨
        if bbox:
            x, y, w, h = bbox
            img_h, img_w = image.shape[:2]
            
            # è½¬æ¢ä¸ºYOLOæ ¼å¼ (å½’ä¸€åŒ–çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜)
            center_x = (x + w/2) / img_w
            center_y = (y + h/2) / img_h
            norm_w = w / img_w
            norm_h = h / img_h
            
            label_filename = image_filename.replace('.jpg', '.txt')
            label_path = self.save_dir / "labels" / label_filename
            
            with open(label_path, 'w') as f:
                f.write(f"0 {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n")
        
        self.image_count += 1
        return str(image_path)
    
    def save_video_sequence(self, frames: List[np.ndarray], class_name: str):
        """ä¿å­˜è§†é¢‘åºåˆ—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_filename = f"{class_name}_{timestamp}.avi"
        video_path = self.save_dir / "videos" / video_filename
        
        if frames:
            h, w = frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(str(video_path), fourcc, 20.0, (w, h))
            
            for frame in frames:
                out.write(frame)
            
            out.release()
        
        return str(video_path)
    
    def get_dataset_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        images_dir = self.save_dir / "images"
        labels_dir = self.save_dir / "labels"
        
        image_files = list(images_dir.glob("*.jpg"))
        label_files = list(labels_dir.glob("*.txt"))
        
        class_counts = {}
        for img_file in image_files:
            class_name = img_file.name.split('_')[0]
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        return {
            "total_images": len(image_files),
            "total_labels": len(label_files),
            "classes": class_counts,
            "save_dir": str(self.save_dir)
        }

class YOLOSTrainingGUI:
    """YOLOSè®­ç»ƒç•Œé¢ä¸»ç±»"""
    
    def __init__(self):
        self.logger = setup_logger("YOLOSTrainingGUI")
        
        # æ ¸å¿ƒç»„ä»¶
        self.video_capture = VideoCapture()
        self.data_collector = TrainingDataCollector()
        self.dataset_manager = DatasetManager()
        self.trainer = YOLOSTrainer()
        self.offline_trainer = OfflineTrainingManager()
        self.detector = YOLOSDetector()
        
        # GUIç»„ä»¶
        self.root = None
        self.video_frame = None
        self.control_frame = None
        self.status_frame = None
        
        # çŠ¶æ€å˜é‡
        self.is_camera_active = False
        self.is_training = False
        self.current_mode = "capture"  # capture, annotate, train, detect
        self.selected_bbox = None
        self.drawing_bbox = False
        self.bbox_start = None
        
        # é…ç½®
        self.config = {
            "camera_id": 0,
            "image_size": (640, 480),
            "classes": ["person", "pet", "object"],
            "model_type": "yolov8n",
            "epochs": 100,
            "batch_size": 16
        }
        
        self.create_gui()
    
    def create_gui(self):
        """åˆ›å»ºGUIç•Œé¢"""
        self.root = tk.Tk()
        self.root.title("YOLOSè®­ç»ƒç³»ç»Ÿ - è§†é¢‘æ•æ‰ä¸æ¨¡å‹è®­ç»ƒ")
        self.root.geometry("1200x800")
        
        # åˆ›å»ºä¸»è¦åŒºåŸŸ
        self.create_menu_bar()
        self.create_video_area()
        self.create_control_panel()
        self.create_status_panel()
        
        # ç»‘å®šäº‹ä»¶
        self.bind_events()
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.update_status("ç³»ç»Ÿå·²å¯åŠ¨ï¼Œè¯·é€‰æ‹©æ‘„åƒå¤´")
    
    def create_menu_bar(self):
        """åˆ›å»ºèœå•æ """
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # æ–‡ä»¶èœå•
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="æ–‡ä»¶", menu=file_menu)
        file_menu.add_command(label="åŠ è½½æ•°æ®é›†", command=self.load_dataset)
        file_menu.add_command(label="ä¿å­˜æ•°æ®é›†", command=self.save_dataset)
        file_menu.add_command(label="å¯¼å‡ºæ¨¡å‹", command=self.export_model)
        file_menu.add_separator()
        file_menu.add_command(label="é€€å‡º", command=self.on_closing)
        
        # è§†å›¾èœå•
        view_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="è§†å›¾", menu=view_menu)
        view_menu.add_command(label="å…¨å±", command=self.toggle_fullscreen)
        view_menu.add_command(label="é‡ç½®å¸ƒå±€", command=self.reset_layout)
        
        # å·¥å…·èœå•
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å·¥å…·", menu=tools_menu)
        tools_menu.add_command(label="æ•°æ®å¢å¼º", command=self.show_augmentation_dialog)
        tools_menu.add_command(label="æ¨¡å‹è¯„ä¼°", command=self.show_evaluation_dialog)
        tools_menu.add_command(label="ç³»ç»Ÿè®¾ç½®", command=self.show_settings_dialog)
        
        # å¸®åŠ©èœå•
        help_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="å¸®åŠ©", menu=help_menu)
        help_menu.add_command(label="ä½¿ç”¨è¯´æ˜", command=self.show_help)
        help_menu.add_command(label="å…³äº", command=self.show_about)
    
    def create_video_area(self):
        """åˆ›å»ºè§†é¢‘æ˜¾ç¤ºåŒºåŸŸ"""
        # ä¸»è§†é¢‘æ¡†æ¶
        self.video_frame = tk.Frame(self.root, bg="black", relief=tk.SUNKEN, bd=2)
        self.video_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # è§†é¢‘ç”»å¸ƒ
        self.video_canvas = tk.Canvas(self.video_frame, bg="black", width=640, height=480)
        self.video_canvas.pack(expand=True, fill=tk.BOTH)
        
        # è§†é¢‘æ§åˆ¶æŒ‰é’®
        video_controls = tk.Frame(self.video_frame)
        video_controls.pack(side=tk.BOTTOM, fill=tk.X, pady=2)
        
        tk.Button(video_controls, text="å¯åŠ¨æ‘„åƒå¤´", command=self.start_camera).pack(side=tk.LEFT, padx=2)
        tk.Button(video_controls, text="åœæ­¢æ‘„åƒå¤´", command=self.stop_camera).pack(side=tk.LEFT, padx=2)
        tk.Button(video_controls, text="æ•è·å›¾åƒ", command=self.capture_image).pack(side=tk.LEFT, padx=2)
        tk.Button(video_controls, text="å¼€å§‹å½•åˆ¶", command=self.start_recording).pack(side=tk.LEFT, padx=2)
        tk.Button(video_controls, text="åœæ­¢å½•åˆ¶", command=self.stop_recording).pack(side=tk.LEFT, padx=2)
    
    def create_control_panel(self):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        self.control_frame = tk.Frame(self.root, width=300, relief=tk.RAISED, bd=1)
        self.control_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=5, pady=5)
        self.control_frame.pack_propagate(False)
        
        # æ¨¡å¼é€‰æ‹©
        mode_frame = tk.LabelFrame(self.control_frame, text="å·¥ä½œæ¨¡å¼", padx=5, pady=5)
        mode_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.mode_var = tk.StringVar(value="capture")
        modes = [("æ•°æ®æ•è·", "capture"), ("æ ‡æ³¨æ¨¡å¼", "annotate"), ("æ¨¡å‹è®­ç»ƒ", "train"), ("å®æ—¶æ£€æµ‹", "detect")]
        
        for text, mode in modes:
            tk.Radiobutton(mode_frame, text=text, variable=self.mode_var, 
                          value=mode, command=self.on_mode_change).pack(anchor=tk.W)
        
        # ç±»åˆ«é€‰æ‹©
        class_frame = tk.LabelFrame(self.control_frame, text="ç›®æ ‡ç±»åˆ«", padx=5, pady=5)
        class_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.class_var = tk.StringVar(value="person")
        self.class_combo = ttk.Combobox(class_frame, textvariable=self.class_var, 
                                       values=self.config["classes"], state="readonly")
        self.class_combo.pack(fill=tk.X, pady=2)
        
        tk.Button(class_frame, text="æ·»åŠ æ–°ç±»åˆ«", command=self.add_new_class).pack(fill=tk.X, pady=2)
        
        # è®­ç»ƒé…ç½®
        train_frame = tk.LabelFrame(self.control_frame, text="è®­ç»ƒé…ç½®", padx=5, pady=5)
        train_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ¨¡å‹ç±»å‹
        tk.Label(train_frame, text="æ¨¡å‹ç±»å‹:").pack(anchor=tk.W)
        self.model_var = tk.StringVar(value="yolov8n")
        model_combo = ttk.Combobox(train_frame, textvariable=self.model_var,
                                  values=["yolov8n", "yolov8s", "yolov8m", "yolov8l"], state="readonly")
        model_combo.pack(fill=tk.X, pady=2)
        
        # è®­ç»ƒå‚æ•°
        params_frame = tk.Frame(train_frame)
        params_frame.pack(fill=tk.X, pady=2)
        
        tk.Label(params_frame, text="è®­ç»ƒè½®æ•°:").grid(row=0, column=0, sticky=tk.W)
        self.epochs_var = tk.IntVar(value=100)
        tk.Spinbox(params_frame, from_=10, to=1000, textvariable=self.epochs_var, width=10).grid(row=0, column=1)
        
        tk.Label(params_frame, text="æ‰¹æ¬¡å¤§å°:").grid(row=1, column=0, sticky=tk.W)
        self.batch_var = tk.IntVar(value=16)
        tk.Spinbox(params_frame, from_=1, to=64, textvariable=self.batch_var, width=10).grid(row=1, column=1)
        
        # è®­ç»ƒæ§åˆ¶
        tk.Button(train_frame, text="å¼€å§‹è®­ç»ƒ", command=self.start_training, 
                 bg="green", fg="white").pack(fill=tk.X, pady=2)
        tk.Button(train_frame, text="åœæ­¢è®­ç»ƒ", command=self.stop_training, 
                 bg="red", fg="white").pack(fill=tk.X, pady=2)
        
        # æ•°æ®é›†ä¿¡æ¯
        dataset_frame = tk.LabelFrame(self.control_frame, text="æ•°æ®é›†ä¿¡æ¯", padx=5, pady=5)
        dataset_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.dataset_info = tk.Text(dataset_frame, height=8, width=30)
        self.dataset_info.pack(fill=tk.BOTH, expand=True)
        
        tk.Button(dataset_frame, text="åˆ·æ–°ä¿¡æ¯", command=self.update_dataset_info).pack(fill=tk.X, pady=2)
    
    def create_status_panel(self):
        """åˆ›å»ºçŠ¶æ€é¢æ¿"""
        self.status_frame = tk.Frame(self.root, height=100, relief=tk.SUNKEN, bd=1)
        self.status_frame.pack(side=tk.BOTTOM, fill=tk.X, padx=5, pady=5)
        self.status_frame.pack_propagate(False)
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_label = tk.Label(self.status_frame, text="å°±ç»ª", anchor=tk.W)
        self.status_label.pack(side=tk.LEFT, padx=5)
        
        # è¿›åº¦æ¡
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(self.status_frame, variable=self.progress_var, 
                                          maximum=100, length=200)
        self.progress_bar.pack(side=tk.RIGHT, padx=5)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats_label = tk.Label(self.status_frame, text="", anchor=tk.E)
        self.stats_label.pack(side=tk.RIGHT, padx=5)
    
    def bind_events(self):
        """ç»‘å®šäº‹ä»¶"""
        # é¼ æ ‡äº‹ä»¶ï¼ˆç”¨äºæ ‡æ³¨ï¼‰
        self.video_canvas.bind("<Button-1>", self.on_mouse_click)
        self.video_canvas.bind("<B1-Motion>", self.on_mouse_drag)
        self.video_canvas.bind("<ButtonRelease-1>", self.on_mouse_release)
        
        # é”®ç›˜äº‹ä»¶
        self.root.bind("<Key>", self.on_key_press)
        self.root.focus_set()
        
        # çª—å£äº‹ä»¶
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
    
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        if self.video_capture.initialize_camera(self.config["camera_id"]):
            self.is_camera_active = True
            self.update_status("æ‘„åƒå¤´å·²å¯åŠ¨")
            self.video_loop()
        else:
            messagebox.showerror("é”™è¯¯", "æ— æ³•å¯åŠ¨æ‘„åƒå¤´")
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_camera_active = False
        self.video_capture.release()
        self.video_canvas.delete("all")
        self.update_status("æ‘„åƒå¤´å·²åœæ­¢")
    
    def video_loop(self):
        """è§†é¢‘å¾ªç¯"""
        if not self.is_camera_active:
            return
        
        frame = self.video_capture.read_frame()
        if frame is not None:
            # å¤„ç†å¸§
            processed_frame = self.process_frame(frame)
            
            # æ˜¾ç¤ºå¸§
            self.display_frame(processed_frame)
            
            # æ›´æ–°ç»Ÿè®¡
            self.update_stats()
        
        # ç»§ç»­å¾ªç¯
        self.root.after(33, self.video_loop)  # ~30 FPS
    
    def process_frame(self, frame: np.ndarray) -> np.ndarray:
        """å¤„ç†è§†é¢‘å¸§"""
        processed = frame.copy()
        
        # æ ¹æ®å½“å‰æ¨¡å¼å¤„ç†
        if self.current_mode == "detect":
            # å®æ—¶æ£€æµ‹æ¨¡å¼
            detections = self.detector.detect(frame)
            processed = self.draw_detections(processed, detections)
        
        elif self.current_mode == "annotate":
            # æ ‡æ³¨æ¨¡å¼ - æ˜¾ç¤ºæ ‡æ³¨å·¥å…·
            if self.selected_bbox:
                x, y, w, h = self.selected_bbox
                cv2.rectangle(processed, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(processed, self.class_var.get(), (x, y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æ·»åŠ æ¨¡å¼æŒ‡ç¤ºå™¨
        cv2.putText(processed, f"æ¨¡å¼: {self.current_mode}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return processed
    
    def display_frame(self, frame: np.ndarray):
        """åœ¨ç”»å¸ƒä¸Šæ˜¾ç¤ºå¸§"""
        # è½¬æ¢ä¸ºRGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # è°ƒæ•´å¤§å°ä»¥é€‚åº”ç”»å¸ƒ
        canvas_width = self.video_canvas.winfo_width()
        canvas_height = self.video_canvas.winfo_height()
        
        if canvas_width > 1 and canvas_height > 1:
            frame_resized = cv2.resize(frame_rgb, (canvas_width, canvas_height))
            
            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶æ˜¾ç¤º
            from PIL import Image, ImageTk
            image = Image.fromarray(frame_resized)
            photo = ImageTk.PhotoImage(image)
            
            self.video_canvas.delete("all")
            self.video_canvas.create_image(0, 0, anchor=tk.NW, image=photo)
            self.video_canvas.image = photo  # ä¿æŒå¼•ç”¨
    
    def draw_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """ç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        for detection in detections:
            bbox = detection.get('bbox', [])
            if len(bbox) == 4:
                x, y, w, h = bbox
                confidence = detection.get('confidence', 0)
                class_name = detection.get('class', 'unknown')
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                
                # ç»˜åˆ¶æ ‡ç­¾
                label = f"{class_name}: {confidence:.2f}"
                cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        return frame
    
    def capture_image(self):
        """æ•è·å½“å‰å›¾åƒ"""
        if not self.is_camera_active:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´")
            return
        
        image = self.video_capture.capture_image()
        if image is not None:
            # ä¿å­˜å›¾åƒ
            image_path = self.data_collector.save_image_with_annotation(
                image, self.selected_bbox
            )
            self.update_status(f"å›¾åƒå·²ä¿å­˜: {os.path.basename(image_path)}")
            self.update_dataset_info()
        else:
            messagebox.showerror("é”™è¯¯", "æ— æ³•æ•è·å›¾åƒ")
    
    def start_recording(self):
        """å¼€å§‹å½•åˆ¶"""
        if not self.is_camera_active:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´")
            return
        
        self.video_capture.start_recording()
        self.update_status("å¼€å§‹å½•åˆ¶è§†é¢‘...")
    
    def stop_recording(self):
        """åœæ­¢å½•åˆ¶"""
        frames = self.video_capture.stop_recording()
        if frames:
            video_path = self.data_collector.save_video_sequence(frames, self.class_var.get())
            self.update_status(f"è§†é¢‘å·²ä¿å­˜: {os.path.basename(video_path)}")
        else:
            self.update_status("å½•åˆ¶åœæ­¢")
    
    def start_training(self):
        """å¼€å§‹è®­ç»ƒ"""
        if self.is_training:
            messagebox.showwarning("è­¦å‘Š", "è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­")
            return
        
        # æ£€æŸ¥æ•°æ®é›†
        dataset_info = self.data_collector.get_dataset_info()
        if dataset_info["total_images"] < 10:
            messagebox.showwarning("è­¦å‘Š", "è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10å¼ å›¾åƒ")
            return
        
        # é…ç½®è®­ç»ƒå‚æ•°
        train_config = {
            "model_type": self.model_var.get(),
            "epochs": self.epochs_var.get(),
            "batch_size": self.batch_var.get(),
            "data_path": dataset_info["save_dir"],
            "classes": list(dataset_info["classes"].keys())
        }
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¼€å§‹è®­ç»ƒ
        self.is_training = True
        self.update_status("å¼€å§‹è®­ç»ƒ...")
        
        def train_thread():
            try:
                result = self.offline_trainer.start_training(train_config)
                self.root.after(0, lambda: self.on_training_complete(result))
            except Exception as e:
                self.root.after(0, lambda: self.on_training_error(str(e)))
        
        threading.Thread(target=train_thread, daemon=True).start()
    
    def stop_training(self):
        """åœæ­¢è®­ç»ƒ"""
        self.is_training = False
        self.update_status("è®­ç»ƒå·²åœæ­¢")
    
    def on_training_complete(self, result):
        """è®­ç»ƒå®Œæˆå›è°ƒ"""
        self.is_training = False
        self.progress_var.set(100)
        self.update_status("è®­ç»ƒå®Œæˆ")
        messagebox.showinfo("æˆåŠŸ", f"æ¨¡å‹è®­ç»ƒå®Œæˆ\næ¨¡å‹è·¯å¾„: {result.get('model_path', 'unknown')}")
    
    def on_training_error(self, error_msg):
        """è®­ç»ƒé”™è¯¯å›è°ƒ"""
        self.is_training = False
        self.progress_var.set(0)
        self.update_status("è®­ç»ƒå¤±è´¥")
        messagebox.showerror("é”™è¯¯", f"è®­ç»ƒå¤±è´¥: {error_msg}")
    
    def on_mode_change(self):
        """æ¨¡å¼åˆ‡æ¢"""
        self.current_mode = self.mode_var.get()
        self.data_collector.set_current_class(self.class_var.get())
        self.update_status(f"åˆ‡æ¢åˆ°{self.current_mode}æ¨¡å¼")
    
    def on_mouse_click(self, event):
        """é¼ æ ‡ç‚¹å‡»äº‹ä»¶"""
        if self.current_mode == "annotate":
            self.drawing_bbox = True
            self.bbox_start = (event.x, event.y)
    
    def on_mouse_drag(self, event):
        """é¼ æ ‡æ‹–æ‹½äº‹ä»¶"""
        if self.drawing_bbox and self.bbox_start:
            # å®æ—¶æ˜¾ç¤ºæ‹–æ‹½æ¡†
            pass
    
    def on_mouse_release(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        if self.drawing_bbox and self.bbox_start:
            x1, y1 = self.bbox_start
            x2, y2 = event.x, event.y
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x = min(x1, x2)
            y = min(y1, y2)
            w = abs(x2 - x1)
            h = abs(y2 - y1)
            
            if w > 10 and h > 10:  # æœ€å°å°ºå¯¸æ£€æŸ¥
                self.selected_bbox = (x, y, w, h)
                self.update_status(f"é€‰æ‹©åŒºåŸŸ: {w}x{h}")
            
            self.drawing_bbox = False
            self.bbox_start = None
    
    def on_key_press(self, event):
        """é”®ç›˜äº‹ä»¶"""
        key = event.keysym.lower()
        
        if key == 'space':
            self.capture_image()
        elif key == 'r':
            if self.video_capture.is_recording:
                self.stop_recording()
            else:
                self.start_recording()
        elif key == 'escape':
            self.selected_bbox = None
    
    def add_new_class(self):
        """æ·»åŠ æ–°ç±»åˆ«"""
        class_name = tk.simpledialog.askstring("æ–°ç±»åˆ«", "è¯·è¾“å…¥ç±»åˆ«åç§°:")
        if class_name and class_name not in self.config["classes"]:
            self.config["classes"].append(class_name)
            self.class_combo['values'] = self.config["classes"]
            self.class_var.set(class_name)
            self.update_status(f"æ·»åŠ æ–°ç±»åˆ«: {class_name}")
    
    def update_dataset_info(self):
        """æ›´æ–°æ•°æ®é›†ä¿¡æ¯"""
        info = self.data_collector.get_dataset_info()
        
        info_text = f"""æ•°æ®é›†ç»Ÿè®¡:
æ€»å›¾åƒæ•°: {info['total_images']}
æ€»æ ‡æ³¨æ•°: {info['total_labels']}

ç±»åˆ«åˆ†å¸ƒ:
"""
        for class_name, count in info['classes'].items():
            info_text += f"  {class_name}: {count}\n"
        
        info_text += f"\nä¿å­˜è·¯å¾„: {info['save_dir']}"
        
        self.dataset_info.delete(1.0, tk.END)
        self.dataset_info.insert(1.0, info_text)
    
    def update_status(self, message: str):
        """æ›´æ–°çŠ¶æ€"""
        self.status_label.config(text=message)
        self.logger.info(message)
    
    def update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if self.is_camera_active:
            fps = 30  # ç®€åŒ–çš„FPSè®¡ç®—
            frame_count = self.video_capture.frame_count
            self.stats_label.config(text=f"FPS: {fps} | å¸§æ•°: {frame_count}")
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        directory = filedialog.askdirectory(title="é€‰æ‹©æ•°æ®é›†ç›®å½•")
        if directory:
            try:
                dataset = self.dataset_manager.load_dataset(directory)
                self.update_status(f"æ•°æ®é›†å·²åŠ è½½: {len(dataset.get('images', []))} å¼ å›¾åƒ")
                self.update_dataset_info()
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
    
    def save_dataset(self):
        """ä¿å­˜æ•°æ®é›†"""
        directory = filedialog.askdirectory(title="é€‰æ‹©ä¿å­˜ç›®å½•")
        if directory:
            try:
                info = self.data_collector.get_dataset_info()
                # è¿™é‡Œå¯ä»¥å®ç°æ•°æ®é›†æ ¼å¼è½¬æ¢å’Œä¿å­˜
                self.update_status(f"æ•°æ®é›†å·²ä¿å­˜åˆ°: {directory}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ•°æ®é›†å¤±è´¥: {e}")
    
    def export_model(self):
        """å¯¼å‡ºæ¨¡å‹"""
        filename = filedialog.asksaveasfilename(
            title="å¯¼å‡ºæ¨¡å‹",
            defaultextension=".pt",
            filetypes=[("PyTorchæ¨¡å‹", "*.pt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            # è¿™é‡Œå®ç°æ¨¡å‹å¯¼å‡ºé€»è¾‘
            self.update_status(f"æ¨¡å‹å·²å¯¼å‡º: {filename}")
    
    def show_settings_dialog(self):
        """æ˜¾ç¤ºè®¾ç½®å¯¹è¯æ¡†"""
        settings_window = tk.Toplevel(self.root)
        settings_window.title("ç³»ç»Ÿè®¾ç½®")
        settings_window.geometry("400x300")
        
        # æ‘„åƒå¤´è®¾ç½®
        camera_frame = tk.LabelFrame(settings_window, text="æ‘„åƒå¤´è®¾ç½®", padx=5, pady=5)
        camera_frame.pack(fill=tk.X, padx=10, pady=5)
        
        tk.Label(camera_frame, text="æ‘„åƒå¤´ID:").pack(anchor=tk.W)
        camera_id_var = tk.IntVar(value=self.config["camera_id"])
        tk.Spinbox(camera_frame, from_=0, to=10, textvariable=camera_id_var).pack(fill=tk.X)
        
        # åº”ç”¨è®¾ç½®æŒ‰é’®
        def apply_settings():
            self.config["camera_id"] = camera_id_var.get()
            settings_window.destroy()
            self.update_status("è®¾ç½®å·²åº”ç”¨")
        
        tk.Button(settings_window, text="åº”ç”¨", command=apply_settings).pack(pady=10)
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©"""
        help_text = """
YOLOSè®­ç»ƒç³»ç»Ÿä½¿ç”¨è¯´æ˜:

1. æ•°æ®æ•è·æ¨¡å¼:
   - å¯åŠ¨æ‘„åƒå¤´
   - é€‰æ‹©ç›®æ ‡ç±»åˆ«
   - æŒ‰ç©ºæ ¼é”®æˆ–ç‚¹å‡»"æ•è·å›¾åƒ"

2. æ ‡æ³¨æ¨¡å¼:
   - åœ¨è§†é¢‘ç”»é¢ä¸Šæ‹–æ‹½é€‰æ‹©ç›®æ ‡åŒºåŸŸ
   - æŒ‰ç©ºæ ¼é”®ä¿å­˜æ ‡æ³¨

3. è®­ç»ƒæ¨¡å¼:
   - é…ç½®è®­ç»ƒå‚æ•°
   - ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"

4. æ£€æµ‹æ¨¡å¼:
   - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
   - å®æ—¶æ£€æµ‹è§†é¢‘ä¸­çš„ç›®æ ‡

å¿«æ·é”®:
- ç©ºæ ¼: æ•è·å›¾åƒ
- R: å¼€å§‹/åœæ­¢å½•åˆ¶
- ESC: å–æ¶ˆé€‰æ‹©
        """
        
        messagebox.showinfo("ä½¿ç”¨è¯´æ˜", help_text)
    
    def show_about(self):
        """æ˜¾ç¤ºå…³äºä¿¡æ¯"""
        about_text = """
YOLOSè®­ç»ƒç³»ç»Ÿ v1.0

ä¸“æ³¨äºè§†é¢‘æ•æ‰å’Œå›¾åƒè¯†åˆ«çš„æ ¸å¿ƒåŠŸèƒ½
æ”¯æŒå®æ—¶æ•°æ®æ”¶é›†ã€æ ‡æ³¨å’Œæ¨¡å‹è®­ç»ƒ

å¼€å‘å›¢é˜Ÿ: YOLOSé¡¹ç›®ç»„
        """
        messagebox.showinfo("å…³äº", about_text)
    
    def toggle_fullscreen(self):
        """åˆ‡æ¢å…¨å±"""
        pass
    
    def reset_layout(self):
        """é‡ç½®å¸ƒå±€"""
        pass
    
    def show_augmentation_dialog(self):
        """æ˜¾ç¤ºæ•°æ®å¢å¼ºå¯¹è¯æ¡†"""
        pass
    
    def show_evaluation_dialog(self):
        """æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°å¯¹è¯æ¡†"""
        pass
    
    def on_closing(self):
        """å…³é—­ç¨‹åº"""
        if self.is_camera_active:
            self.stop_camera()
        
        if self.is_training:
            if messagebox.askokcancel("ç¡®è®¤", "è®­ç»ƒæ­£åœ¨è¿›è¡Œï¼Œç¡®å®šè¦é€€å‡ºå—ï¼Ÿ"):
                self.stop_training()
            else:
                return
        
        self.root.destroy()
    
    def run(self):
        """è¿è¡ŒGUI"""
        self.update_dataset_info()
        self.root.mainloop()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOSè®­ç»ƒç³»ç»Ÿå¯åŠ¨")
    print("ä¸“æ³¨äºè§†é¢‘æ•æ‰å’Œå›¾åƒè¯†åˆ«çš„æ ¸å¿ƒåŠŸèƒ½")
    print("=" * 50)
    
    try:
        app = YOLOSTrainingGUI()
        app.run()
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        logging.error(f"GUIå¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()