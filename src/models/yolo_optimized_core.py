#!/usr/bin/env python3
"""
YOLOä¼˜åŒ–æ ¸å¿ƒæ£€æµ‹å™¨
æ”¯æŒå¤šå¹³å°é«˜æ•ˆè¿è¡Œçš„ç»Ÿä¸€YOLOæ£€æµ‹æ¥å£
"""

import os
import sys
import time
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path
import logging

# å¹³å°æ£€æµ‹
PLATFORM = sys.platform
IS_WINDOWS = PLATFORM == 'win32'
IS_LINUX = PLATFORM.startswith('linux')
IS_MACOS = PLATFORM == 'darwin'

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False

try:
    import torch
    import torchvision
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False

try:
    import tflite_runtime.interpreter as tflite
    TFLITE_AVAILABLE = True
except ImportError:
    try:
        import tensorflow.lite as tflite
        TFLITE_AVAILABLE = True
    except ImportError:
        TFLITE_AVAILABLE = False

class DetectionResult:
    """æ£€æµ‹ç»“æœç±»"""
    
    def __init__(self, class_id: int, class_name: str, confidence: float, 
                 bbox: Tuple[int, int, int, int]):
        self.class_id = class_id
        self.class_name = class_name
        self.confidence = confidence
        self.bbox = bbox  # (x1, y1, x2, y2)
        
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'class_id': self.class_id,
            'class_name': self.class_name,
            'confidence': self.confidence,
            'bbox': self.bbox
        }
        
    def __str__(self) -> str:
        return f"{self.class_name}({self.confidence:.2f}): {self.bbox}"

class YOLOOptimizedCore:
    """YOLOä¼˜åŒ–æ ¸å¿ƒæ£€æµ‹å™¨"""
    
    def __init__(self, model_path: Optional[str] = None, 
                 device: str = 'auto',
                 input_size: Tuple[int, int] = (640, 640),
                 confidence_threshold: float = 0.5,
                 nms_threshold: float = 0.4):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: è¿è¡Œè®¾å¤‡ ('cpu', 'cuda', 'auto')
            input_size: è¾“å…¥å°ºå¯¸ (width, height)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            nms_threshold: NMSé˜ˆå€¼
        """
        self.model_path = model_path
        self.device = self._determine_device(device)
        self.input_size = input_size
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        
        # æ¨¡å‹ç›¸å…³
        self.model = None
        self.model_type = None
        self.session = None
        self.interpreter = None
        
        # ç±»åˆ«åç§°
        self.class_names = self._get_default_class_names()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.inference_times = []
        self.preprocess_times = []
        self.postprocess_times = []
        
        # æ—¥å¿—
        self.logger = self._setup_logger()
        
        # è‡ªåŠ¨åŠ è½½æ¨¡å‹
        if model_path:
            self.load_model(model_path)
            
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('YOLOOptimizedCore')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
        
    def _determine_device(self, device: str) -> str:
        """ç¡®å®šè¿è¡Œè®¾å¤‡"""
        if device == 'auto':
            if TORCH_AVAILABLE and torch.cuda.is_available():
                return 'cuda'
            else:
                return 'cpu'
        return device
        
    def _get_default_class_names(self) -> List[str]:
        """è·å–é»˜è®¤ç±»åˆ«åç§°(COCOæ•°æ®é›†)"""
        return [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
    def load_model(self, model_path: str) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(model_path):
            self.logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
            
        self.model_path = model_path
        file_ext = Path(model_path).suffix.lower()
        
        try:
            if file_ext == '.pt' and TORCH_AVAILABLE:
                return self._load_pytorch_model(model_path)
            elif file_ext == '.onnx' and ONNX_AVAILABLE:
                return self._load_onnx_model(model_path)
            elif file_ext == '.tflite' and TFLITE_AVAILABLE:
                return self._load_tflite_model(model_path)
            else:
                self.logger.error(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {file_ext}")
                return False
                
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
            
    def _load_pytorch_model(self, model_path: str) -> bool:
        """åŠ è½½PyTorchæ¨¡å‹"""
        try:
            self.model = torch.jit.load(model_path, map_location=self.device)
            self.model.eval()
            self.model_type = 'pytorch'
            self.logger.info(f"PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
        except Exception as e:
            self.logger.error(f"PyTorchæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
            
    def _load_onnx_model(self, model_path: str) -> bool:
        """åŠ è½½ONNXæ¨¡å‹"""
        try:
            providers = ['CPUExecutionProvider']
            if self.device == 'cuda':
                providers.insert(0, 'CUDAExecutionProvider')
                
            self.session = ort.InferenceSession(model_path, providers=providers)
            self.model_type = 'onnx'
            self.logger.info(f"ONNXæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
        except Exception as e:
            self.logger.error(f"ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
            
    def _load_tflite_model(self, model_path: str) -> bool:
        """åŠ è½½TFLiteæ¨¡å‹"""
        try:
            self.interpreter = tflite.Interpreter(model_path=model_path)
            self.interpreter.allocate_tensors()
            self.model_type = 'tflite'
            self.logger.info(f"TFLiteæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
        except Exception as e:
            self.logger.error(f"TFLiteæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
            
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        å›¾åƒé¢„å¤„ç†
        
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C)
            
        Returns:
            np.ndarray: é¢„å¤„ç†åçš„å›¾åƒ
        """
        start_time = time.time()
        
        # è°ƒæ•´å°ºå¯¸
        if image.shape[:2] != self.input_size[::-1]:  # (H, W) vs (W, H)
            if OPENCV_AVAILABLE:
                image = cv2.resize(image, self.input_size)
            else:
                # ç®€å•çš„æœ€è¿‘é‚»æ’å€¼
                image = self._simple_resize(image, self.input_size)
        
        # å½’ä¸€åŒ–
        image = image.astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        if self.model_type in ['pytorch', 'onnx']:
            # (H, W, C) -> (1, C, H, W)
            image = np.transpose(image, (2, 0, 1))
            image = np.expand_dims(image, axis=0)
        elif self.model_type == 'tflite':
            # (H, W, C) -> (1, H, W, C)
            image = np.expand_dims(image, axis=0)
            
        self.preprocess_times.append(time.time() - start_time)
        return image
        
    def _simple_resize(self, image: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """ç®€å•çš„å›¾åƒç¼©æ”¾(æœ€è¿‘é‚»æ’å€¼)"""
        h, w = image.shape[:2]
        target_w, target_h = target_size
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = w / target_w
        scale_y = h / target_h
        
        # åˆ›å»ºè¾“å‡ºå›¾åƒ
        if len(image.shape) == 3:
            resized = np.zeros((target_h, target_w, image.shape[2]), dtype=image.dtype)
        else:
            resized = np.zeros((target_h, target_w), dtype=image.dtype)
            
        # æœ€è¿‘é‚»æ’å€¼
        for y in range(target_h):
            for x in range(target_w):
                src_x = int(x * scale_x)
                src_y = int(y * scale_y)
                src_x = min(src_x, w - 1)
                src_y = min(src_y, h - 1)
                resized[y, x] = image[src_y, src_x]
                
        return resized
        
    def inference(self, preprocessed_image: np.ndarray) -> np.ndarray:
        """
        æ¨¡å‹æ¨ç†
        
        Args:
            preprocessed_image: é¢„å¤„ç†åçš„å›¾åƒ
            
        Returns:
            np.ndarray: æ¨ç†ç»“æœ
        """
        start_time = time.time()
        
        try:
            if self.model_type == 'pytorch':
                with torch.no_grad():
                    input_tensor = torch.from_numpy(preprocessed_image).to(self.device)
                    output = self.model(input_tensor)
                    if isinstance(output, (list, tuple)):
                        output = output[0]
                    result = output.cpu().numpy()
                    
            elif self.model_type == 'onnx':
                input_name = self.session.get_inputs()[0].name
                result = self.session.run(None, {input_name: preprocessed_image})[0]
                
            elif self.model_type == 'tflite':
                input_details = self.interpreter.get_input_details()
                output_details = self.interpreter.get_output_details()
                
                self.interpreter.set_tensor(input_details[0]['index'], preprocessed_image)
                self.interpreter.invoke()
                result = self.interpreter.get_tensor(output_details[0]['index'])
                
            else:
                # æ¨¡æ‹Ÿæ¨ç†ç»“æœ
                batch_size = preprocessed_image.shape[0]
                result = np.random.random((batch_size, 25200, 85)).astype(np.float32)
                
        except Exception as e:
            self.logger.error(f"æ¨ç†å¤±è´¥: {e}")
            # è¿”å›ç©ºç»“æœ
            batch_size = preprocessed_image.shape[0]
            result = np.zeros((batch_size, 25200, 85), dtype=np.float32)
            
        self.inference_times.append(time.time() - start_time)
        return result
        
    def postprocess_detections(self, predictions: np.ndarray, 
                             original_shape: Tuple[int, int]) -> List[DetectionResult]:
        """
        åå¤„ç†æ£€æµ‹ç»“æœ
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹ç»“æœ
            original_shape: åŸå§‹å›¾åƒå°ºå¯¸ (H, W)
            
        Returns:
            List[DetectionResult]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        
        detections = []
        
        try:
            # å‡è®¾è¾“å‡ºæ ¼å¼ä¸º (batch, num_boxes, 85) å…¶ä¸­85 = 4(bbox) + 1(conf) + 80(classes)
            if len(predictions.shape) == 3:
                predictions = predictions[0]  # å–ç¬¬ä¸€ä¸ªbatch
                
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            confidences = predictions[:, 4]
            valid_indices = confidences > self.confidence_threshold
            valid_predictions = predictions[valid_indices]
            
            if len(valid_predictions) == 0:
                self.postprocess_times.append(time.time() - start_time)
                return detections
                
            # è§£ææ£€æµ‹ç»“æœ
            boxes = valid_predictions[:, :4]  # x_center, y_center, width, height
            confidences = valid_predictions[:, 4]
            class_scores = valid_predictions[:, 5:]
            
            # è·å–æœ€é«˜åˆ†ç±»åˆ«
            class_ids = np.argmax(class_scores, axis=1)
            class_confidences = np.max(class_scores, axis=1)
            
            # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
            final_confidences = confidences * class_confidences
            
            # è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼ (center_x, center_y, w, h) -> (x1, y1, x2, y2)
            x_centers, y_centers, widths, heights = boxes.T
            x1 = x_centers - widths / 2
            y1 = y_centers - heights / 2
            x2 = x_centers + widths / 2
            y2 = y_centers + heights / 2
            
            # ç¼©æ”¾åˆ°åŸå§‹å›¾åƒå°ºå¯¸
            orig_h, orig_w = original_shape
            scale_x = orig_w / self.input_size[0]
            scale_y = orig_h / self.input_size[1]
            
            x1 = (x1 * scale_x).astype(int)
            y1 = (y1 * scale_y).astype(int)
            x2 = (x2 * scale_x).astype(int)
            y2 = (y2 * scale_y).astype(int)
            
            # åº”ç”¨NMS
            if OPENCV_AVAILABLE:
                indices = cv2.dnn.NMSBoxes(
                    [(int(x1[i]), int(y1[i]), int(x2[i]-x1[i]), int(y2[i]-y1[i])) 
                     for i in range(len(x1))],
                    final_confidences.tolist(),
                    self.confidence_threshold,
                    self.nms_threshold
                )
                
                if len(indices) > 0:
                    indices = indices.flatten()
                else:
                    indices = []
            else:
                # ç®€å•çš„NMSå®ç°
                indices = self._simple_nms(
                    np.column_stack([x1, y1, x2, y2]),
                    final_confidences,
                    self.nms_threshold
                )
            
            # åˆ›å»ºæ£€æµ‹ç»“æœ
            for i in indices:
                class_id = class_ids[i]
                class_name = (self.class_names[class_id] 
                            if class_id < len(self.class_names) 
                            else f'class_{class_id}')
                confidence = final_confidences[i]
                bbox = (int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i]))
                
                detections.append(DetectionResult(
                    class_id=int(class_id),
                    class_name=class_name,
                    confidence=float(confidence),
                    bbox=bbox
                ))
                
        except Exception as e:
            self.logger.error(f"åå¤„ç†å¤±è´¥: {e}")
            
        self.postprocess_times.append(time.time() - start_time)
        return detections
        
    def _simple_nms(self, boxes: np.ndarray, scores: np.ndarray, 
                   threshold: float) -> List[int]:
        """ç®€å•çš„NMSå®ç°"""
        if len(boxes) == 0:
            return []
            
        # è®¡ç®—é¢ç§¯
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        
        # æŒ‰åˆ†æ•°æ’åº
        order = scores.argsort()[::-1]
        
        keep = []
        while len(order) > 0:
            i = order[0]
            keep.append(i)
            
            if len(order) == 1:
                break
                
            # è®¡ç®—IoU
            xx1 = np.maximum(boxes[i, 0], boxes[order[1:], 0])
            yy1 = np.maximum(boxes[i, 1], boxes[order[1:], 1])
            xx2 = np.minimum(boxes[i, 2], boxes[order[1:], 2])
            yy2 = np.minimum(boxes[i, 3], boxes[order[1:], 3])
            
            w = np.maximum(0, xx2 - xx1)
            h = np.maximum(0, yy2 - yy1)
            intersection = w * h
            
            union = areas[i] + areas[order[1:]] - intersection
            iou = intersection / (union + 1e-6)
            
            # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
            indices = np.where(iou <= threshold)[0]
            order = order[indices + 1]
            
        return keep
        
    def detect(self, image: np.ndarray) -> List[DetectionResult]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„ç›®æ ‡
        
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C)
            
        Returns:
            List[DetectionResult]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        if self.model is None and self.session is None and self.interpreter is None:
            self.logger.warning("æ¨¡å‹æœªåŠ è½½ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ")
            return self._generate_mock_detections(image.shape[:2])
            
        # é¢„å¤„ç†
        preprocessed = self.preprocess_image(image)
        
        # æ¨ç†
        predictions = self.inference(preprocessed)
        
        # åå¤„ç†
        detections = self.postprocess_detections(predictions, image.shape[:2])
        
        return detections
        
    def _generate_mock_detections(self, image_shape: Tuple[int, int]) -> List[DetectionResult]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ£€æµ‹ç»“æœ"""
        h, w = image_shape
        
        # ç”Ÿæˆ1-3ä¸ªéšæœºæ£€æµ‹ç»“æœ
        num_detections = np.random.randint(1, 4)
        detections = []
        
        for i in range(num_detections):
            # éšæœºç±»åˆ«
            class_id = np.random.randint(0, len(self.class_names))
            class_name = self.class_names[class_id]
            
            # éšæœºç½®ä¿¡åº¦
            confidence = np.random.uniform(0.5, 0.95)
            
            # éšæœºè¾¹ç•Œæ¡†
            x1 = np.random.randint(0, w // 2)
            y1 = np.random.randint(0, h // 2)
            x2 = np.random.randint(x1 + 50, min(w, x1 + 200))
            y2 = np.random.randint(y1 + 50, min(h, y1 + 200))
            
            detections.append(DetectionResult(
                class_id=class_id,
                class_name=class_name,
                confidence=confidence,
                bbox=(x1, y1, x2, y2)
            ))
            
        return detections
        
    def get_performance_stats(self) -> Dict[str, float]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = {}
        
        if self.preprocess_times:
            stats['avg_preprocess_time'] = np.mean(self.preprocess_times)
            stats['max_preprocess_time'] = np.max(self.preprocess_times)
            
        if self.inference_times:
            stats['avg_inference_time'] = np.mean(self.inference_times)
            stats['max_inference_time'] = np.max(self.inference_times)
            
        if self.postprocess_times:
            stats['avg_postprocess_time'] = np.mean(self.postprocess_times)
            stats['max_postprocess_time'] = np.max(self.postprocess_times)
            
        total_times = []
        for i in range(min(len(self.preprocess_times), 
                          len(self.inference_times), 
                          len(self.postprocess_times))):
            total_time = (self.preprocess_times[i] + 
                         self.inference_times[i] + 
                         self.postprocess_times[i])
            total_times.append(total_time)
            
        if total_times:
            stats['avg_total_time'] = np.mean(total_times)
            stats['avg_fps'] = 1.0 / np.mean(total_times)
            
        return stats
        
    def reset_performance_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        self.preprocess_times.clear()
        self.inference_times.clear()
        self.postprocess_times.clear()
        
    def set_confidence_threshold(self, threshold: float):
        """è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼"""
        self.confidence_threshold = max(0.0, min(1.0, threshold))
        
    def set_nms_threshold(self, threshold: float):
        """è®¾ç½®NMSé˜ˆå€¼"""
        self.nms_threshold = max(0.0, min(1.0, threshold))
        
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_path': self.model_path,
            'model_type': self.model_type,
            'device': self.device,
            'input_size': self.input_size,
            'confidence_threshold': self.confidence_threshold,
            'nms_threshold': self.nms_threshold,
            'num_classes': len(self.class_names),
            'opencv_available': OPENCV_AVAILABLE,
            'torch_available': TORCH_AVAILABLE,
            'onnx_available': ONNX_AVAILABLE,
            'tflite_available': TFLITE_AVAILABLE
        }

def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•YOLOä¼˜åŒ–æ ¸å¿ƒæ£€æµ‹å™¨...")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = YOLOOptimizedCore()
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    info = detector.get_model_info()
    print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    for key, value in info.items():
        print(f"   {key}: {value}")
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    print(f"\nğŸ–¼ï¸ æµ‹è¯•å›¾åƒå°ºå¯¸: {test_image.shape}")
    
    # æ‰§è¡Œæ£€æµ‹
    print("\nğŸ¯ æ‰§è¡Œæ£€æµ‹...")
    detections = detector.detect(test_image)
    
    print(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡:")
    for det in detections:
        print(f"   - {det}")
    
    # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
    stats = detector.get_performance_stats()
    print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
    for key, value in stats.items():
        if 'time' in key:
            print(f"   {key}: {value*1000:.2f}ms")
        elif 'fps' in key:
            print(f"   {key}: {value:.1f}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()